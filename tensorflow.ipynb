{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing tensorflow\n",
    "- 每次运行时必须创建session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.  12.  15.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "#turn off tensorflow warning messages in program output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "# define d=computational graph\n",
    "X=tf.placeholder(tf.float32,name=\"X\")\n",
    "Y=tf.placeholder(tf.float32,name=\"Y\")\n",
    "\n",
    "addition=tf.add(X,Y,name=\"addition\")\n",
    "\n",
    "#create the session\n",
    "with tf.Session() as session:\n",
    "    result=session.run(addition,feed_dict={X:[1,5,6],Y:[4,7,9]})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"resul2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "p=tf.constant(-1)\n",
    "l=tf.constant(5)\n",
    "resul2=tf.add(p,l,name='resul2')\n",
    "print(resul2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 电子游戏销售预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#make the data\n",
    "# col=['critic_rating','is_action','is_exclusive_to_us','is_portable','is_role_playing','is_sequel','is_sports','suitable_for_kids','total_earnings','unit_price']\n",
    "col=['critic_rating','is_action','is_exclusive_to_us','is_portable','is_role_playing','is_sequel','is_sports','suitable_for_kids','total_earnings','unit_price']\n",
    "# trainData={} #store the trainData\n",
    "# testData={}  #store the testData\n",
    "# # prediceData={}#store the predict data\n",
    "# for i in range(len(col)):\n",
    "#     if i==0:\n",
    "#         testData[col[i]]=np.random.uniform(1,5,10000)\n",
    "#     elif i==(len(col)-1):\n",
    "#         testData[col[i]]=np.random.uniform(30,60,10000)\n",
    "#     elif  i==len(col)-2:\n",
    "#         testData[col[i]]=np.random.randint(30000,140000,10000)\n",
    "#     else:\n",
    "#         testData[col[i]]=np.random.randint(0,2,10000)\n",
    "        \n",
    "# testData=pd.DataFrame(testData)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "(10000, 1)\n",
      "note:Y values were scaled by multiplying by 0.0000090917 and adding -0.2728\n"
     ]
    }
   ],
   "source": [
    "#model.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "  \n",
    "\n",
    "tranining_data_df=pd.read_excel(\"data/gameTranindata.xlsx\",dtype=float)\n",
    "\n",
    "X_training=tranining_data_df.drop('total_earnings',axis=1).values\n",
    "Y_training=tranining_data_df[['total_earnings']].values\n",
    "\n",
    "\n",
    "test_data_df=pd.read_excel(\"data/gameTestdata.xlsx\",dtype=float)\n",
    "\n",
    "X_testing=test_data_df.drop('total_earnings',axis=1).values\n",
    "Y_testing=test_data_df[['total_earnings']].values\n",
    "\n",
    "#all data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "X_scaler=MinMaxScaler(feature_range=(0,1))#使每个feaure值在0到1之间\n",
    "Y_scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "#sacle both the training inputs and outputs\n",
    "X_scaled_training=X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training=Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# \n",
    "X_scaled_testing=X_scaler.transform(X_testing)\n",
    "Y_scaled_testing=Y_scaler.transform(Y_testing)\n",
    "\n",
    "print(X_scaled_testing.shape)\n",
    "print(Y_scaled_testing.shape)\n",
    "print(\"note:Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0],Y_scaler.min_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "#model.py\n",
    "# define model parameters\n",
    "learning_rate=0.001 #学习率\n",
    "training_epochs=100 # 迭代次数\n",
    "display_step=5 #每5次迭代展示一次\n",
    "\n",
    "#define how many inputs and outputs are in our neural network\n",
    "number_of_inputs=9\n",
    "number_of_outputs=1\n",
    "\n",
    "#define how many neurons we want in each layer of our neural network\n",
    "layer_1_nodes=50\n",
    "layer_2_nodes=100\n",
    "layer_3_nodes=50\n",
    "\n",
    "\n",
    "#section one: define the layers of the neural network itself\n",
    "\n",
    "#input layer\n",
    "with tf.variable_scope('input'):\n",
    "    X=tf.placeholder(tf.float32,shape=(None,number_of_inputs))\n",
    "\n",
    "#layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights=tf.get_variable(name=\"weights1\",shape=[number_of_inputs,layer_1_nodes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases=tf.get_variable(name=\"baiases1\",shape=[layer_1_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_1_output=tf.nn.relu(tf.matmul(X,weights)+biases)\n",
    "\n",
    "#layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights=tf.get_variable(name=\"weights2\",shape=[layer_1_nodes,layer_2_nodes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases=tf.get_variable(name=\"baiases2\",shape=[layer_2_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_2_output=tf.nn.relu(tf.matmul(layer_1_output,weights)+biases)\n",
    "    \n",
    "#layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights=tf.get_variable(name=\"weights3\",shape=[layer_2_nodes,layer_3_nodes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases=tf.get_variable(name=\"baiases3\",shape=[layer_3_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_3_output=tf.nn.relu(tf.matmul(layer_2_output,weights)+biases)\n",
    "\n",
    "\n",
    "#output layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights=tf.get_variable(name=\"weights4\",shape=[layer_3_nodes,number_of_outputs],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases=tf.get_variable(name=\"baiases4\",shape=[number_of_outputs],initializer=tf.zeros_initializer())\n",
    "    prediction=tf.nn.relu(tf.matmul(layer_3_output,weights)+biases)\n",
    "\n",
    "#section two: define the cost function of the neural network that will measure prediction\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y=tf.placeholder(tf.float32,shape=(None,1))\n",
    "    cost=tf.reduce_mean(tf.squared_difference(prediction,Y))\n",
    "    \n",
    "#section three: define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#'''使用tensorboard 展示数据. 1、保持日志文件 2、使用tensorboard  图标展示日志文件 \n",
    "#    3、程序执行完后,在终端执行:tensorboard 把生成的链接贴到浏览器中查看'''\n",
    "\n",
    "# create a summary operation to log the progress of the network\n",
    "# with tf.variable_scope('logging'):\n",
    "#     tf.summary.scalar('current_cost',cost)\n",
    "#     summary=tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.270431 0.272129\n",
      "5 0.100326 0.0996455\n",
      "10 0.119588 0.11819\n",
      "15 0.0933929 0.0927999\n",
      "20 0.0971223 0.0967862\n",
      "25 0.0921832 0.0916579\n",
      "30 0.0893359 0.0886045\n",
      "35 0.0896593 0.0889946\n",
      "40 0.0875677 0.0871659\n",
      "45 0.0876617 0.0874575\n",
      "50 0.0867465 0.086623\n",
      "55 0.0865773 0.0865123\n",
      "60 0.0860007 0.0860662\n",
      "65 0.0857365 0.085927\n",
      "70 0.0853411 0.0856331\n",
      "75 0.0850475 0.0854885\n",
      "80 0.084719 0.085359\n",
      "85 0.0844274 0.0852553\n",
      "90 0.0841628 0.0851786\n",
      "95 0.0839262 0.0851104\n",
      "training is complete\n",
      "finanl traing cost:0.08375921845436096\n",
      "final testing cost:0.08507178723812103\n"
     ]
    }
   ],
   "source": [
    "# training_loop.py 内容包括接上面model.py\n",
    "\n",
    "#'''使用tensorboard 展示数据. 1、保持日志文件 2、使用tensorboard  图标展示日志文件 \n",
    "#    3、程序执行完后,在终端执行:tensorboard 把生成的链接贴到浏览器中查看'''\n",
    "# create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost',cost)\n",
    "    summary=tf.summary.merge_all()\n",
    "    \n",
    "#initialize a session so that we can run tensorflow  operations\n",
    "with tf.Session() as session:\n",
    "    #run the global variable initializer to initialize all variables and layers of\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #create log file writers to record training progress.\n",
    "    #we'll store training and testing log data separately\n",
    "    training_writer=tf.summary.FileWriter(\"data/logs/training\",session.graph)\n",
    "    testing_writer=tf.summary.FileWriter(\"data/logs/testing\",session.graph)\n",
    "    \n",
    "    \n",
    "    #run the optimizer over and over to train the network\n",
    "    #one epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        #feed in the training data and do one step of neural network tranining\n",
    "        session.run(optimizer,feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "        \n",
    "        #print the current training status to the screen\n",
    "#         print(\"training pass:{}\".format(epoch))\n",
    "        \n",
    "        #every 5 training steps,log our progress\n",
    "        if epoch % 5 ==0:\n",
    "            training_cost,training_summary=session.run([cost,summary],feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "            testing_cost,testing_summary=session.run([cost,summary],feed_dict={X:X_scaled_testing,Y:Y_scaled_testing})\n",
    "            \n",
    "            #write the current training staus to the log files(which we can visai)\n",
    "            training_writer.add_summary(training_summary,epoch)\n",
    "            testing_writer.add_summary(testing_summary,epoch)\n",
    "            \n",
    "            print(epoch,training_cost,testing_cost)\n",
    "            \n",
    "            \n",
    "    #training is now complete!\n",
    "    print(\"training is complete\")\n",
    "    \n",
    "    #print the last traning_cost and testing_cost\n",
    "    final_training_cost=session.run(cost,feed_dict={X:X_scaled_training,Y:Y_scaled_training})\n",
    "    final_testing_cost=session.run(cost,feed_dict={X:X_scaled_testing,Y:Y_scaled_testing})\n",
    "    \n",
    "    print(\"finanl traing cost:{}\".format(final_training_cost))\n",
    "    print(\"final testing cost:{}\".format(final_testing_cost))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用tensorboard 展示数据. 1、保持日志文件 2、使用tensorboard  图标展示日志文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.19852506  1.71705731  1.10382514  1.52350191]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "col=np.random.rand(0,2,5)\n",
    "p=np.random.uniform(0,2,4)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow tutorials--MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute 'main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dbdf77239414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#our application logic will be added here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute 'main'"
     ]
    }
   ],
   "source": [
    "# set up the skeleton for our tensorflwo program\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "#our application logic will be added here\n",
    "if __name__==\"__main__\":\n",
    "    tf.app.run()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-4b0ef73f57db>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-4b0ef73f57db>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    padding=\"same\",\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def cnn_model_fn(features,labels,mode):\n",
    "    \"\"\"model function for cnn.\"\"\"\n",
    "    #input layer\n",
    "    input_layer=tf.reshape(features[\"x\"],[-1,28,28,1])\n",
    "    \n",
    "    #convolutional layer #1\n",
    "    conv1=tf.layers.comv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,  #?????什么意思?\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #pooling layer #1\n",
    "    pool1=tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],stides=2)#what are the means of arguments?\n",
    "    \n",
    "    #convolutional layer #2 and pooling layer #2\n",
    "    conv2=tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5,5]\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2=tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2)\n",
    "    \n",
    "    #dense layer\n",
    "    pool2_flat=tf.reshape(pool2,[-1,7*7*64])\n",
    "    dense=tf.layers.dense(inputs=pool2_flat,units=1024,activation=tf.nn.relu)\n",
    "    dropout=tf.layers.dropout(inputs=dense,rate=0.4,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    #logits layer\n",
    "    logits=tf.layers.dense(inputs=dropput,units=10)\n",
    "    \n",
    "    predictions={\n",
    "        #generrate predictions(for PREDICT and EVAL mode)\n",
    "        \"class\":tf.argmax(input=logits,axis=1)\n",
    "        #add 'softmax_tensor' to the graph.it is used for PREDICT and by the  logging_hook\n",
    "        \"probabilities\":tf.nn.softmax(logits,name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode==tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)\n",
    "    \n",
    "    #calculate loss (for both train and eval modes)\n",
    "    loss=tf.losses.spare_softmax_cross_entropy(labels=labels,logits=logits)\n",
    "    \n",
    "    #configure the training op(for train mode)\n",
    "    if mode=tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op=optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,loss=loss,train_op=train_op)\n",
    "    \n",
    "    #add evaluation metrics(for eval mode)\n",
    "    eval_metric_ops={\"accuracy\":tf.metrics.accuracy(labels=labels,predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,loss=loss,eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "def main(unused_argv):\n",
    "    #load training and eval data\n",
    "    mnist=tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data=minist.train.images#returns np.array\n",
    "    train_labels=np.asarray(minist.train.labels,dtype=np.int32)\n",
    "    eval_data=mnist.test.images#returns np.array\n",
    "    eval_labels=np.asarray(mnist.test.labels,dtype=np.int32)\n",
    " \n",
    "\n",
    "#create the estimator\n",
    "mnist_classifier=tf.estimator.Estimator(model_fn=cnn_model_fn,model_dir=\"data/modes/mnist_convet_model\")\n",
    "\n",
    "#set up logging for predictions\n",
    "tensors_to_log={\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "#train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=20000,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "\n",
    "#evaluate the model and print results\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-aa083ac3af30>:120: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/four/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x181dbb5160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.09159087  0.10853945  0.10612378  0.10294334  0.09788223  0.08723353\n",
      "   0.10447243  0.09259229  0.10463656  0.10398556]\n",
      " [ 0.09960701  0.10438505  0.11134908  0.10148304  0.098099    0.09532498\n",
      "   0.08833025  0.09027442  0.10849435  0.1026528 ]\n",
      " [ 0.09580486  0.10040106  0.10573372  0.09688298  0.10308225  0.09613252\n",
      "   0.10053393  0.08710782  0.10292479  0.1113961 ]\n",
      " [ 0.09353602  0.10049186  0.11092947  0.09371085  0.10736536  0.08928324\n",
      "   0.09428304  0.10611203  0.10305443  0.10123366]\n",
      " [ 0.09810295  0.10638459  0.11528621  0.09293118  0.1080321   0.09112791\n",
      "   0.0835828   0.08757606  0.11423416  0.10274208]\n",
      " [ 0.08677518  0.09929691  0.10563153  0.09311245  0.13255718  0.09934928\n",
      "   0.0864765   0.09306013  0.10639033  0.09735049]\n",
      " [ 0.10714216  0.10745619  0.10640433  0.09891431  0.10425773  0.09879873\n",
      "   0.0905145   0.09339289  0.09668814  0.09643104]\n",
      " [ 0.09258009  0.11488137  0.11819571  0.09649842  0.10451611  0.09533975\n",
      "   0.08833248  0.09535126  0.09584453  0.09846026]\n",
      " [ 0.10232262  0.09662696  0.10028753  0.10446912  0.107575    0.08861479\n",
      "   0.09922466  0.08069412  0.1134092   0.10677596]\n",
      " [ 0.10486797  0.10001931  0.10106228  0.09837936  0.10281087  0.10722945\n",
      "   0.09505217  0.08980426  0.10549487  0.09527946]\n",
      " [ 0.10228197  0.11742032  0.10400083  0.09108208  0.10702199  0.0884956\n",
      "   0.09662262  0.08851669  0.09685736  0.10770053]\n",
      " [ 0.09834863  0.09345321  0.11059628  0.10209038  0.11263365  0.09839895\n",
      "   0.10101256  0.08387583  0.09252368  0.10706679]\n",
      " [ 0.09918829  0.1021886   0.10693576  0.09189517  0.10801875  0.09327823\n",
      "   0.1009924   0.10481232  0.09815043  0.09454007]\n",
      " [ 0.10220883  0.10580516  0.10432246  0.09477725  0.09653654  0.09408321\n",
      "   0.0850849   0.10589347  0.10503263  0.10625558]\n",
      " [ 0.08889475  0.10962068  0.10785938  0.08477551  0.09710913  0.11429733\n",
      "   0.09405687  0.09085406  0.11840578  0.09412657]\n",
      " [ 0.09420746  0.10842078  0.11581837  0.09995461  0.09798001  0.0978056\n",
      "   0.09607086  0.0937669   0.09656966  0.09940577]\n",
      " [ 0.09621856  0.10256933  0.1073629   0.10082291  0.09770697  0.09627662\n",
      "   0.09886047  0.08739439  0.1072558   0.10553202]\n",
      " [ 0.0989651   0.0948287   0.12053455  0.10129984  0.1087322   0.09044601\n",
      "   0.09077395  0.09000865  0.09945133  0.10495967]\n",
      " [ 0.11234672  0.10561335  0.10810425  0.09307832  0.10412154  0.09186126\n",
      "   0.09210552  0.08883586  0.09897079  0.10496241]\n",
      " [ 0.10130893  0.08645449  0.11589677  0.09511231  0.10311172  0.10505921\n",
      "   0.09480727  0.10025643  0.10946216  0.08853079]\n",
      " [ 0.0937945   0.09245752  0.1232992   0.11283467  0.08850162  0.08298192\n",
      "   0.09965555  0.08677327  0.10408478  0.11561695]\n",
      " [ 0.10155935  0.11544719  0.12440065  0.09615899  0.08985294  0.08004878\n",
      "   0.09969094  0.08310335  0.1055109   0.10422686]\n",
      " [ 0.10403957  0.10867193  0.11796364  0.0863423   0.11325427  0.08729517\n",
      "   0.08313238  0.09714666  0.10508108  0.09707297]\n",
      " [ 0.10326415  0.10497668  0.10528765  0.09096364  0.09429767  0.10956158\n",
      "   0.09482942  0.09672387  0.10263517  0.09746008]\n",
      " [ 0.10398857  0.09977837  0.11230458  0.09592564  0.1136656   0.08679377\n",
      "   0.09337996  0.09095073  0.10813681  0.09507596]\n",
      " [ 0.09760227  0.09047572  0.11633477  0.09552421  0.11247593  0.0899369\n",
      "   0.09554048  0.09307303  0.10379536  0.10524128]\n",
      " [ 0.10422121  0.09943891  0.11418606  0.09339967  0.11092196  0.10016531\n",
      "   0.08401932  0.08476096  0.10223986  0.10664682]\n",
      " [ 0.10420816  0.09812596  0.11014988  0.08939163  0.10646962  0.09926834\n",
      "   0.09622135  0.08996336  0.10239296  0.10380881]\n",
      " [ 0.10475401  0.08551479  0.12564072  0.09827184  0.1030977   0.09903154\n",
      "   0.08381096  0.090793    0.10529272  0.10379273]\n",
      " [ 0.08886018  0.09059849  0.11657627  0.09428874  0.10587604  0.09458008\n",
      "   0.09612348  0.10347347  0.10558535  0.10403794]\n",
      " [ 0.10234085  0.10389256  0.10384812  0.09128978  0.10701813  0.09391004\n",
      "   0.08530603  0.0844242   0.11454484  0.11342537]\n",
      " [ 0.0951357   0.09914134  0.11151468  0.09726916  0.11589389  0.11082079\n",
      "   0.08953819  0.08896814  0.10374077  0.08797734]\n",
      " [ 0.09738608  0.10864144  0.10147732  0.09653253  0.10432476  0.10270481\n",
      "   0.09769171  0.08462442  0.10627539  0.10034148]\n",
      " [ 0.10007906  0.10424305  0.11314999  0.09908393  0.09924523  0.09223782\n",
      "   0.0907728   0.09818635  0.10405323  0.09894853]\n",
      " [ 0.09011367  0.09668737  0.11309292  0.09416182  0.11210777  0.09491095\n",
      "   0.09492961  0.09123182  0.10428944  0.1084746 ]\n",
      " [ 0.09342843  0.09938665  0.10982608  0.09444951  0.11416804  0.10235979\n",
      "   0.08866753  0.09139919  0.10451584  0.10179902]\n",
      " [ 0.09974162  0.09890006  0.10742296  0.10171943  0.10006873  0.09976307\n",
      "   0.09651064  0.08743493  0.09650828  0.1119303 ]\n",
      " [ 0.1081532   0.09822561  0.11692892  0.09304143  0.10757354  0.09900573\n",
      "   0.09430186  0.09291839  0.09138887  0.09846236]\n",
      " [ 0.08854331  0.11417808  0.10499614  0.09195172  0.0944095   0.10091823\n",
      "   0.09944481  0.09936517  0.10512446  0.10106858]\n",
      " [ 0.10589329  0.10291807  0.10288924  0.08612671  0.11648413  0.09779555\n",
      "   0.10411546  0.09962622  0.08613996  0.09801136]\n",
      " [ 0.10969743  0.10170979  0.10368643  0.09677477  0.10158348  0.09120164\n",
      "   0.10652232  0.08573711  0.09840289  0.10468413]\n",
      " [ 0.10895837  0.10369133  0.0997962   0.09382393  0.10937868  0.0934769\n",
      "   0.10363913  0.08591574  0.10062281  0.10069695]\n",
      " [ 0.10181079  0.10281788  0.11051162  0.09357034  0.099418    0.09464489\n",
      "   0.09458974  0.08760774  0.10667214  0.10835676]\n",
      " [ 0.10901359  0.09348714  0.10505387  0.08879977  0.1064956   0.08565997\n",
      "   0.1068888   0.0777491   0.11784312  0.10900907]\n",
      " [ 0.09279092  0.08998232  0.10998155  0.10133013  0.11476025  0.09506588\n",
      "   0.0893866   0.09467421  0.10594154  0.10608652]\n",
      " [ 0.09835418  0.09980662  0.10920059  0.09402248  0.11656213  0.09261861\n",
      "   0.09282058  0.10189331  0.09032164  0.10439984]\n",
      " [ 0.10197058  0.10088608  0.10333908  0.0977835   0.10204035  0.09218043\n",
      "   0.0814675   0.09793242  0.10837483  0.11402518]\n",
      " [ 0.09137817  0.10247736  0.10461615  0.10156313  0.11261169  0.1004588\n",
      "   0.08844022  0.09298377  0.09831415  0.10715651]\n",
      " [ 0.09280293  0.10305126  0.11129174  0.09283024  0.10511556  0.09534151\n",
      "   0.09623855  0.10098732  0.10125843  0.10108244]\n",
      " [ 0.0901022   0.09408644  0.10995582  0.09142759  0.10471532  0.09285097\n",
      "   0.09113253  0.09260716  0.119149    0.11397302]\n",
      " [ 0.09448687  0.10091079  0.11769016  0.09782101  0.10524022  0.0958275\n",
      "   0.1007803   0.08435468  0.1003442   0.10254437]\n",
      " [ 0.09548443  0.108372    0.10621145  0.09977112  0.09609204  0.10438294\n",
      "   0.09317043  0.09112893  0.09334061  0.11204603]\n",
      " [ 0.09755303  0.10137574  0.10610642  0.08595068  0.09662614  0.09870601\n",
      "   0.09997895  0.10077645  0.10800021  0.10492641]\n",
      " [ 0.09801763  0.09777872  0.10610507  0.09955462  0.11432728  0.09484983\n",
      "   0.0946089   0.10610947  0.09177793  0.09687058]\n",
      " [ 0.0934769   0.09303667  0.11704028  0.09782169  0.0981217   0.10036802\n",
      "   0.0966      0.09350309  0.09762799  0.11240362]\n",
      " [ 0.09599382  0.09738755  0.11621699  0.09454034  0.11975158  0.09893005\n",
      "   0.09929238  0.0911935   0.09173357  0.09496012]\n",
      " [ 0.09735592  0.09618267  0.11582797  0.10935881  0.09585741  0.09540898\n",
      "   0.08985281  0.09633893  0.10835718  0.09545934]\n",
      " [ 0.09158012  0.09214319  0.11953937  0.09578862  0.09727607  0.09666944\n",
      "   0.09748442  0.09150369  0.10253315  0.11548191]\n",
      " [ 0.10197116  0.10546812  0.11235654  0.09256988  0.10837572  0.09092218\n",
      "   0.10612199  0.0940053   0.09870406  0.08950508]\n",
      " [ 0.09996814  0.10707534  0.10575514  0.09740318  0.0942804   0.09973176\n",
      "   0.09323945  0.10872514  0.09894905  0.09487237]\n",
      " [ 0.10720536  0.10279046  0.10621011  0.09695683  0.11087886  0.09741571\n",
      "   0.09688386  0.08828118  0.09990244  0.09347516]\n",
      " [ 0.09292965  0.09955016  0.11104059  0.09452274  0.10391167  0.09531569\n",
      "   0.08886985  0.08599612  0.10441294  0.12345053]\n",
      " [ 0.09548765  0.10084487  0.09877478  0.09281329  0.10401664  0.10401405\n",
      "   0.10271639  0.09747418  0.09999294  0.10386522]\n",
      " [ 0.08704869  0.10782745  0.11242907  0.08780154  0.10620374  0.104366\n",
      "   0.09393112  0.09721937  0.10178491  0.10138808]\n",
      " [ 0.0937847   0.10084514  0.10675447  0.09052026  0.10550641  0.0951905\n",
      "   0.09133121  0.10247776  0.11190595  0.1016836 ]\n",
      " [ 0.1003162   0.09550059  0.1145277   0.10095681  0.09441464  0.09205785\n",
      "   0.08743296  0.09148894  0.11547232  0.10783202]\n",
      " [ 0.10275793  0.10709348  0.11708518  0.09356122  0.09698033  0.09239763\n",
      "   0.0974653   0.09245329  0.09988264  0.10032295]\n",
      " [ 0.09179708  0.10222048  0.10106625  0.08469011  0.11765251  0.10934497\n",
      "   0.08573022  0.10234714  0.10527428  0.09987693]\n",
      " [ 0.09481858  0.0927422   0.10502501  0.1001182   0.11178728  0.09442555\n",
      "   0.09856049  0.0976622   0.10370285  0.10115763]\n",
      " [ 0.09074886  0.09943376  0.11704008  0.09769207  0.09436534  0.0949538\n",
      "   0.10175604  0.09294256  0.10288212  0.10818545]\n",
      " [ 0.08576649  0.09569262  0.12027135  0.11058155  0.10742433  0.08375617\n",
      "   0.09649182  0.0834657   0.10156291  0.11498708]\n",
      " [ 0.10189523  0.09805162  0.10752922  0.09897476  0.09405192  0.09891035\n",
      "   0.09532931  0.09269045  0.11090642  0.10166062]\n",
      " [ 0.0968884   0.10304028  0.10608522  0.08690868  0.09544095  0.10065142\n",
      "   0.0961855   0.09854389  0.10216871  0.1140869 ]\n",
      " [ 0.108753    0.11546349  0.10934931  0.0970825   0.0913661   0.09791676\n",
      "   0.08327937  0.08776511  0.10269159  0.10633285]\n",
      " [ 0.10304551  0.09452007  0.1115298   0.09722283  0.10072644  0.08466099\n",
      "   0.08967881  0.09589814  0.10774692  0.11497045]\n",
      " [ 0.09010101  0.10420567  0.09933816  0.08521135  0.11533941  0.09573668\n",
      "   0.0883359   0.08890462  0.1240975   0.10872965]\n",
      " [ 0.10291213  0.09877434  0.11607366  0.09457953  0.10659271  0.09988643\n",
      "   0.08831537  0.09441374  0.09862415  0.09982789]\n",
      " [ 0.09773563  0.09666332  0.10185561  0.09928403  0.10334296  0.09689763\n",
      "   0.09398838  0.09365682  0.11006372  0.10651182]\n",
      " [ 0.1037815   0.0964826   0.11083768  0.09411682  0.11029989  0.09966524\n",
      "   0.09613544  0.08640411  0.10579511  0.09648167]\n",
      " [ 0.09471274  0.10022005  0.10824241  0.095479    0.11078311  0.09774084\n",
      "   0.09030347  0.08789745  0.11241498  0.10220597]\n",
      " [ 0.10719199  0.10709486  0.10779201  0.09757499  0.10702106  0.08938204\n",
      "   0.09829097  0.0934809   0.09981149  0.09235965]\n",
      " [ 0.11065998  0.09274824  0.09868857  0.10177156  0.10402421  0.0987365\n",
      "   0.1104493   0.08598927  0.09779215  0.0991402 ]\n",
      " [ 0.0993818   0.10396262  0.10393871  0.10087579  0.10981853  0.09307815\n",
      "   0.09768345  0.09447757  0.104035    0.09274837]\n",
      " [ 0.0896629   0.10591445  0.11659471  0.08931638  0.09840813  0.10381208\n",
      "   0.09254882  0.09455469  0.10405401  0.1051338 ]\n",
      " [ 0.09639476  0.09623106  0.1138755   0.10658421  0.10046136  0.09624827\n",
      "   0.10118256  0.09071045  0.09985772  0.09845408]\n",
      " [ 0.09196116  0.10152083  0.1291302   0.093439    0.11177686  0.09409613\n",
      "   0.09283787  0.09203884  0.09966619  0.09353279]\n",
      " [ 0.10774808  0.1007375   0.10778469  0.09731852  0.10958529  0.09402406\n",
      "   0.09668639  0.08579262  0.10060728  0.09971561]\n",
      " [ 0.08453297  0.10251645  0.10796642  0.10266586  0.11244087  0.10104144\n",
      "   0.09401133  0.09206245  0.10657242  0.09618978]\n",
      " [ 0.10570896  0.10681642  0.11743879  0.08984507  0.10380548  0.09950277\n",
      "   0.10049834  0.08929512  0.09060776  0.09648123]\n",
      " [ 0.1061243   0.10243206  0.10700523  0.08865058  0.09495958  0.09656806\n",
      "   0.09474222  0.0957415   0.11466098  0.09911551]\n",
      " [ 0.09414102  0.10781052  0.11141752  0.09056077  0.10336222  0.10108738\n",
      "   0.08776805  0.09803388  0.10377242  0.10204615]\n",
      " [ 0.09501366  0.09400261  0.11391055  0.10105499  0.1000096   0.09412545\n",
      "   0.09472847  0.0837178   0.09901527  0.12442166]\n",
      " [ 0.09473476  0.10462642  0.11288141  0.10065719  0.09926479  0.10716473\n",
      "   0.08523631  0.08524363  0.1080429   0.10214792]\n",
      " [ 0.09605821  0.10258186  0.10814085  0.103143    0.10708919  0.09482046\n",
      "   0.08786843  0.09213151  0.11148936  0.09667712]\n",
      " [ 0.10609575  0.09797552  0.10732006  0.09769432  0.09815389  0.09983119\n",
      "   0.10007669  0.09473716  0.1029645   0.09515096]\n",
      " [ 0.09805357  0.10424221  0.1046708   0.09176114  0.10460579  0.10091798\n",
      "   0.09273964  0.10390132  0.0940537   0.10505378]\n",
      " [ 0.09393354  0.10581814  0.10321423  0.09742276  0.10438628  0.09759916\n",
      "   0.09539063  0.09205472  0.10376566  0.10641491]\n",
      " [ 0.09840557  0.09882211  0.11783305  0.08824387  0.10418986  0.10892116\n",
      "   0.08793855  0.09142999  0.10469023  0.09952568]\n",
      " [ 0.10170864  0.1084298   0.10822856  0.08725575  0.1035702   0.09460818\n",
      "   0.09984647  0.09575079  0.1008968   0.09970483]\n",
      " [ 0.1011615   0.11307416  0.11586321  0.09235616  0.10895917  0.09493207\n",
      "   0.09782646  0.08183215  0.09176187  0.10223325]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.32599, step = 1\n",
      "INFO:tensorflow:probabilities = [[ 0.10343225  0.10163384  0.11327754  0.10177872  0.0977136   0.09289385\n",
      "   0.09844957  0.09769947  0.09884666  0.09427448]\n",
      " [ 0.10921008  0.10191244  0.10802146  0.08844501  0.1020833   0.0979012\n",
      "   0.09656551  0.0928885   0.10596535  0.09700713]\n",
      " [ 0.09931476  0.09868395  0.1036617   0.09707054  0.10745269  0.09423973\n",
      "   0.09069649  0.09370019  0.10882764  0.10635229]\n",
      " [ 0.09353085  0.1048191   0.11077613  0.0915764   0.10756812  0.10659175\n",
      "   0.09401757  0.09307634  0.09419398  0.10384975]\n",
      " [ 0.1066525   0.09443699  0.1089616   0.10210783  0.0957534   0.0949548\n",
      "   0.09893067  0.1042232   0.08653004  0.10744899]\n",
      " [ 0.10274138  0.10208233  0.11165892  0.09135567  0.10096519  0.09665567\n",
      "   0.09696421  0.09040077  0.10470323  0.10247259]\n",
      " [ 0.10598424  0.09835371  0.12679373  0.08787375  0.0928613   0.08984052\n",
      "   0.09344871  0.09176563  0.10039295  0.11268544]\n",
      " [ 0.0950854   0.0959961   0.11586347  0.09069628  0.09377217  0.09580227\n",
      "   0.09787461  0.09898996  0.10963324  0.10628645]\n",
      " [ 0.10648692  0.09692575  0.1180675   0.09547351  0.10268266  0.09475578\n",
      "   0.10206306  0.08607832  0.10220095  0.09526557]\n",
      " [ 0.09362746  0.10626136  0.12057131  0.09252388  0.11748099  0.0848313\n",
      "   0.08782808  0.08599237  0.10321828  0.10766499]\n",
      " [ 0.10631961  0.10138134  0.10538843  0.08794611  0.11017427  0.10142411\n",
      "   0.07727306  0.09641018  0.10533088  0.10835203]\n",
      " [ 0.10881533  0.10609412  0.10289881  0.10722838  0.10930579  0.08815321\n",
      "   0.0844641   0.08743987  0.10255378  0.10304659]\n",
      " [ 0.10008523  0.10105022  0.11690826  0.09069153  0.10785515  0.09249995\n",
      "   0.09609842  0.08994157  0.10190973  0.10295998]\n",
      " [ 0.10015484  0.10531098  0.1125109   0.10724782  0.09775877  0.09390433\n",
      "   0.1014007   0.08684938  0.09170605  0.10315622]\n",
      " [ 0.0964558   0.09597179  0.10987203  0.10454529  0.10052063  0.09331129\n",
      "   0.08802684  0.09239714  0.11150015  0.10739904]\n",
      " [ 0.08964643  0.10145675  0.1076271   0.1013964   0.10887742  0.0934937\n",
      "   0.09585181  0.09517972  0.10589417  0.10057643]\n",
      " [ 0.09219092  0.10473554  0.10936911  0.09558024  0.11078402  0.0977071\n",
      "   0.09495403  0.09809558  0.09253929  0.10404424]\n",
      " [ 0.10773526  0.11053714  0.10631903  0.09366358  0.10080217  0.09365464\n",
      "   0.09064464  0.09338167  0.09550249  0.10775935]\n",
      " [ 0.09955765  0.09746744  0.10835145  0.0942939   0.11040854  0.08806513\n",
      "   0.09603546  0.09141333  0.10769832  0.10670877]\n",
      " [ 0.11332771  0.0990006   0.10691242  0.10904116  0.10797217  0.10272327\n",
      "   0.0862873   0.08825846  0.09892803  0.08754882]\n",
      " [ 0.09412262  0.11156741  0.11150848  0.09279421  0.10229748  0.10187332\n",
      "   0.09074921  0.09984634  0.09581825  0.09942272]\n",
      " [ 0.10400657  0.09606223  0.11883341  0.09977709  0.09542787  0.08931586\n",
      "   0.08825264  0.08953956  0.10073704  0.11804775]\n",
      " [ 0.09029534  0.10517552  0.10448012  0.09197181  0.10337408  0.09894683\n",
      "   0.09730076  0.09587117  0.11179493  0.1007894 ]\n",
      " [ 0.09608141  0.10425127  0.12499982  0.09059321  0.09624991  0.09313915\n",
      "   0.07906735  0.09319162  0.12293539  0.09949089]\n",
      " [ 0.09528398  0.09993848  0.11254032  0.09125886  0.09986967  0.09649401\n",
      "   0.09179023  0.10405379  0.11154107  0.09722964]\n",
      " [ 0.10573722  0.09750532  0.1180953   0.10358149  0.09839011  0.09723486\n",
      "   0.09011153  0.08831654  0.10150126  0.09952636]\n",
      " [ 0.11606803  0.10090768  0.11058098  0.09326863  0.09853376  0.10027133\n",
      "   0.07752633  0.10088954  0.1013702   0.10058353]\n",
      " [ 0.10479474  0.10134531  0.10553796  0.09744815  0.10468038  0.08860029\n",
      "   0.09534273  0.09738191  0.09997643  0.10489212]\n",
      " [ 0.1012477   0.09367489  0.104281    0.09230671  0.1113326   0.09619625\n",
      "   0.09889669  0.10137071  0.10269157  0.0980019 ]\n",
      " [ 0.10281499  0.10444116  0.12183639  0.09474731  0.10363802  0.09828421\n",
      "   0.09287734  0.09755813  0.07990941  0.10389312]\n",
      " [ 0.09784617  0.11266918  0.10373686  0.08954777  0.08732592  0.10612783\n",
      "   0.08858913  0.1060395   0.1137144   0.09440327]\n",
      " [ 0.10510901  0.10573224  0.11139331  0.09491471  0.10816135  0.09520882\n",
      "   0.08663093  0.08994475  0.10168944  0.10121544]\n",
      " [ 0.10024416  0.09624521  0.10726285  0.09407372  0.1140543   0.09086574\n",
      "   0.09503474  0.0879172   0.1008397   0.11346231]\n",
      " [ 0.08631936  0.10272485  0.09137706  0.10898142  0.10571134  0.08909569\n",
      "   0.09794651  0.10582633  0.10454315  0.1074743 ]\n",
      " [ 0.09970988  0.09942344  0.10709611  0.09585399  0.10445073  0.08874241\n",
      "   0.09451474  0.09571867  0.10081978  0.11367018]\n",
      " [ 0.10695034  0.10131309  0.11600126  0.08883338  0.10555121  0.09323446\n",
      "   0.10049188  0.09353192  0.09288015  0.10121232]\n",
      " [ 0.10949301  0.09811117  0.12002892  0.10182375  0.09271648  0.0881554\n",
      "   0.08893715  0.09247852  0.09897897  0.10927666]\n",
      " [ 0.09963321  0.10097264  0.11688293  0.09343293  0.09252735  0.09868383\n",
      "   0.09591894  0.10829846  0.10196391  0.09168586]\n",
      " [ 0.10527802  0.10237616  0.10788693  0.09296262  0.09582342  0.09530634\n",
      "   0.09313147  0.0992989   0.10675742  0.10117866]\n",
      " [ 0.10820036  0.09762283  0.10957198  0.09966151  0.10131638  0.08615739\n",
      "   0.10004883  0.08872055  0.10346601  0.10523414]\n",
      " [ 0.09615017  0.1027094   0.11246835  0.08530971  0.11688147  0.10134735\n",
      "   0.09101787  0.08446674  0.10192577  0.10772321]\n",
      " [ 0.09822785  0.09514895  0.11965708  0.09831077  0.1002586   0.09579524\n",
      "   0.10166366  0.08647829  0.09567574  0.10878386]\n",
      " [ 0.10370726  0.10126405  0.1206075   0.09224486  0.09654795  0.09045888\n",
      "   0.09645785  0.09291828  0.10336323  0.10243009]\n",
      " [ 0.116675    0.10387471  0.11137135  0.08624311  0.09736658  0.09112591\n",
      "   0.10053416  0.08294845  0.10450049  0.1053602 ]\n",
      " [ 0.09400823  0.10635945  0.109184    0.09361359  0.1081209   0.09581957\n",
      "   0.10312275  0.09473496  0.10543501  0.08960161]\n",
      " [ 0.10194019  0.10753322  0.11277856  0.09427597  0.0947802   0.10050891\n",
      "   0.08825867  0.09512248  0.10752229  0.09727956]\n",
      " [ 0.09820058  0.10266764  0.11053139  0.09964581  0.09868567  0.10123806\n",
      "   0.08499976  0.10080039  0.10968573  0.09354503]\n",
      " [ 0.10173182  0.11213112  0.10189579  0.09359441  0.10764631  0.09722485\n",
      "   0.0898691   0.08795694  0.10636039  0.10158926]\n",
      " [ 0.11095033  0.10653736  0.11095066  0.09718695  0.09929595  0.09293641\n",
      "   0.09724318  0.07879935  0.10194322  0.10415655]\n",
      " [ 0.10346758  0.10710189  0.10933129  0.10582072  0.10697186  0.08428398\n",
      "   0.10271879  0.0793635   0.09528819  0.10565222]\n",
      " [ 0.10225233  0.09983121  0.10737209  0.09706347  0.10639309  0.08960965\n",
      "   0.09668002  0.09237026  0.09963936  0.10878852]\n",
      " [ 0.10490426  0.0961772   0.12060115  0.09571763  0.09968074  0.09223373\n",
      "   0.10583356  0.08891182  0.09957723  0.0963627 ]\n",
      " [ 0.10510562  0.1013845   0.11374044  0.1003947   0.10888569  0.09985992\n",
      "   0.09246668  0.08336962  0.10250036  0.09229244]\n",
      " [ 0.10402456  0.10855744  0.10368618  0.08928046  0.10696315  0.09902491\n",
      "   0.0936683   0.08949346  0.09771049  0.107591  ]\n",
      " [ 0.09038789  0.10476327  0.1053144   0.09300847  0.1027824   0.10061211\n",
      "   0.09436772  0.09969061  0.10467683  0.10439632]\n",
      " [ 0.08703291  0.10350755  0.10988322  0.10203845  0.10588767  0.08921886\n",
      "   0.09435157  0.10499933  0.09931462  0.10376577]\n",
      " [ 0.08804755  0.09702128  0.10679296  0.09725502  0.10161855  0.09758653\n",
      "   0.10290565  0.10235731  0.09963745  0.10677771]\n",
      " [ 0.08658472  0.10577793  0.10069272  0.09419969  0.1102566   0.09659765\n",
      "   0.09922643  0.1036286   0.09933419  0.10370155]\n",
      " [ 0.09543683  0.09462096  0.09866709  0.09297144  0.10599848  0.10314232\n",
      "   0.10510125  0.08976556  0.1070295   0.10726661]\n",
      " [ 0.09861655  0.09546378  0.10133211  0.09644563  0.10642892  0.09054106\n",
      "   0.09996614  0.09536454  0.10460409  0.11123718]\n",
      " [ 0.10493406  0.10536377  0.11413288  0.08518159  0.09512191  0.10454753\n",
      "   0.09476231  0.08756056  0.10637205  0.10202328]\n",
      " [ 0.08658202  0.10861623  0.10661636  0.10071763  0.10603189  0.10126945\n",
      "   0.09330863  0.09548157  0.10200028  0.0993759 ]\n",
      " [ 0.09832945  0.10054706  0.10031354  0.10049973  0.09872513  0.11771687\n",
      "   0.09220367  0.09105907  0.09746943  0.10313597]\n",
      " [ 0.09879231  0.08609941  0.10729234  0.09094327  0.10522605  0.1073048\n",
      "   0.10297072  0.09080812  0.10473812  0.10582487]\n",
      " [ 0.10342459  0.10219506  0.1081498   0.09994993  0.10231249  0.09518541\n",
      "   0.08501453  0.09422366  0.110264    0.09928048]\n",
      " [ 0.10358354  0.10071521  0.10387257  0.11096127  0.09638929  0.08527891\n",
      "   0.10126656  0.0918907   0.10186642  0.10417549]\n",
      " [ 0.09084447  0.09692714  0.11360251  0.10508935  0.11361905  0.09379793\n",
      "   0.09696753  0.08478581  0.10637876  0.09798747]\n",
      " [ 0.10210004  0.09388936  0.10166717  0.10070185  0.10062325  0.1029324\n",
      "   0.0895857   0.09652711  0.10458451  0.10738856]\n",
      " [ 0.09924353  0.09744766  0.110511    0.10142053  0.10141539  0.08175045\n",
      "   0.08866165  0.10187197  0.09600903  0.12166882]\n",
      " [ 0.09756859  0.10141693  0.11586312  0.09671136  0.10177752  0.09514066\n",
      "   0.09977832  0.08623537  0.09818612  0.10732195]\n",
      " [ 0.09308279  0.09817628  0.10705682  0.08649345  0.09594426  0.10078251\n",
      "   0.09453873  0.1033474   0.105602    0.1149758 ]\n",
      " [ 0.09358925  0.10381543  0.10971895  0.0956568   0.10426331  0.08855274\n",
      "   0.09780341  0.08702086  0.11684529  0.10273392]\n",
      " [ 0.08835101  0.09427275  0.11405744  0.09925754  0.10017958  0.09466832\n",
      "   0.0955868   0.09760064  0.10043246  0.11559342]\n",
      " [ 0.09452976  0.10726492  0.10072513  0.08804731  0.1087146   0.09312755\n",
      "   0.09692173  0.10055339  0.10923141  0.10088425]\n",
      " [ 0.09882597  0.09653536  0.09854114  0.09316225  0.10633857  0.09374538\n",
      "   0.08609255  0.10293287  0.10808139  0.11574457]\n",
      " [ 0.09472958  0.10342826  0.1057936   0.09852076  0.1129694   0.09517178\n",
      "   0.09574922  0.08167184  0.10488562  0.10707989]\n",
      " [ 0.10236285  0.10667149  0.11585099  0.10373091  0.10874201  0.09288602\n",
      "   0.08486298  0.08723637  0.09877849  0.0988779 ]\n",
      " [ 0.10304943  0.09867626  0.11593358  0.09595888  0.09743328  0.09240706\n",
      "   0.08760601  0.09686365  0.11286454  0.0992073 ]\n",
      " [ 0.09899708  0.1116393   0.10755202  0.10061017  0.09945082  0.10160017\n",
      "   0.08647821  0.09313139  0.10818527  0.09235556]\n",
      " [ 0.11584386  0.09784429  0.10922427  0.08993597  0.11193746  0.09439822\n",
      "   0.08918005  0.08992797  0.09346829  0.10823969]\n",
      " [ 0.09354156  0.11533196  0.10237163  0.09894808  0.11125586  0.09968614\n",
      "   0.09650544  0.08539642  0.10205104  0.09491184]\n",
      " [ 0.10879783  0.10494974  0.11753668  0.08931284  0.09555554  0.09450369\n",
      "   0.08624212  0.10119879  0.09917323  0.10272952]\n",
      " [ 0.10011477  0.10539528  0.11224394  0.09534431  0.11545607  0.09188961\n",
      "   0.09265853  0.09341665  0.09725104  0.0962298 ]\n",
      " [ 0.10475386  0.10416777  0.09936824  0.08725587  0.10008314  0.10120618\n",
      "   0.0960793   0.09905592  0.1109588   0.09707087]\n",
      " [ 0.10279649  0.10521004  0.1073879   0.0898081   0.0967511   0.09419496\n",
      "   0.09584299  0.08973759  0.10775192  0.11051891]\n",
      " [ 0.10243755  0.11809859  0.09721221  0.09685902  0.10686783  0.09667164\n",
      "   0.09184998  0.09477858  0.09827255  0.09695207]\n",
      " [ 0.09860282  0.09538692  0.10688439  0.11105825  0.09908754  0.09317761\n",
      "   0.09435614  0.09326341  0.10120002  0.10698296]\n",
      " [ 0.08956252  0.1021794   0.1132706   0.08651218  0.09682576  0.10511739\n",
      "   0.1023372   0.09103469  0.10571977  0.10744059]\n",
      " [ 0.10185217  0.09877191  0.10998759  0.0905128   0.11597709  0.08608855\n",
      "   0.09578737  0.08573997  0.11001881  0.10526372]\n",
      " [ 0.10068231  0.11062209  0.11803962  0.08836347  0.11131925  0.09221898\n",
      "   0.08723579  0.09211154  0.10338429  0.09602267]\n",
      " [ 0.10256848  0.11155463  0.10999382  0.09630843  0.09593835  0.09011442\n",
      "   0.08629602  0.09957524  0.11485828  0.09279236]\n",
      " [ 0.09793574  0.10381037  0.0995246   0.09868927  0.10869705  0.10002311\n",
      "   0.09723265  0.09416626  0.10320096  0.09671996]\n",
      " [ 0.10016372  0.10160013  0.11128327  0.09299123  0.09100798  0.09059998\n",
      "   0.09866674  0.0899839   0.11047928  0.11322382]\n",
      " [ 0.10241497  0.10283513  0.09462813  0.09403308  0.10452535  0.09715293\n",
      "   0.0897792   0.10927755  0.09686712  0.10848662]\n",
      " [ 0.10148056  0.11039556  0.10652595  0.10150892  0.09833376  0.09423193\n",
      "   0.09432069  0.09056395  0.10778502  0.09485366]\n",
      " [ 0.10316917  0.10178843  0.1047198   0.0992346   0.10051303  0.1032899\n",
      "   0.09844533  0.08548629  0.1009906   0.10236288]\n",
      " [ 0.09971699  0.0956813   0.10211477  0.10402683  0.10682429  0.09533819\n",
      "   0.09982073  0.09373506  0.10110562  0.10163622]\n",
      " [ 0.08884918  0.09605142  0.11281876  0.10603949  0.11524761  0.08825394\n",
      "   0.10206291  0.08780548  0.09830013  0.10457108]\n",
      " [ 0.09710408  0.10318403  0.11076837  0.09516407  0.10749903  0.09299252\n",
      "   0.08944823  0.08741381  0.11524842  0.10117741]\n",
      " [ 0.0954994   0.10825965  0.10598113  0.09494599  0.10201426  0.0948115\n",
      "   0.09874126  0.09177472  0.10337288  0.10459923]] (8.700 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.8696\n",
      "INFO:tensorflow:probabilities = [[ 0.10157643  0.1054237   0.10714445  0.09566553  0.10340902  0.0980543\n",
      "   0.09337593  0.09829812  0.09639454  0.10065794]\n",
      " [ 0.10587794  0.0947562   0.11018158  0.10147193  0.10185402  0.10036322\n",
      "   0.09432625  0.0934203   0.0983392   0.09940933]\n",
      " [ 0.09054609  0.10230929  0.11005872  0.10043325  0.10143561  0.09424527\n",
      "   0.09363911  0.0964144   0.10336784  0.10755049]\n",
      " [ 0.0872244   0.10502327  0.11371048  0.09729776  0.11506118  0.09448692\n",
      "   0.0935143   0.08613185  0.09646399  0.11108582]\n",
      " [ 0.1061219   0.1029824   0.11420835  0.08501456  0.09496055  0.10219406\n",
      "   0.08873724  0.09602097  0.10674134  0.1030186 ]\n",
      " [ 0.09540038  0.10227685  0.10827131  0.10097679  0.11299372  0.09415659\n",
      "   0.09842762  0.0944513   0.09798598  0.09505948]\n",
      " [ 0.09565299  0.10503683  0.1056259   0.10505375  0.11078946  0.08925487\n",
      "   0.0893999   0.09853391  0.09997965  0.10067269]\n",
      " [ 0.08911046  0.11086448  0.11007453  0.08448023  0.10059272  0.09726477\n",
      "   0.09135903  0.09145333  0.11352027  0.11128011]\n",
      " [ 0.09529745  0.11228082  0.1119958   0.08940357  0.10510932  0.09514838\n",
      "   0.10264731  0.08956389  0.09354328  0.10501014]\n",
      " [ 0.09011145  0.09487852  0.09804809  0.09729375  0.1099694   0.0935898\n",
      "   0.10703217  0.08887076  0.10584851  0.11435755]\n",
      " [ 0.09714957  0.10694893  0.10445123  0.08820458  0.10539233  0.09898581\n",
      "   0.09253549  0.10763701  0.10169923  0.09699581]\n",
      " [ 0.09607629  0.10550078  0.0941755   0.10007764  0.10544226  0.09922493\n",
      "   0.09163813  0.09230866  0.1067159   0.10883997]\n",
      " [ 0.10378316  0.10564113  0.11309163  0.08925608  0.09890853  0.09737673\n",
      "   0.09289414  0.09443343  0.09739939  0.1072158 ]\n",
      " [ 0.09348832  0.10725318  0.10366736  0.10633411  0.11030771  0.08564809\n",
      "   0.08383919  0.09527119  0.10723338  0.10695749]\n",
      " [ 0.0905728   0.09760157  0.11205851  0.10181501  0.10860825  0.0969382\n",
      "   0.09084544  0.09612495  0.09867664  0.10675868]\n",
      " [ 0.09400155  0.09382742  0.12227149  0.09285566  0.11596113  0.09042687\n",
      "   0.09628958  0.09102219  0.10359437  0.09974976]\n",
      " [ 0.10040099  0.10031855  0.1109871   0.09047727  0.10641187  0.10103465\n",
      "   0.1028772   0.07922622  0.10030247  0.10796362]\n",
      " [ 0.09827199  0.10088178  0.10775863  0.10160774  0.09677489  0.09964243\n",
      "   0.0925469   0.09538039  0.10130754  0.10582778]\n",
      " [ 0.11002742  0.09896347  0.10316689  0.08769484  0.10311801  0.10070801\n",
      "   0.10174692  0.09251032  0.1034987   0.09856553]\n",
      " [ 0.09933094  0.10446431  0.10414041  0.09505544  0.11385617  0.09919132\n",
      "   0.09767579  0.09210195  0.09888466  0.09529892]\n",
      " [ 0.10057131  0.10229275  0.12298907  0.09204181  0.09713764  0.0863474\n",
      "   0.09560126  0.08861563  0.10401714  0.11038602]\n",
      " [ 0.09499137  0.10016929  0.12218041  0.09113777  0.11588213  0.09699473\n",
      "   0.09229477  0.08696263  0.10703571  0.09235116]\n",
      " [ 0.09285949  0.09964083  0.10319383  0.09841975  0.1113461   0.09753644\n",
      "   0.09481035  0.09179957  0.11144685  0.09894683]\n",
      " [ 0.10610031  0.09749579  0.10543866  0.0970479   0.10672987  0.09684505\n",
      "   0.09588531  0.09313062  0.1092165   0.09210997]\n",
      " [ 0.09277464  0.09563947  0.09698375  0.09577916  0.09243666  0.09732594\n",
      "   0.10551447  0.09757949  0.11007328  0.11589318]\n",
      " [ 0.10906001  0.10603958  0.10956428  0.08766218  0.10501994  0.09510947\n",
      "   0.10034151  0.08783284  0.10035541  0.09901467]\n",
      " [ 0.10575947  0.09735407  0.11237528  0.09806046  0.10233805  0.09878396\n",
      "   0.09034685  0.09296869  0.10235126  0.09966188]\n",
      " [ 0.10630452  0.09334902  0.11272688  0.0922926   0.09885558  0.10231635\n",
      "   0.08909141  0.09136864  0.1072749   0.10642004]\n",
      " [ 0.1001945   0.1097627   0.10962812  0.09540234  0.09834055  0.0964499\n",
      "   0.09533775  0.09058225  0.10379237  0.10050949]\n",
      " [ 0.09761024  0.10342645  0.10222974  0.10124367  0.10699196  0.10074845\n",
      "   0.09686103  0.09202195  0.10503148  0.0938351 ]\n",
      " [ 0.10439309  0.09270826  0.10684393  0.10114206  0.1056003   0.10025576\n",
      "   0.09820332  0.09762547  0.0866942   0.10653361]\n",
      " [ 0.08967356  0.10356982  0.11820935  0.09453868  0.10369495  0.10354238\n",
      "   0.0978524   0.09494348  0.1002966   0.09367885]\n",
      " [ 0.10389983  0.10919532  0.10356477  0.10227456  0.0963094   0.10661216\n",
      "   0.08790287  0.09033933  0.09983949  0.10006232]\n",
      " [ 0.08662996  0.10189682  0.12242486  0.11134198  0.08579051  0.0954585\n",
      "   0.09212954  0.09058937  0.1075833   0.10615508]\n",
      " [ 0.11246009  0.08984532  0.1117417   0.09608675  0.10227693  0.09267523\n",
      "   0.09607038  0.08381391  0.11213844  0.10289124]\n",
      " [ 0.10027062  0.10120709  0.10659114  0.0914596   0.10479364  0.09701093\n",
      "   0.09879513  0.09805382  0.09645117  0.10536684]\n",
      " [ 0.09666222  0.09844587  0.09877224  0.10438737  0.10741623  0.10401162\n",
      "   0.09915717  0.08265997  0.10974289  0.0987444 ]\n",
      " [ 0.10364131  0.10805647  0.11118946  0.10402477  0.09591228  0.10312545\n",
      "   0.08628947  0.09611747  0.08860195  0.1030414 ]\n",
      " [ 0.10473746  0.10649666  0.10240515  0.09913199  0.09631681  0.09465548\n",
      "   0.08641077  0.09478817  0.1083798   0.10667773]\n",
      " [ 0.0991309   0.11319292  0.10174625  0.09579687  0.09868326  0.09949856\n",
      "   0.09402374  0.09545199  0.10916808  0.09330752]\n",
      " [ 0.10506484  0.09567215  0.11385161  0.09139082  0.10002622  0.08843662\n",
      "   0.10043763  0.09498518  0.10596767  0.10416728]\n",
      " [ 0.10642868  0.09623772  0.11180191  0.09761795  0.10855145  0.08823077\n",
      "   0.09344222  0.09844052  0.09986536  0.09938336]\n",
      " [ 0.09453029  0.10275074  0.11025582  0.10374855  0.09663785  0.08832394\n",
      "   0.09836484  0.08188479  0.11815521  0.10534795]\n",
      " [ 0.09063856  0.09561126  0.10433216  0.09448233  0.10963834  0.11153083\n",
      "   0.10290791  0.08218082  0.1087712   0.09990663]\n",
      " [ 0.11044741  0.1176535   0.10524098  0.09544504  0.0904702   0.09314702\n",
      "   0.09958853  0.08738145  0.10039533  0.10023063]\n",
      " [ 0.09089354  0.09741833  0.10576162  0.10031826  0.1025224   0.0921085\n",
      "   0.09743896  0.08910403  0.11694778  0.10748661]\n",
      " [ 0.09487233  0.10567994  0.11252178  0.08261248  0.1020216   0.09908704\n",
      "   0.09601825  0.0941938   0.10463222  0.10836049]\n",
      " [ 0.10418003  0.10397762  0.10693316  0.09931088  0.10642458  0.09678502\n",
      "   0.0934171   0.09155678  0.10070868  0.09670614]\n",
      " [ 0.10348374  0.10769302  0.10907946  0.09921546  0.09988803  0.0937534\n",
      "   0.10907453  0.08118095  0.09401379  0.10261762]\n",
      " [ 0.09568154  0.09750705  0.10797966  0.09677203  0.11197153  0.09712914\n",
      "   0.10077389  0.08348094  0.10458709  0.10411719]\n",
      " [ 0.09691141  0.09943213  0.11506543  0.10777181  0.10204943  0.09736504\n",
      "   0.10156521  0.09298518  0.09250835  0.09434599]\n",
      " [ 0.09683011  0.0956538   0.1208007   0.0957334   0.09896155  0.09668745\n",
      "   0.09832828  0.10009366  0.09082083  0.10609023]\n",
      " [ 0.09478208  0.10484856  0.11273195  0.09392828  0.10489323  0.09104414\n",
      "   0.09097648  0.09221815  0.10882275  0.1057544 ]\n",
      " [ 0.09489492  0.10064749  0.10071684  0.10139923  0.1078215   0.10039473\n",
      "   0.09642439  0.09888069  0.10597019  0.09284996]\n",
      " [ 0.0975287   0.10260003  0.09886096  0.097232    0.10028397  0.10248133\n",
      "   0.0953867   0.09139396  0.11349884  0.10073351]\n",
      " [ 0.08999703  0.08675391  0.11855017  0.10528547  0.08797629  0.09076633\n",
      "   0.09967192  0.10331085  0.10700085  0.11068714]\n",
      " [ 0.10299832  0.10630654  0.10084746  0.09959578  0.11139733  0.09228099\n",
      "   0.09122352  0.09493052  0.09913644  0.10128304]\n",
      " [ 0.09276295  0.0955826   0.11429343  0.09193093  0.0877365   0.10351928\n",
      "   0.09232286  0.09281457  0.11812221  0.11091469]\n",
      " [ 0.10919761  0.09661467  0.11035248  0.09453578  0.09979137  0.09430447\n",
      "   0.08765572  0.08850683  0.10946465  0.10957643]\n",
      " [ 0.10149387  0.10911624  0.09788619  0.08430983  0.10591334  0.10507561\n",
      "   0.09694247  0.0879821   0.11307919  0.0982012 ]\n",
      " [ 0.0959048   0.10939652  0.10009523  0.09562169  0.10579848  0.09257842\n",
      "   0.09684698  0.0984418   0.10370066  0.1016154 ]\n",
      " [ 0.09834708  0.09859929  0.10644338  0.10059917  0.1077557   0.09216025\n",
      "   0.1028699   0.09932668  0.09814115  0.09575734]\n",
      " [ 0.08996926  0.10628446  0.09921154  0.09403352  0.10061978  0.0981409\n",
      "   0.09107372  0.09480253  0.11899292  0.1068714 ]\n",
      " [ 0.11040122  0.10159059  0.12451514  0.09260435  0.10122675  0.09067456\n",
      "   0.0910694   0.08545242  0.10352846  0.09893709]\n",
      " [ 0.09628097  0.09686507  0.12221297  0.09296323  0.10536931  0.09037597\n",
      "   0.10368222  0.09468855  0.08982987  0.10773189]\n",
      " [ 0.1009763   0.10589037  0.10297726  0.09400468  0.10128775  0.09959887\n",
      "   0.10831533  0.08718659  0.09904049  0.10072232]\n",
      " [ 0.0930187   0.0829667   0.12377045  0.1012558   0.11342508  0.09532002\n",
      "   0.10441604  0.09067999  0.10053196  0.09461527]\n",
      " [ 0.0970386   0.10885277  0.11653022  0.10136538  0.10209049  0.09260266\n",
      "   0.09367125  0.09199363  0.09858661  0.09726845]\n",
      " [ 0.10204993  0.09682743  0.11870544  0.09113887  0.10339632  0.08579738\n",
      "   0.09972302  0.09163671  0.09848186  0.11224302]\n",
      " [ 0.09924634  0.10144231  0.11705065  0.09771612  0.10678637  0.09578432\n",
      "   0.09829257  0.09264762  0.0981264   0.09290731]\n",
      " [ 0.09845636  0.099071    0.11290825  0.10196395  0.09334911  0.09845182\n",
      "   0.10038381  0.09072997  0.10500921  0.09967647]\n",
      " [ 0.11171453  0.10152041  0.10734823  0.09364368  0.09890439  0.10206252\n",
      "   0.08688371  0.08469702  0.11744884  0.09577671]\n",
      " [ 0.09817351  0.10273349  0.10989915  0.09417094  0.09989706  0.09889693\n",
      "   0.09146677  0.08810581  0.11488768  0.10176867]\n",
      " [ 0.10284533  0.09835297  0.10534292  0.09859938  0.11497221  0.09243727\n",
      "   0.09769787  0.0894551   0.09433175  0.10596519]\n",
      " [ 0.1027396   0.09930377  0.11298345  0.10021235  0.10457921  0.09710583\n",
      "   0.08874134  0.09461544  0.10255466  0.09716433]\n",
      " [ 0.09271625  0.09537395  0.11211652  0.08796119  0.10754795  0.08992689\n",
      "   0.0959823   0.10623434  0.10232829  0.10981232]\n",
      " [ 0.11172879  0.09340651  0.11771099  0.10182248  0.09276174  0.09526304\n",
      "   0.08231229  0.09707752  0.09860609  0.10931052]\n",
      " [ 0.10063566  0.09694664  0.1138779   0.09963291  0.09454758  0.09628156\n",
      "   0.09386898  0.09226478  0.10243899  0.10950504]\n",
      " [ 0.11507657  0.10307738  0.11620462  0.0825619   0.09501034  0.09352478\n",
      "   0.09696897  0.09161269  0.10136872  0.10459397]\n",
      " [ 0.08907843  0.11522046  0.1201642   0.09014781  0.10161571  0.08873653\n",
      "   0.10565375  0.09886966  0.09211521  0.09839827]\n",
      " [ 0.10355378  0.10326152  0.09756917  0.10085072  0.09720387  0.09418555\n",
      "   0.0959968   0.08897871  0.10332181  0.11507811]\n",
      " [ 0.11016918  0.09878495  0.11766705  0.09520358  0.09876409  0.09206047\n",
      "   0.10621949  0.09049752  0.09745055  0.09318322]\n",
      " [ 0.10238606  0.09258816  0.09343116  0.10883259  0.10160127  0.10004005\n",
      "   0.09175498  0.08977401  0.10511927  0.11447248]\n",
      " [ 0.10246582  0.09288342  0.10671222  0.1027318   0.10166298  0.09436579\n",
      "   0.10010276  0.0887383   0.10292792  0.10740897]\n",
      " [ 0.09883295  0.09764089  0.1087751   0.10337932  0.10764351  0.09121943\n",
      "   0.09631849  0.08677557  0.10563948  0.10377523]\n",
      " [ 0.09485498  0.10136593  0.11078779  0.09219712  0.11898123  0.09230877\n",
      "   0.10073433  0.08813112  0.099236    0.10140277]\n",
      " [ 0.10325116  0.10147352  0.10535513  0.09958808  0.10216402  0.09634413\n",
      "   0.10101765  0.10305484  0.09658319  0.09116822]\n",
      " [ 0.11251079  0.10971043  0.09365185  0.10300387  0.10383537  0.09601682\n",
      "   0.08701567  0.08414823  0.10006746  0.11003947]\n",
      " [ 0.09678774  0.10162555  0.10487585  0.0984368   0.100663    0.10170682\n",
      "   0.0981958   0.09526498  0.10006613  0.10237738]\n",
      " [ 0.10614475  0.1132248   0.10524733  0.09321242  0.10880433  0.0929399\n",
      "   0.09509522  0.0854089   0.09851247  0.1014099 ]\n",
      " [ 0.09275452  0.1068285   0.09770644  0.10266941  0.12009837  0.09490525\n",
      "   0.08966574  0.09396667  0.09430695  0.1070981 ]\n",
      " [ 0.09855051  0.10075128  0.11187205  0.09562564  0.10471868  0.08974437\n",
      "   0.10214438  0.08549953  0.10580593  0.10528772]\n",
      " [ 0.09938584  0.10741952  0.11365316  0.10108285  0.10160118  0.09562746\n",
      "   0.09512436  0.09089123  0.09597985  0.09923457]\n",
      " [ 0.09896959  0.09274364  0.10279839  0.09542732  0.11807223  0.09663357\n",
      "   0.09244818  0.09970328  0.09674665  0.10645712]\n",
      " [ 0.1019913   0.1030694   0.10793474  0.08899633  0.10209063  0.09342928\n",
      "   0.09719551  0.09769289  0.10579747  0.10180253]\n",
      " [ 0.10614622  0.10340761  0.11818753  0.10509098  0.1032003   0.08413714\n",
      "   0.09050767  0.09420191  0.10146233  0.09365828]\n",
      " [ 0.10035741  0.09800209  0.09776544  0.09320759  0.11062935  0.09217407\n",
      "   0.1035556   0.09347811  0.09581905  0.11501124]\n",
      " [ 0.08559483  0.08866534  0.12260067  0.10823017  0.1176666   0.08261439\n",
      "   0.10811616  0.08727397  0.10715248  0.09208534]\n",
      " [ 0.10563017  0.10917472  0.09887727  0.09376197  0.0958937   0.09281178\n",
      "   0.10082899  0.0904946   0.1077172   0.10480966]\n",
      " [ 0.09823299  0.10049107  0.10569198  0.08935742  0.10066777  0.10232838\n",
      "   0.10432354  0.09409918  0.11067276  0.09413488]] (8.338 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.29422, step = 101 (17.036 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10457115  0.10102173  0.10578125  0.09810439  0.10691517  0.09916902\n",
      "   0.09839036  0.08647919  0.09831595  0.10125177]\n",
      " [ 0.09260833  0.10288856  0.09702152  0.09646959  0.11013936  0.0975787\n",
      "   0.09930705  0.10043544  0.10128687  0.10226453]\n",
      " [ 0.11644691  0.10804043  0.12015725  0.09000594  0.09125751  0.08826548\n",
      "   0.08559728  0.09017182  0.10089595  0.10916151]\n",
      " [ 0.09668802  0.10216969  0.11410182  0.10155963  0.10581165  0.08437549\n",
      "   0.0992467   0.09130229  0.10465087  0.10009386]\n",
      " [ 0.09802097  0.09733626  0.09929586  0.09966894  0.11515626  0.10186052\n",
      "   0.09123927  0.08696508  0.09936578  0.11109101]\n",
      " [ 0.09875348  0.10112293  0.10985623  0.09786775  0.09671221  0.09017112\n",
      "   0.09185384  0.10224188  0.09672514  0.11469543]\n",
      " [ 0.09066436  0.10779022  0.1057232   0.0848306   0.11146002  0.09780335\n",
      "   0.08879374  0.09230251  0.11052673  0.11010525]\n",
      " [ 0.10781655  0.09355585  0.1114461   0.09306561  0.11059054  0.09151457\n",
      "   0.09120059  0.09495566  0.11267962  0.09317491]\n",
      " [ 0.10111473  0.10520124  0.10166436  0.10924418  0.09244607  0.10285408\n",
      "   0.09083176  0.08433636  0.11163335  0.10067392]\n",
      " [ 0.10116591  0.1018958   0.10650112  0.09500729  0.10480783  0.0972264\n",
      "   0.09683445  0.09260969  0.10918554  0.09476598]\n",
      " [ 0.08922969  0.08762836  0.1172631   0.09799642  0.1144549   0.09174995\n",
      "   0.09674228  0.10329527  0.10269499  0.09894509]\n",
      " [ 0.1108264   0.09425415  0.10396896  0.08898205  0.10670263  0.08838779\n",
      "   0.08830769  0.10244613  0.11805837  0.0980659 ]\n",
      " [ 0.11499543  0.09043195  0.11172915  0.10785077  0.09183887  0.09523187\n",
      "   0.0895916   0.1028318   0.1065264   0.08897214]\n",
      " [ 0.09605633  0.10373559  0.10309885  0.09345604  0.10736869  0.10221396\n",
      "   0.09060453  0.08742484  0.11388037  0.10216083]\n",
      " [ 0.09741666  0.10086798  0.10257382  0.09540406  0.10936476  0.10134497\n",
      "   0.09983499  0.08661433  0.10200445  0.10457401]\n",
      " [ 0.10137478  0.10768703  0.1156085   0.09696948  0.09829821  0.08638418\n",
      "   0.09727971  0.0912837   0.10000136  0.10511307]\n",
      " [ 0.11733701  0.09902237  0.11411332  0.09294015  0.10879342  0.08845603\n",
      "   0.09809776  0.07921284  0.09383514  0.10819187]\n",
      " [ 0.11073956  0.09308165  0.12023401  0.11054126  0.11178857  0.08590558\n",
      "   0.0938011   0.08306178  0.09767503  0.09317138]\n",
      " [ 0.09851894  0.10283523  0.11595152  0.08088706  0.10998087  0.1002643\n",
      "   0.09073491  0.09683795  0.10861225  0.09537694]\n",
      " [ 0.10071196  0.10733362  0.11585713  0.09836748  0.09458197  0.09451583\n",
      "   0.09369086  0.08242185  0.10277464  0.10974463]\n",
      " [ 0.10164127  0.09510663  0.10754386  0.09890185  0.10999408  0.0907133\n",
      "   0.08948759  0.09639017  0.10271411  0.10750715]\n",
      " [ 0.10019793  0.10907748  0.10714259  0.09643003  0.10221416  0.09364904\n",
      "   0.09937041  0.08715431  0.09811801  0.10664615]\n",
      " [ 0.09883743  0.10765755  0.10959207  0.09732354  0.10421031  0.09384124\n",
      "   0.10245062  0.08715933  0.09751277  0.10141511]\n",
      " [ 0.08577085  0.1023342   0.11104735  0.10124917  0.1070599   0.09479617\n",
      "   0.09641714  0.08388605  0.10615285  0.11128631]\n",
      " [ 0.09996143  0.08906224  0.11120211  0.0967657   0.09683304  0.09398334\n",
      "   0.09195393  0.10890871  0.10225695  0.10907262]\n",
      " [ 0.10024308  0.09940828  0.11693015  0.08524387  0.0958608   0.08234809\n",
      "   0.10000355  0.08674408  0.1201077   0.11311036]\n",
      " [ 0.0915155   0.10368051  0.12145366  0.09368424  0.10246693  0.09092953\n",
      "   0.09327167  0.10231747  0.11164666  0.08903385]\n",
      " [ 0.09886517  0.09039724  0.11272057  0.09805952  0.10474788  0.09418759\n",
      "   0.09359054  0.09386812  0.10815225  0.10541114]\n",
      " [ 0.10010398  0.09618982  0.1020072   0.10105957  0.10191569  0.09388316\n",
      "   0.10663587  0.09249162  0.10182991  0.1038832 ]\n",
      " [ 0.10594717  0.10026373  0.11137097  0.08822502  0.09833163  0.09413138\n",
      "   0.0981698   0.08798733  0.10791503  0.10765799]\n",
      " [ 0.09905121  0.10249563  0.09524736  0.10772842  0.09468312  0.09409946\n",
      "   0.1002496   0.09616051  0.10728965  0.10299509]\n",
      " [ 0.11352144  0.0952725   0.10800971  0.10458713  0.1036054   0.09100881\n",
      "   0.09720095  0.09305429  0.09129603  0.10244364]\n",
      " [ 0.11019341  0.10459086  0.11010001  0.0990585   0.10190204  0.08541129\n",
      "   0.09716412  0.09601396  0.09931122  0.09625465]\n",
      " [ 0.0914406   0.10222071  0.10306498  0.09605172  0.10538884  0.09198548\n",
      "   0.10122797  0.0910599   0.09854158  0.11901823]\n",
      " [ 0.10835821  0.11193778  0.10240693  0.09947389  0.09533619  0.09168999\n",
      "   0.0956874   0.09871434  0.10063882  0.09575647]\n",
      " [ 0.09519229  0.10365736  0.11870352  0.08744608  0.09395708  0.10223466\n",
      "   0.1000305   0.09689784  0.0990739   0.10280676]\n",
      " [ 0.09645075  0.1143656   0.10559503  0.09385928  0.10446493  0.0965648\n",
      "   0.09346496  0.09087069  0.10354631  0.10081767]\n",
      " [ 0.09537917  0.09745416  0.11294174  0.0959506   0.10049426  0.0937732\n",
      "   0.10609256  0.09160512  0.09944738  0.10686176]\n",
      " [ 0.10012422  0.09073807  0.11449122  0.10107458  0.09684193  0.09775008\n",
      "   0.09848006  0.09373552  0.09862708  0.10813725]\n",
      " [ 0.10073432  0.10023874  0.11088076  0.10139506  0.10034978  0.10159468\n",
      "   0.09838124  0.09103892  0.09564522  0.09974129]\n",
      " [ 0.09488081  0.09226426  0.10645724  0.10467362  0.11004066  0.09594116\n",
      "   0.09365422  0.09784483  0.10566138  0.09858184]\n",
      " [ 0.09459997  0.09190433  0.12588321  0.09145291  0.10634016  0.08985373\n",
      "   0.09133092  0.09132283  0.1113308   0.10598115]\n",
      " [ 0.09447102  0.09283558  0.11932039  0.10298559  0.09992824  0.09272705\n",
      "   0.09370838  0.09829582  0.10694975  0.09877814]\n",
      " [ 0.1019714   0.09670494  0.10030701  0.09313297  0.09514164  0.09979877\n",
      "   0.09436671  0.09676809  0.11573607  0.10607246]\n",
      " [ 0.10489734  0.11062042  0.10396488  0.09694268  0.0999099   0.1004862\n",
      "   0.09676561  0.08621159  0.1037599   0.09644151]\n",
      " [ 0.10699815  0.1000122   0.11537182  0.09095654  0.09981285  0.09038541\n",
      "   0.09651779  0.09232728  0.10318965  0.10442838]\n",
      " [ 0.09623075  0.10335852  0.11391225  0.08649818  0.10251849  0.097448\n",
      "   0.10111763  0.09222742  0.10844914  0.09823964]\n",
      " [ 0.10376506  0.09917972  0.09735726  0.10431881  0.09974214  0.09587391\n",
      "   0.09027778  0.09713577  0.10044014  0.11190946]\n",
      " [ 0.09750352  0.10256771  0.10757475  0.09281522  0.09667929  0.11120721\n",
      "   0.09801138  0.08830782  0.10252971  0.10280339]\n",
      " [ 0.10290255  0.10326642  0.11125769  0.10419365  0.10518255  0.09539587\n",
      "   0.09107939  0.08409357  0.09938022  0.1032481 ]\n",
      " [ 0.11050083  0.09297118  0.1140818   0.08915592  0.10182194  0.09261984\n",
      "   0.09437225  0.10417734  0.09683263  0.10346627]\n",
      " [ 0.10405526  0.09811407  0.10975803  0.10788621  0.10154986  0.08855128\n",
      "   0.09375016  0.09620234  0.10010678  0.10002609]\n",
      " [ 0.09340712  0.09849417  0.10851004  0.09846202  0.09933354  0.09463511\n",
      "   0.10017174  0.10169662  0.10626046  0.09902917]\n",
      " [ 0.1029443   0.10379084  0.1282316   0.09484491  0.10206392  0.08784433\n",
      "   0.10332003  0.08517242  0.09896392  0.0928237 ]\n",
      " [ 0.08897798  0.10668668  0.10530169  0.09383792  0.09943667  0.09249371\n",
      "   0.09678036  0.09221763  0.11621812  0.10804924]\n",
      " [ 0.10269357  0.09333416  0.09811621  0.10399806  0.11293732  0.09003344\n",
      "   0.09908547  0.09360901  0.09858607  0.10760666]\n",
      " [ 0.1053661   0.09528152  0.11130241  0.10227142  0.10171368  0.0929497\n",
      "   0.09104043  0.08707079  0.09766796  0.11533595]\n",
      " [ 0.09843297  0.09516057  0.11081044  0.09970591  0.10865599  0.08693927\n",
      "   0.09378905  0.09056924  0.11328045  0.10265607]\n",
      " [ 0.0923181   0.09660808  0.11890859  0.09900639  0.10276857  0.10137397\n",
      "   0.10641042  0.08798102  0.09338241  0.10124245]\n",
      " [ 0.09293933  0.09922252  0.11590489  0.10125636  0.10565202  0.09266575\n",
      "   0.09160873  0.0942641   0.09962168  0.10686459]\n",
      " [ 0.09983136  0.09393948  0.10629419  0.09854258  0.11151359  0.08735922\n",
      "   0.10328617  0.09522213  0.0959045   0.10810684]\n",
      " [ 0.09985659  0.0943305   0.097018    0.09611447  0.10091275  0.09985104\n",
      "   0.10279955  0.09284015  0.11075872  0.1055182 ]\n",
      " [ 0.09824962  0.10514171  0.1185302   0.09439397  0.09659491  0.09362897\n",
      "   0.10166792  0.09755027  0.09872283  0.09551951]\n",
      " [ 0.09332129  0.11362315  0.10775983  0.10106543  0.09895734  0.10167831\n",
      "   0.09353221  0.09349002  0.10021963  0.09635285]\n",
      " [ 0.09330537  0.10054356  0.09367482  0.11191413  0.11450406  0.09489058\n",
      "   0.09224641  0.09776161  0.10160472  0.09955466]\n",
      " [ 0.10584231  0.10047131  0.10959639  0.10110799  0.10518585  0.08648597\n",
      "   0.1005301   0.0857596   0.0951749   0.10984554]\n",
      " [ 0.09929071  0.11085717  0.10286048  0.09379375  0.10545035  0.10743476\n",
      "   0.0914304   0.09075392  0.10709356  0.09103486]\n",
      " [ 0.09730558  0.1025373   0.10621359  0.10564218  0.11425447  0.08842678\n",
      "   0.09607459  0.08795758  0.10463118  0.09695671]\n",
      " [ 0.10908037  0.1182363   0.10012257  0.08614401  0.10582478  0.09795703\n",
      "   0.0878099   0.10336273  0.10217907  0.08928324]\n",
      " [ 0.09503115  0.1027497   0.1056958   0.09816065  0.10804693  0.09553887\n",
      "   0.09205464  0.09458568  0.10517167  0.10296485]\n",
      " [ 0.09226804  0.09713145  0.10781075  0.10432389  0.09657679  0.09105871\n",
      "   0.09845582  0.10228888  0.10016703  0.10991856]\n",
      " [ 0.09375647  0.10646468  0.1059825   0.09446622  0.10443405  0.09664628\n",
      "   0.09898807  0.09085319  0.09876907  0.10963945]\n",
      " [ 0.0992534   0.09962662  0.10338875  0.10544756  0.0938158   0.09844477\n",
      "   0.08993201  0.09617013  0.10692517  0.10699581]\n",
      " [ 0.09789488  0.09887146  0.10957228  0.09751831  0.11232208  0.09305581\n",
      "   0.09241078  0.08721223  0.11210586  0.09903629]\n",
      " [ 0.10169967  0.10175136  0.09798162  0.09195583  0.10732348  0.11158457\n",
      "   0.09907043  0.09968906  0.09951522  0.08942875]\n",
      " [ 0.09822111  0.1016093   0.10630599  0.10482775  0.10407559  0.09553084\n",
      "   0.09539233  0.0906892   0.0983751   0.10497284]\n",
      " [ 0.1084785   0.10671405  0.10126384  0.09154876  0.1038401   0.08753359\n",
      "   0.10051226  0.09962843  0.10315146  0.09732901]\n",
      " [ 0.11609045  0.09912485  0.09991246  0.09303223  0.10548621  0.09376494\n",
      "   0.09510347  0.09115224  0.10504283  0.10129029]\n",
      " [ 0.09491574  0.10251312  0.10550288  0.09995299  0.11056624  0.08830969\n",
      "   0.10205858  0.08911096  0.10200942  0.10506031]\n",
      " [ 0.11312547  0.1037742   0.11005948  0.09637807  0.10421427  0.09158999\n",
      "   0.0939865   0.0934438   0.09853956  0.09488865]\n",
      " [ 0.09498625  0.09378547  0.10305117  0.09504525  0.11881676  0.09207407\n",
      "   0.09728639  0.0938832   0.10374984  0.10732161]\n",
      " [ 0.10214237  0.09692295  0.10907049  0.0906827   0.10501918  0.0965028\n",
      "   0.09828602  0.09445208  0.10104493  0.10587644]\n",
      " [ 0.10162565  0.09636774  0.09813106  0.09667514  0.10354917  0.09251174\n",
      "   0.09597223  0.09129791  0.10440067  0.11946873]\n",
      " [ 0.09693875  0.08878526  0.11613207  0.105671    0.1054773   0.08401619\n",
      "   0.08943038  0.09868849  0.10101345  0.11384713]\n",
      " [ 0.11096878  0.0978704   0.111136    0.09721749  0.10191042  0.0920855\n",
      "   0.10452859  0.09653614  0.08414508  0.10360154]\n",
      " [ 0.09946837  0.10334349  0.10709304  0.0977134   0.10377272  0.09690921\n",
      "   0.09701762  0.10144471  0.09699439  0.09624298]\n",
      " [ 0.09616495  0.10657849  0.10976351  0.09317405  0.11269253  0.09418438\n",
      "   0.08743898  0.0969272   0.10762748  0.0954484 ]\n",
      " [ 0.10544443  0.10085822  0.10603501  0.09886631  0.09064481  0.09999475\n",
      "   0.08330753  0.09813022  0.1112028   0.1055159 ]\n",
      " [ 0.10300152  0.09480743  0.10535508  0.09346224  0.08976139  0.08856046\n",
      "   0.10732644  0.09252383  0.11056216  0.11463949]\n",
      " [ 0.101293    0.09534852  0.09889938  0.10248037  0.11810271  0.09299355\n",
      "   0.08838892  0.08688767  0.10809629  0.10750961]\n",
      " [ 0.09027537  0.09554109  0.12098849  0.10260893  0.11049626  0.09259948\n",
      "   0.09008467  0.0917507   0.10216571  0.10348926]\n",
      " [ 0.10904497  0.09126723  0.10368884  0.09016852  0.10444987  0.08966161\n",
      "   0.09219316  0.10514913  0.11153149  0.10284518]\n",
      " [ 0.09694833  0.09933857  0.10743223  0.10312007  0.10179604  0.091883\n",
      "   0.09647038  0.08444048  0.09759101  0.12097988]\n",
      " [ 0.09926496  0.10002999  0.10519905  0.0925662   0.09993088  0.09310421\n",
      "   0.10269899  0.10487576  0.09681647  0.10551354]\n",
      " [ 0.08721051  0.10210457  0.11105815  0.09199777  0.10098961  0.09502111\n",
      "   0.09272902  0.10572482  0.10642564  0.10673881]\n",
      " [ 0.10054787  0.09300039  0.11169866  0.09404327  0.09594004  0.09901278\n",
      "   0.09426752  0.11209831  0.0983659   0.10102527]\n",
      " [ 0.0972565   0.10447477  0.09587727  0.0954702   0.10778273  0.09994196\n",
      "   0.0889558   0.08980028  0.10835364  0.11208685]\n",
      " [ 0.10069476  0.098457    0.09512525  0.09314182  0.10630176  0.09764445\n",
      "   0.09624343  0.09023725  0.10696749  0.11518675]\n",
      " [ 0.11139303  0.10352855  0.11359982  0.09450312  0.1041556   0.08851638\n",
      "   0.08461949  0.08478499  0.10399973  0.11089927]\n",
      " [ 0.10108184  0.0860669   0.10421744  0.09685827  0.09836341  0.08839976\n",
      "   0.103964    0.10136478  0.10724877  0.11243484]] (8.475 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.84505\n",
      "INFO:tensorflow:probabilities = [[ 0.10053402  0.10093413  0.11290628  0.09885496  0.09830894  0.10351192\n",
      "   0.09617208  0.09426062  0.09972733  0.09478965]\n",
      " [ 0.09433874  0.10146111  0.10237706  0.09206899  0.10012092  0.10488214\n",
      "   0.09962501  0.0916751   0.11146678  0.10198424]\n",
      " [ 0.10669003  0.11356639  0.10834613  0.10198293  0.08963568  0.08849739\n",
      "   0.09563091  0.10045911  0.10475715  0.09043428]\n",
      " [ 0.11389101  0.09551381  0.11911867  0.10172549  0.09597852  0.09532854\n",
      "   0.08942487  0.09261001  0.09923043  0.09717876]\n",
      " [ 0.09801485  0.10277592  0.1164466   0.09324662  0.11040146  0.09406632\n",
      "   0.08745269  0.09812928  0.09899319  0.10047308]\n",
      " [ 0.10376691  0.10743959  0.1094953   0.09477191  0.09228441  0.08701251\n",
      "   0.10167976  0.10678519  0.09554602  0.10121837]\n",
      " [ 0.08652911  0.08697824  0.10987787  0.10437089  0.09784031  0.10961188\n",
      "   0.10359372  0.09743109  0.11144389  0.09232304]\n",
      " [ 0.10658754  0.10953409  0.10684878  0.09147106  0.11251168  0.09268819\n",
      "   0.09132975  0.0918675   0.09800938  0.09915203]\n",
      " [ 0.09424064  0.10456727  0.10806709  0.09195779  0.10251273  0.10196225\n",
      "   0.10760611  0.09398895  0.09981636  0.09528086]\n",
      " [ 0.10518356  0.10029505  0.10813145  0.08883677  0.10115827  0.09160627\n",
      "   0.09861012  0.09749796  0.11219282  0.09648775]\n",
      " [ 0.10843517  0.09640038  0.10539092  0.09691478  0.10159489  0.09050835\n",
      "   0.09292702  0.09676575  0.10524396  0.1058188 ]\n",
      " [ 0.10657752  0.11202373  0.10504842  0.09730907  0.09998001  0.1004415\n",
      "   0.09433389  0.09958888  0.09954252  0.08515447]\n",
      " [ 0.09944929  0.09361999  0.10355789  0.08840057  0.11126089  0.08900406\n",
      "   0.09473796  0.09562758  0.1094306   0.11491126]\n",
      " [ 0.1107333   0.09295312  0.10104058  0.10259379  0.10273589  0.08596914\n",
      "   0.09940076  0.09468322  0.09719386  0.11269634]\n",
      " [ 0.11257953  0.09911995  0.10501649  0.10104876  0.11852239  0.0954431\n",
      "   0.0921307   0.08962339  0.08815731  0.09835839]\n",
      " [ 0.09641279  0.08374492  0.10582512  0.10586593  0.10944148  0.0936502\n",
      "   0.10915384  0.0975545   0.10324249  0.09510873]\n",
      " [ 0.09554378  0.09507599  0.11154024  0.1005296   0.10399999  0.08428182\n",
      "   0.09310916  0.10017115  0.11252914  0.1032191 ]\n",
      " [ 0.09860329  0.09458264  0.11074637  0.10395014  0.09847388  0.09121578\n",
      "   0.1074137   0.09504529  0.1045391   0.09542976]\n",
      " [ 0.11289131  0.10218433  0.11525387  0.10588743  0.10689761  0.09790453\n",
      "   0.08272789  0.08212037  0.09463706  0.09949557]\n",
      " [ 0.09703336  0.09149501  0.10963895  0.09997306  0.1102405   0.08457845\n",
      "   0.09130203  0.10012178  0.10490172  0.11071514]\n",
      " [ 0.103567    0.1156335   0.10618807  0.09556487  0.09779105  0.09881657\n",
      "   0.09406573  0.08329385  0.10737409  0.09770525]\n",
      " [ 0.09310141  0.10834087  0.09910907  0.09575135  0.10583775  0.09778292\n",
      "   0.10101689  0.09188898  0.11174     0.09543076]\n",
      " [ 0.08945478  0.09357589  0.10418215  0.10924166  0.10615356  0.09081783\n",
      "   0.08856449  0.09435961  0.11380097  0.10984897]\n",
      " [ 0.10272163  0.10417382  0.10158604  0.09953701  0.10006178  0.09185557\n",
      "   0.0995094   0.09717876  0.10285188  0.10052411]\n",
      " [ 0.08693612  0.09381957  0.09821294  0.09735233  0.11586018  0.08776386\n",
      "   0.10402282  0.09414777  0.10600565  0.11587875]\n",
      " [ 0.1051624   0.11117054  0.09927498  0.09150908  0.11106627  0.09846286\n",
      "   0.09769701  0.09319394  0.09648424  0.09597866]\n",
      " [ 0.09096048  0.10574482  0.11166605  0.09263477  0.10201403  0.08943334\n",
      "   0.0937923   0.09466385  0.11625308  0.10283729]\n",
      " [ 0.09904093  0.09602123  0.09547487  0.10457581  0.1060702   0.09602983\n",
      "   0.0964136   0.09620424  0.10598789  0.10418142]\n",
      " [ 0.09456215  0.09493952  0.10448401  0.09404154  0.10494965  0.10378937\n",
      "   0.09922988  0.10708802  0.10347115  0.09344472]\n",
      " [ 0.09311725  0.09626567  0.12069469  0.09497464  0.104209    0.09772882\n",
      "   0.0942601   0.08844841  0.10449121  0.10581026]\n",
      " [ 0.10587561  0.09544557  0.11908364  0.09381089  0.09639066  0.09560592\n",
      "   0.09288843  0.08691584  0.11730173  0.09668175]\n",
      " [ 0.10145179  0.10230054  0.09976937  0.11586583  0.10695665  0.09312741\n",
      "   0.10459808  0.08683419  0.09540074  0.09369536]\n",
      " [ 0.09782439  0.09717306  0.11602037  0.08876831  0.09348418  0.09592694\n",
      "   0.09804101  0.09324688  0.11745927  0.1020556 ]\n",
      " [ 0.11352368  0.09042814  0.11076587  0.10185412  0.10734351  0.08843788\n",
      "   0.08533687  0.10055219  0.10668949  0.09506822]\n",
      " [ 0.09695287  0.09858411  0.11703743  0.10125177  0.10111488  0.09548628\n",
      "   0.09509125  0.09575347  0.08556242  0.11316562]\n",
      " [ 0.1031893   0.09302699  0.12204425  0.0989745   0.09933256  0.0820501\n",
      "   0.09019181  0.0925952   0.11401884  0.10457641]\n",
      " [ 0.09838375  0.10595997  0.10995846  0.09609915  0.10410109  0.09857403\n",
      "   0.10188529  0.08919694  0.10348921  0.09235207]\n",
      " [ 0.10450898  0.09565949  0.11372084  0.10625296  0.10155357  0.08445359\n",
      "   0.08797373  0.09068228  0.10838318  0.10681139]\n",
      " [ 0.10625454  0.1077101   0.10427011  0.1013785   0.10747678  0.09856098\n",
      "   0.08773394  0.09760138  0.09866072  0.09035292]\n",
      " [ 0.09780648  0.09319017  0.11131053  0.09049962  0.106517    0.09705285\n",
      "   0.10490069  0.0938066   0.10000982  0.10490621]\n",
      " [ 0.10252806  0.09525347  0.10876054  0.10425309  0.09748124  0.09046494\n",
      "   0.10377413  0.09680266  0.1001595   0.10052237]\n",
      " [ 0.10167758  0.09282177  0.12484262  0.09975296  0.10802205  0.09779721\n",
      "   0.08781736  0.08533684  0.10531659  0.09661505]\n",
      " [ 0.10362072  0.09069043  0.11529561  0.10073132  0.09975249  0.09065053\n",
      "   0.10231621  0.08328736  0.09679302  0.11686232]\n",
      " [ 0.09395607  0.09961236  0.10744728  0.09497326  0.10331955  0.09464018\n",
      "   0.10839914  0.09248218  0.10191318  0.10325681]\n",
      " [ 0.09463656  0.09997126  0.10304199  0.09945334  0.10971496  0.10114363\n",
      "   0.09248162  0.10157199  0.09581047  0.10217424]\n",
      " [ 0.08866837  0.09368116  0.10746101  0.10324443  0.10327211  0.08840746\n",
      "   0.0949288   0.10190955  0.09838071  0.12004647]\n",
      " [ 0.10436858  0.10338689  0.0937379   0.10036925  0.10335491  0.09230742\n",
      "   0.10733977  0.0988671   0.09142854  0.10483968]\n",
      " [ 0.10678688  0.09880511  0.10484713  0.0942642   0.09363828  0.10072072\n",
      "   0.09427252  0.09265576  0.10537598  0.10863341]\n",
      " [ 0.10369995  0.08953431  0.1015318   0.100264    0.10273502  0.09137729\n",
      "   0.09630498  0.10575277  0.10286342  0.10593645]\n",
      " [ 0.09847313  0.09193122  0.10591191  0.09846473  0.11020069  0.08797031\n",
      "   0.09567136  0.09190622  0.10843147  0.11103894]\n",
      " [ 0.10336307  0.09728757  0.11370378  0.09817798  0.09434187  0.09374547\n",
      "   0.09430016  0.09912731  0.10223387  0.103719  ]\n",
      " [ 0.09982199  0.09479341  0.11275999  0.09698195  0.10667089  0.09810559\n",
      "   0.10255348  0.0903725   0.10280808  0.09513219]\n",
      " [ 0.10227079  0.10438982  0.1142453   0.09431903  0.09362517  0.08882497\n",
      "   0.0968347   0.08786771  0.1024554   0.1151671 ]\n",
      " [ 0.09084613  0.08449919  0.1253743   0.08845647  0.10645809  0.09461098\n",
      "   0.09527212  0.09168753  0.10490999  0.11788517]\n",
      " [ 0.10704902  0.09856201  0.11543688  0.09339628  0.10229439  0.10186832\n",
      "   0.09586924  0.09898134  0.08897881  0.09756372]\n",
      " [ 0.09913461  0.1003008   0.11287891  0.09571575  0.09702079  0.09063857\n",
      "   0.09628655  0.10395077  0.10625136  0.09782194]\n",
      " [ 0.09627817  0.08794641  0.11027293  0.1013306   0.11285232  0.09768824\n",
      "   0.09877794  0.07994617  0.11851922  0.09638799]\n",
      " [ 0.10483351  0.10967652  0.099437    0.08680456  0.10461546  0.09487531\n",
      "   0.10012233  0.096906    0.10012751  0.10260186]\n",
      " [ 0.10606674  0.09313803  0.10202573  0.09503786  0.10270461  0.08940192\n",
      "   0.10099836  0.09933275  0.10191552  0.10937846]\n",
      " [ 0.09701128  0.11279243  0.11255652  0.09457526  0.10616747  0.09553579\n",
      "   0.09092537  0.08796483  0.10399905  0.09847192]\n",
      " [ 0.10011837  0.10171004  0.1085709   0.09668913  0.11056874  0.08505706\n",
      "   0.09302551  0.09141304  0.10615389  0.10669328]\n",
      " [ 0.10046701  0.09492209  0.10416178  0.09623904  0.10271699  0.08654017\n",
      "   0.10116941  0.09480417  0.10277523  0.11620412]\n",
      " [ 0.10873385  0.09759434  0.1185296   0.09904955  0.09087844  0.09015755\n",
      "   0.09351405  0.09452475  0.10554822  0.10146963]\n",
      " [ 0.09856164  0.10384186  0.11586602  0.09042752  0.10684527  0.09240141\n",
      "   0.09029726  0.09097619  0.09345324  0.11732962]\n",
      " [ 0.10069512  0.10059407  0.12649532  0.09927526  0.09297195  0.08626965\n",
      "   0.09865385  0.09536036  0.10501433  0.09467012]\n",
      " [ 0.12393906  0.10173323  0.11309946  0.08936595  0.09666853  0.09324331\n",
      "   0.08793002  0.09369227  0.09962211  0.10070606]\n",
      " [ 0.10787982  0.10435662  0.10940727  0.08210951  0.09810633  0.10000565\n",
      "   0.0976297   0.09069294  0.11637804  0.09343416]\n",
      " [ 0.10601716  0.09328289  0.10724613  0.09176908  0.09751131  0.09616974\n",
      "   0.09316505  0.09367707  0.11357952  0.1075821 ]\n",
      " [ 0.09422546  0.11293411  0.1105973   0.10006817  0.10244973  0.09894595\n",
      "   0.10618144  0.09262891  0.09404239  0.08792654]\n",
      " [ 0.10766827  0.10477427  0.10546842  0.09166317  0.1095305   0.09637071\n",
      "   0.09792832  0.08965907  0.09766828  0.09926895]\n",
      " [ 0.09926207  0.10373156  0.10356661  0.09615702  0.10381681  0.09567083\n",
      "   0.09899975  0.09935769  0.10317909  0.09625859]\n",
      " [ 0.10526276  0.09716804  0.10204819  0.09315827  0.10879154  0.09073341\n",
      "   0.10061703  0.09763894  0.1042642   0.10031763]\n",
      " [ 0.10322782  0.09922172  0.1120891   0.10057253  0.103181    0.09022084\n",
      "   0.08873265  0.09326837  0.10679752  0.10268845]\n",
      " [ 0.09739411  0.09975688  0.11711943  0.09537975  0.1114195   0.08804027\n",
      "   0.10416978  0.08802343  0.10313165  0.09556525]\n",
      " [ 0.09733572  0.11339013  0.10391083  0.10117621  0.10433062  0.0912982\n",
      "   0.09949832  0.09034431  0.10091876  0.09779689]\n",
      " [ 0.09803     0.09662917  0.11212526  0.10288119  0.10077358  0.08734361\n",
      "   0.11913528  0.07745251  0.10126635  0.10436308]\n",
      " [ 0.10087003  0.10105805  0.11094153  0.09739812  0.10659952  0.08998713\n",
      "   0.08484662  0.0941163   0.11316473  0.10101791]\n",
      " [ 0.101459    0.10284864  0.09904722  0.09488603  0.10886164  0.0903575\n",
      "   0.09917985  0.1006594   0.09829549  0.10440526]\n",
      " [ 0.09648658  0.08694924  0.12827209  0.10631566  0.09684679  0.09510738\n",
      "   0.09045235  0.09681743  0.1116882   0.09106424]\n",
      " [ 0.10948324  0.0957331   0.10123248  0.09473928  0.12081415  0.09718914\n",
      "   0.10099243  0.08285315  0.09604975  0.10091329]\n",
      " [ 0.10055701  0.10652407  0.11804904  0.09034807  0.0977226   0.0959502\n",
      "   0.09642841  0.0950208   0.09413394  0.10526589]\n",
      " [ 0.09933466  0.10301431  0.10731389  0.11093759  0.10169289  0.08942745\n",
      "   0.09724943  0.09209793  0.09423901  0.10469282]\n",
      " [ 0.09465908  0.09788234  0.10788678  0.09957767  0.10153786  0.10067604\n",
      "   0.10001881  0.09316478  0.09772941  0.10686725]\n",
      " [ 0.11391752  0.09885024  0.11922628  0.08641592  0.09676444  0.09566504\n",
      "   0.08141637  0.09183498  0.11885659  0.09705259]\n",
      " [ 0.09606189  0.10361069  0.10286262  0.10025852  0.10039433  0.10574496\n",
      "   0.0932219   0.09557446  0.10353938  0.09873129]\n",
      " [ 0.10158906  0.10051364  0.10436049  0.09585139  0.10086416  0.09304297\n",
      "   0.0961621   0.09676851  0.10259201  0.10825565]\n",
      " [ 0.08254099  0.09612372  0.10922299  0.10434024  0.09934809  0.09308692\n",
      "   0.09771068  0.09996753  0.1060245   0.11163429]\n",
      " [ 0.08863421  0.10201221  0.10785257  0.08667187  0.10668189  0.10459303\n",
      "   0.1097725   0.08735027  0.11095662  0.09547483]\n",
      " [ 0.09930027  0.09271854  0.1095107   0.09357032  0.10161937  0.09777485\n",
      "   0.09314477  0.08498691  0.11561026  0.11176398]\n",
      " [ 0.1029746   0.09722546  0.11768775  0.08758929  0.10027781  0.09360568\n",
      "   0.09454711  0.09196024  0.10940062  0.10473137]\n",
      " [ 0.10251506  0.10360285  0.11008804  0.09440132  0.10385977  0.1028405\n",
      "   0.09584166  0.09194518  0.10461149  0.09029416]\n",
      " [ 0.09270022  0.09572348  0.11456387  0.09848318  0.09470479  0.10172209\n",
      "   0.10087457  0.10369675  0.09434754  0.1031835 ]\n",
      " [ 0.10191374  0.10560166  0.11376362  0.09992117  0.10473798  0.08866777\n",
      "   0.09267056  0.08777589  0.09660672  0.10834084]\n",
      " [ 0.09360494  0.10656618  0.10715828  0.09288965  0.11126819  0.10243217\n",
      "   0.09421425  0.09365127  0.10161934  0.09659573]\n",
      " [ 0.10256809  0.08618089  0.10900389  0.10623573  0.10121308  0.09034394\n",
      "   0.09640545  0.08951088  0.10201707  0.11652107]\n",
      " [ 0.09663211  0.09856575  0.10588048  0.09384698  0.11350615  0.09500223\n",
      "   0.09502608  0.09556238  0.09956652  0.1064114 ]\n",
      " [ 0.11136108  0.0904845   0.11210395  0.09979064  0.10937667  0.09350988\n",
      "   0.1036149   0.08450922  0.0996946   0.09555462]\n",
      " [ 0.10723362  0.0858558   0.10411473  0.09584177  0.11139043  0.09982376\n",
      "   0.09031476  0.09694269  0.10161725  0.10686523]\n",
      " [ 0.09135366  0.09215334  0.11442722  0.10839507  0.09760509  0.10290277\n",
      "   0.09779067  0.09575819  0.09247436  0.10713967]\n",
      " [ 0.0962567   0.10123356  0.10178095  0.10481105  0.10905087  0.09053637\n",
      "   0.10552198  0.0883756   0.10356811  0.09886488]] (8.633 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.27282, step = 201 (17.112 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10009819  0.09106896  0.10515348  0.10465789  0.09622758  0.09033169\n",
      "   0.09331304  0.0981594   0.10735758  0.11363217]\n",
      " [ 0.09311552  0.09599265  0.10031763  0.10398927  0.10035294  0.09500979\n",
      "   0.10321181  0.09505855  0.10805224  0.10489962]\n",
      " [ 0.09803563  0.10021664  0.11500819  0.0935757   0.09445193  0.10123967\n",
      "   0.10360943  0.09060337  0.10004663  0.10321282]\n",
      " [ 0.09689471  0.0979299   0.09835213  0.0994022   0.09831875  0.10162598\n",
      "   0.09541996  0.09609681  0.11529351  0.10066607]\n",
      " [ 0.10166118  0.0926776   0.08978505  0.10353643  0.10971807  0.1024894\n",
      "   0.10355937  0.08782318  0.09487471  0.11387506]\n",
      " [ 0.10646265  0.09922098  0.10948978  0.10692146  0.10480715  0.09156846\n",
      "   0.09483685  0.09490411  0.08538464  0.10640391]\n",
      " [ 0.09417949  0.08615063  0.12614799  0.09902679  0.09729556  0.09400877\n",
      "   0.096932    0.09877762  0.1044902   0.10299094]\n",
      " [ 0.09811947  0.08701173  0.11856583  0.10634603  0.10383173  0.08896823\n",
      "   0.10324005  0.09196879  0.09825937  0.10368876]\n",
      " [ 0.10688123  0.08417315  0.11674266  0.10165803  0.09112098  0.0896272\n",
      "   0.09527464  0.09566007  0.10758106  0.11128098]\n",
      " [ 0.10594507  0.08861416  0.10649411  0.10539761  0.09613116  0.09039506\n",
      "   0.10618404  0.09961186  0.09963648  0.10159038]\n",
      " [ 0.11583216  0.11322903  0.11007803  0.09751239  0.0962835   0.10133906\n",
      "   0.08705527  0.09125166  0.09288286  0.09453606]\n",
      " [ 0.09113502  0.09619465  0.11214304  0.10612968  0.1068434   0.09286422\n",
      "   0.09465007  0.08265351  0.10537596  0.11201051]\n",
      " [ 0.1071371   0.09333889  0.10853382  0.09754257  0.117011    0.0907701\n",
      "   0.09029112  0.08154295  0.09928948  0.11454298]\n",
      " [ 0.097383    0.10094073  0.11020088  0.09025514  0.09657577  0.09876958\n",
      "   0.09901949  0.09625345  0.09954661  0.11105531]\n",
      " [ 0.09827422  0.09626816  0.10738002  0.09436927  0.09985664  0.10816363\n",
      "   0.09322468  0.09688385  0.10009856  0.10548092]\n",
      " [ 0.10084563  0.08812426  0.10384341  0.10419201  0.1013564   0.09399997\n",
      "   0.08649421  0.09571929  0.1130904   0.11233442]\n",
      " [ 0.10243527  0.10069597  0.11358797  0.09912007  0.09825344  0.09628458\n",
      "   0.09050968  0.09256425  0.10486264  0.10168605]\n",
      " [ 0.09051981  0.09895448  0.10721187  0.10440487  0.09507777  0.10410133\n",
      "   0.09816893  0.09253245  0.10218678  0.10684162]\n",
      " [ 0.10627814  0.10556532  0.10204284  0.09156859  0.09717887  0.09567577\n",
      "   0.10468543  0.09432106  0.10606501  0.09661894]\n",
      " [ 0.09604082  0.10348831  0.1300233   0.10578997  0.09497467  0.09373117\n",
      "   0.08821034  0.08712249  0.10147779  0.09914108]\n",
      " [ 0.10301527  0.09414821  0.11043616  0.09341714  0.10453488  0.09831914\n",
      "   0.09718544  0.09679589  0.1045505   0.09759739]\n",
      " [ 0.10623694  0.09589592  0.1128412   0.10481483  0.10147811  0.09683634\n",
      "   0.09279305  0.09295598  0.09558351  0.10056411]\n",
      " [ 0.11067256  0.10990968  0.10033408  0.08290526  0.09392251  0.09772861\n",
      "   0.10880598  0.09208259  0.1022899   0.1013488 ]\n",
      " [ 0.10454933  0.09800496  0.09890355  0.09386975  0.10176174  0.10190909\n",
      "   0.1017955   0.09547155  0.10747171  0.09626291]\n",
      " [ 0.11002856  0.09755441  0.1179144   0.09142691  0.10875948  0.0877479\n",
      "   0.09257043  0.09126341  0.10746986  0.09526467]\n",
      " [ 0.11311655  0.09265475  0.10805448  0.08692417  0.09910417  0.0963884\n",
      "   0.08178276  0.10592563  0.10665484  0.10939422]\n",
      " [ 0.08795833  0.08148353  0.10650314  0.1072241   0.11215287  0.09092622\n",
      "   0.10027491  0.09581023  0.10215057  0.11551616]\n",
      " [ 0.10264149  0.11175799  0.09796467  0.10476241  0.09659417  0.09702234\n",
      "   0.09356849  0.09687353  0.10137705  0.09743785]\n",
      " [ 0.09696394  0.1014473   0.10930359  0.09313677  0.10574327  0.09272644\n",
      "   0.1042552   0.09235712  0.10098194  0.10308436]\n",
      " [ 0.10453233  0.1050821   0.10466283  0.09654156  0.1033939   0.09281851\n",
      "   0.09086935  0.09777737  0.09916122  0.10516076]\n",
      " [ 0.09831852  0.11546061  0.10876548  0.09926385  0.10369465  0.09660084\n",
      "   0.10016925  0.09329691  0.09459328  0.08983663]\n",
      " [ 0.09848311  0.08914649  0.10364427  0.10061894  0.1095427   0.093346\n",
      "   0.10153817  0.0937411   0.10328893  0.10665027]\n",
      " [ 0.09629448  0.09261568  0.10037089  0.1123378   0.10170077  0.0869161\n",
      "   0.09770193  0.08421975  0.11026573  0.11757687]\n",
      " [ 0.1011894   0.10651614  0.11277619  0.09759624  0.10229525  0.0890732\n",
      "   0.09118842  0.09128406  0.11107644  0.09700472]\n",
      " [ 0.10779715  0.10531216  0.10546026  0.09158282  0.09648802  0.09280217\n",
      "   0.08745511  0.09494497  0.10485142  0.11330587]\n",
      " [ 0.09412462  0.09074585  0.10391955  0.10078377  0.1009493   0.09784397\n",
      "   0.11157116  0.09585227  0.09960177  0.10460779]\n",
      " [ 0.08905312  0.09856915  0.11669539  0.0870906   0.09584111  0.09791363\n",
      "   0.11109491  0.09703795  0.10493309  0.101771  ]\n",
      " [ 0.10853889  0.09869451  0.11157995  0.09154624  0.09764963  0.09731255\n",
      "   0.10176741  0.09421052  0.09714416  0.10155617]\n",
      " [ 0.09572878  0.08947484  0.11487811  0.10040153  0.10426094  0.10221585\n",
      "   0.10566133  0.08794262  0.10644819  0.09298792]\n",
      " [ 0.09429314  0.10756149  0.1124793   0.10558987  0.09902523  0.0993794\n",
      "   0.10120835  0.10083345  0.0891721   0.09045769]\n",
      " [ 0.11381413  0.09847827  0.11463158  0.08904287  0.09318744  0.09253243\n",
      "   0.08827573  0.09277675  0.11631964  0.10094111]\n",
      " [ 0.10008955  0.11435579  0.10573468  0.09406268  0.09756774  0.09412987\n",
      "   0.08779085  0.09581994  0.11297817  0.09747077]\n",
      " [ 0.09519865  0.10554862  0.10103083  0.09724767  0.09869473  0.09753751\n",
      "   0.10638189  0.09376454  0.0988627   0.1057329 ]\n",
      " [ 0.11321894  0.08965696  0.10581298  0.0837477   0.10408974  0.0918455\n",
      "   0.09903773  0.10128577  0.10051401  0.11079064]\n",
      " [ 0.10920368  0.09126062  0.10965863  0.10203634  0.10059647  0.08644181\n",
      "   0.09971211  0.1042267   0.09992959  0.09693411]\n",
      " [ 0.10439119  0.1024175   0.10864484  0.09693466  0.10742091  0.09640168\n",
      "   0.10312954  0.08647051  0.1001281   0.09406117]\n",
      " [ 0.11085054  0.09668621  0.10368974  0.09948078  0.10946018  0.08511686\n",
      "   0.09731386  0.09624219  0.09471796  0.10644177]\n",
      " [ 0.08978602  0.10009894  0.10987546  0.10770344  0.10521957  0.08635248\n",
      "   0.09410822  0.09587338  0.09332625  0.11765622]\n",
      " [ 0.12148659  0.09058219  0.10207471  0.09825961  0.10736823  0.10306305\n",
      "   0.08766431  0.0913597   0.10838588  0.0897558 ]\n",
      " [ 0.09942399  0.08899681  0.10529856  0.09991055  0.10443964  0.09585258\n",
      "   0.10621299  0.09260178  0.09995291  0.10731021]\n",
      " [ 0.09726357  0.09555758  0.10407333  0.10015108  0.10643396  0.08514198\n",
      "   0.09798402  0.09662803  0.10724051  0.10952593]\n",
      " [ 0.10032856  0.10013759  0.09790666  0.09080371  0.09756355  0.09443337\n",
      "   0.1003972   0.09530728  0.11350539  0.10961661]\n",
      " [ 0.10427068  0.10315394  0.11730439  0.09310376  0.09317585  0.09961165\n",
      "   0.08711334  0.09805962  0.10544247  0.09876429]\n",
      " [ 0.10492853  0.09248478  0.1106864   0.10577101  0.10473897  0.08332799\n",
      "   0.09443653  0.09631915  0.10126486  0.10604176]\n",
      " [ 0.10345929  0.09877735  0.11609769  0.09869673  0.09591953  0.08452765\n",
      "   0.08916945  0.09823651  0.10892171  0.10619405]\n",
      " [ 0.1023602   0.11519954  0.10575369  0.10119796  0.10126855  0.09217518\n",
      "   0.09498546  0.08820967  0.09569539  0.10315426]\n",
      " [ 0.10518943  0.09603649  0.10780384  0.09822844  0.09767149  0.08829593\n",
      "   0.10397243  0.09865855  0.10038549  0.10375785]\n",
      " [ 0.10310614  0.10205861  0.10264295  0.10081532  0.09519119  0.09534523\n",
      "   0.09035933  0.09353322  0.11136714  0.10558085]\n",
      " [ 0.10564327  0.10672387  0.11093023  0.08754349  0.11062937  0.09838594\n",
      "   0.09172354  0.09151518  0.09631956  0.10058562]\n",
      " [ 0.09994347  0.09538835  0.10415169  0.10492402  0.09228165  0.08070324\n",
      "   0.10052507  0.09789333  0.10705632  0.11713291]\n",
      " [ 0.09457028  0.10468947  0.1194447   0.09196427  0.10999551  0.10083779\n",
      "   0.08854223  0.09412322  0.09400686  0.10182565]\n",
      " [ 0.10908373  0.10010141  0.11066984  0.09429637  0.10003181  0.09302146\n",
      "   0.09916191  0.08632251  0.10932917  0.09798182]\n",
      " [ 0.09331461  0.09330966  0.11184055  0.10046543  0.10661543  0.09855493\n",
      "   0.10433242  0.09137915  0.09585172  0.10433611]\n",
      " [ 0.09976128  0.0973493   0.11886904  0.08876799  0.1047942   0.09192607\n",
      "   0.09291705  0.10168141  0.10355796  0.10037573]\n",
      " [ 0.10088202  0.11133758  0.10729862  0.09001275  0.10292715  0.0984261\n",
      "   0.09253266  0.09959278  0.09553498  0.10145541]\n",
      " [ 0.09877747  0.08814263  0.1199801   0.08571222  0.1038176   0.09912964\n",
      "   0.10197082  0.09046493  0.1130531   0.09895154]\n",
      " [ 0.0969572   0.10527208  0.10536235  0.10453701  0.09681296  0.09843455\n",
      "   0.09812465  0.09341648  0.10066755  0.10041519]\n",
      " [ 0.1058017   0.10923875  0.09538034  0.09326231  0.10544952  0.09362544\n",
      "   0.08971389  0.09701702  0.10747103  0.10303997]\n",
      " [ 0.10056052  0.09921043  0.10829035  0.10990052  0.09438989  0.09768237\n",
      "   0.09726535  0.09971285  0.09931826  0.0936695 ]\n",
      " [ 0.09832404  0.0945797   0.10463244  0.09988957  0.11376984  0.07722815\n",
      "   0.08848024  0.09889121  0.1156731   0.10853175]\n",
      " [ 0.10811171  0.08986168  0.11093328  0.09401326  0.11199233  0.09676606\n",
      "   0.11534867  0.0798136   0.09659743  0.09656192]\n",
      " [ 0.09801469  0.098755    0.10547174  0.10100257  0.10119948  0.09337351\n",
      "   0.09706768  0.09726314  0.10346612  0.10438605]\n",
      " [ 0.10604654  0.09237597  0.10563609  0.10535866  0.103723    0.0880862\n",
      "   0.0870317   0.09808825  0.10027327  0.11338036]\n",
      " [ 0.11186089  0.09902931  0.11872049  0.09186877  0.10453109  0.09832928\n",
      "   0.09038641  0.09179635  0.09165394  0.10182349]\n",
      " [ 0.0970604   0.10920162  0.10645809  0.09697309  0.1082668   0.09198899\n",
      "   0.09757064  0.10125394  0.09431245  0.09691399]\n",
      " [ 0.10084814  0.11519079  0.11492736  0.09221061  0.09471527  0.09189709\n",
      "   0.09302575  0.1009376   0.09761241  0.09863502]\n",
      " [ 0.11420933  0.09538676  0.10409864  0.09461878  0.09557775  0.09448818\n",
      "   0.11010484  0.09633225  0.10316977  0.09201369]\n",
      " [ 0.09834998  0.10010534  0.11324962  0.09825294  0.09025956  0.09420487\n",
      "   0.10645122  0.09826647  0.09529842  0.10556158]\n",
      " [ 0.10171849  0.10359656  0.11437714  0.10711365  0.09234     0.08736271\n",
      "   0.08340356  0.09752865  0.11376385  0.09879532]\n",
      " [ 0.10187893  0.10370707  0.11050026  0.09667212  0.10180655  0.09565625\n",
      "   0.10148697  0.094543    0.09823518  0.09551363]\n",
      " [ 0.10046402  0.09621557  0.13521838  0.08876322  0.11203574  0.08730672\n",
      "   0.09105393  0.08439349  0.11045928  0.09408963]\n",
      " [ 0.09809472  0.10048219  0.10797586  0.09408599  0.10322385  0.09055541\n",
      "   0.10311449  0.10142134  0.10026368  0.10078244]\n",
      " [ 0.1205057   0.09630218  0.11118401  0.0972846   0.09145122  0.09131018\n",
      "   0.09751742  0.09517885  0.0934398   0.10582601]\n",
      " [ 0.10083215  0.08312228  0.11590637  0.10008267  0.11098976  0.09350612\n",
      "   0.09915847  0.093816    0.1038077   0.09877852]\n",
      " [ 0.10656849  0.08822875  0.10270425  0.0933624   0.09614308  0.09323321\n",
      "   0.10956108  0.0964582   0.10533989  0.10840065]\n",
      " [ 0.10635989  0.10223144  0.11229052  0.09636965  0.09045059  0.08176875\n",
      "   0.09649586  0.09243777  0.11273139  0.10886414]\n",
      " [ 0.11253618  0.08803208  0.10851642  0.08473585  0.09949877  0.0863407\n",
      "   0.10600377  0.09123818  0.09756435  0.12553373]\n",
      " [ 0.1034411   0.11162279  0.11270478  0.09601323  0.10157371  0.09658232\n",
      "   0.09296256  0.09441946  0.10393893  0.0867411 ]\n",
      " [ 0.10167133  0.10094537  0.11865189  0.09842534  0.0940443   0.1035887\n",
      "   0.09243846  0.09781151  0.09143614  0.10098702]\n",
      " [ 0.09328636  0.10679093  0.10356936  0.10410155  0.10914861  0.08841533\n",
      "   0.09058338  0.09764846  0.10501342  0.1014426 ]\n",
      " [ 0.09246806  0.09889963  0.10588428  0.09758621  0.10507596  0.0987597\n",
      "   0.09442279  0.09966927  0.10083257  0.10640156]\n",
      " [ 0.09584984  0.09952705  0.10841503  0.10472799  0.09608395  0.09743631\n",
      "   0.0972873   0.09429207  0.10838341  0.09799699]\n",
      " [ 0.09833667  0.09792858  0.11188667  0.08429115  0.09807283  0.10410391\n",
      "   0.10334868  0.09847369  0.10949604  0.0940618 ]\n",
      " [ 0.0877595   0.09258573  0.11921187  0.10159528  0.10300153  0.09904513\n",
      "   0.09873164  0.09021316  0.10777543  0.10008063]\n",
      " [ 0.10921968  0.10182271  0.10556415  0.09578905  0.09775334  0.09538391\n",
      "   0.09368111  0.0968443   0.10366629  0.10027549]\n",
      " [ 0.09618721  0.09905735  0.10561334  0.10488594  0.10617289  0.0891123\n",
      "   0.09718452  0.1003176   0.09853005  0.10293884]\n",
      " [ 0.11028744  0.09064956  0.1193652   0.09151362  0.09189896  0.09145993\n",
      "   0.09856894  0.10095931  0.10092996  0.10436705]\n",
      " [ 0.10061231  0.09178203  0.11294701  0.09814365  0.09844745  0.09208842\n",
      "   0.09501387  0.10197249  0.09525046  0.11374225]\n",
      " [ 0.09227149  0.10256395  0.10791829  0.09666438  0.11211405  0.08523329\n",
      "   0.09148471  0.10262462  0.09680284  0.11232241]\n",
      " [ 0.08930094  0.09035577  0.11351262  0.10123885  0.09958154  0.09682087\n",
      "   0.09949317  0.10488028  0.10601857  0.09879734]] (8.781 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.75875\n",
      "INFO:tensorflow:probabilities = [[ 0.10365096  0.10099898  0.10966524  0.08606413  0.09281744  0.10167474\n",
      "   0.10543618  0.09809866  0.09722827  0.10436539]\n",
      " [ 0.11101072  0.09751036  0.11308756  0.09404676  0.0917122   0.08925938\n",
      "   0.09656359  0.10328914  0.10106134  0.10245898]\n",
      " [ 0.08864693  0.08252345  0.1043193   0.09240464  0.10265363  0.09320416\n",
      "   0.10473664  0.09943101  0.11623256  0.11584768]\n",
      " [ 0.0919386   0.10852046  0.10250773  0.09951634  0.10029607  0.10107846\n",
      "   0.09604774  0.09099843  0.11227362  0.09682255]\n",
      " [ 0.09038034  0.09405731  0.10380433  0.09087412  0.1065059   0.0971052\n",
      "   0.09741065  0.0948163   0.10507613  0.11996975]\n",
      " [ 0.10773504  0.09204888  0.10482279  0.09597263  0.09980365  0.10538612\n",
      "   0.10159498  0.09604255  0.09765579  0.0989375 ]\n",
      " [ 0.10899583  0.09034512  0.10740509  0.08520948  0.09319158  0.09700979\n",
      "   0.09365005  0.0879484   0.11102623  0.12521848]\n",
      " [ 0.0995454   0.10256696  0.09725852  0.10206163  0.09825826  0.09898012\n",
      "   0.10098229  0.09325687  0.10016499  0.10692498]\n",
      " [ 0.10051723  0.09929053  0.10988395  0.09124019  0.09292977  0.09991137\n",
      "   0.09598454  0.09241984  0.11001789  0.10780466]\n",
      " [ 0.11665025  0.08981243  0.12134844  0.09437795  0.11111481  0.09013926\n",
      "   0.09550191  0.0824986   0.09746104  0.10109533]\n",
      " [ 0.12140024  0.0892508   0.10665698  0.1087174   0.09522941  0.09393994\n",
      "   0.09445079  0.1064756   0.10011416  0.08376466]\n",
      " [ 0.09303702  0.09865172  0.10902771  0.09490933  0.1163355   0.09147459\n",
      "   0.10190228  0.09076136  0.10527037  0.09863006]\n",
      " [ 0.09317576  0.09835437  0.09362274  0.10402847  0.09805723  0.10095303\n",
      "   0.08376589  0.10504994  0.1062527   0.11673986]\n",
      " [ 0.1181251   0.10626397  0.10584173  0.09417752  0.1101509   0.08749421\n",
      "   0.09321703  0.08814541  0.10548215  0.09110195]\n",
      " [ 0.10042269  0.10163327  0.11359403  0.09631867  0.09817421  0.10576127\n",
      "   0.09600059  0.09590862  0.0907459   0.10144074]\n",
      " [ 0.09918854  0.09479032  0.10576383  0.1157933   0.10711516  0.10150812\n",
      "   0.09576793  0.0891772   0.0884786   0.10241698]\n",
      " [ 0.09973229  0.0937672   0.10622661  0.10086662  0.10234367  0.10145901\n",
      "   0.09639702  0.09132667  0.1117043   0.09617658]\n",
      " [ 0.09707405  0.1027521   0.10848464  0.09905261  0.09709416  0.08648581\n",
      "   0.09909341  0.09530696  0.10761098  0.1070453 ]\n",
      " [ 0.10021334  0.09672039  0.10199025  0.09157621  0.09857774  0.0886241\n",
      "   0.10434286  0.10371649  0.10541921  0.10881941]\n",
      " [ 0.09756967  0.08370995  0.11185648  0.09566408  0.09931955  0.09306226\n",
      "   0.09586928  0.11271543  0.1069659   0.10326739]\n",
      " [ 0.1000269   0.08696233  0.10037805  0.09585542  0.10378492  0.08833663\n",
      "   0.09886068  0.09323061  0.12725948  0.10530496]\n",
      " [ 0.1062525   0.10799557  0.10630354  0.08826171  0.09783536  0.09002846\n",
      "   0.09517997  0.08636445  0.11239032  0.10938822]\n",
      " [ 0.10898591  0.10066978  0.11694475  0.10143929  0.08909722  0.10342117\n",
      "   0.09763341  0.09283648  0.09412257  0.0948495 ]\n",
      " [ 0.10835797  0.10168505  0.10062584  0.09518027  0.10259692  0.09098773\n",
      "   0.09478899  0.09515986  0.10773952  0.1028778 ]\n",
      " [ 0.11810459  0.09179074  0.11379585  0.08976565  0.09279127  0.09965066\n",
      "   0.10920253  0.0966089   0.08992124  0.09836856]\n",
      " [ 0.10072736  0.0964177   0.10193834  0.09286904  0.10974561  0.09705402\n",
      "   0.09767663  0.09353683  0.10384127  0.10619323]\n",
      " [ 0.1044709   0.09900729  0.10839069  0.09398904  0.10007641  0.09706031\n",
      "   0.09885828  0.10448981  0.09873945  0.0949178 ]\n",
      " [ 0.10890024  0.10163505  0.10857793  0.09284051  0.10427439  0.09554002\n",
      "   0.09377252  0.08896526  0.09728802  0.10820603]\n",
      " [ 0.09215741  0.11084934  0.10427766  0.10861958  0.09747428  0.09792184\n",
      "   0.09020048  0.08845796  0.10204971  0.10799173]\n",
      " [ 0.09364863  0.08561614  0.11068672  0.10740498  0.10589612  0.09225375\n",
      "   0.09365863  0.09230229  0.11047207  0.10806071]\n",
      " [ 0.10741844  0.0965699   0.11581663  0.09471726  0.10166112  0.09337396\n",
      "   0.09146606  0.09627654  0.09868775  0.10401231]\n",
      " [ 0.10360499  0.08952756  0.10302363  0.09526987  0.11261342  0.09754607\n",
      "   0.09980131  0.09039097  0.11713991  0.09108222]\n",
      " [ 0.11459552  0.0992444   0.1063391   0.08486417  0.09917812  0.09313232\n",
      "   0.10780706  0.09132886  0.11106545  0.09244502]\n",
      " [ 0.09615108  0.09261474  0.10305674  0.09676813  0.10442148  0.09113462\n",
      "   0.09831285  0.09444508  0.11632514  0.10677009]\n",
      " [ 0.12433013  0.0996349   0.11029302  0.09056945  0.09422854  0.09947792\n",
      "   0.09465512  0.09017769  0.09390602  0.10272723]\n",
      " [ 0.10475312  0.09426682  0.1048236   0.105179    0.10083289  0.09633603\n",
      "   0.10146943  0.09205486  0.10025966  0.10002459]\n",
      " [ 0.10587135  0.08829749  0.12375244  0.09427418  0.09853965  0.08478412\n",
      "   0.1009136   0.08968579  0.10417805  0.10970337]\n",
      " [ 0.10570247  0.10332556  0.10176001  0.090673    0.10525206  0.09286436\n",
      "   0.08961171  0.09993671  0.10569412  0.10517997]\n",
      " [ 0.10260401  0.09589378  0.1171858   0.10201875  0.10455256  0.10064834\n",
      "   0.10233656  0.08350439  0.09360012  0.09765574]\n",
      " [ 0.10355866  0.09469203  0.10267502  0.10512611  0.10450277  0.09340417\n",
      "   0.08899731  0.10152415  0.09661439  0.10890535]\n",
      " [ 0.10021872  0.08630029  0.10541124  0.1054915   0.09866339  0.10717387\n",
      "   0.10766753  0.08209851  0.10522336  0.10175156]\n",
      " [ 0.09483937  0.09684203  0.10497794  0.09252125  0.10892627  0.09204126\n",
      "   0.09790664  0.09282959  0.11394901  0.10516658]\n",
      " [ 0.10135798  0.09954239  0.1030185   0.09205206  0.11032544  0.09142285\n",
      "   0.09346874  0.10157713  0.09879304  0.10844187]\n",
      " [ 0.12640508  0.09451552  0.10636055  0.09761848  0.0900691   0.09259617\n",
      "   0.09291141  0.08392677  0.10599354  0.10960345]\n",
      " [ 0.09990993  0.09746599  0.1092288   0.10146388  0.10388243  0.09819844\n",
      "   0.09921812  0.09245704  0.10165154  0.09652381]\n",
      " [ 0.09908225  0.10477871  0.10758828  0.09255689  0.09290773  0.09151319\n",
      "   0.10574831  0.10207097  0.11525234  0.0885013 ]\n",
      " [ 0.10942201  0.1119034   0.11914713  0.09322497  0.09826026  0.09291381\n",
      "   0.0968862   0.09068919  0.09760648  0.08994643]\n",
      " [ 0.10584337  0.09327538  0.11053685  0.10059196  0.10127698  0.09097912\n",
      "   0.0953726   0.0929461   0.10811854  0.10105915]\n",
      " [ 0.10382676  0.09965843  0.10704466  0.09748081  0.10531939  0.09219849\n",
      "   0.09740594  0.09030709  0.10659666  0.10016174]\n",
      " [ 0.11795185  0.09419511  0.11697373  0.09775916  0.09148559  0.09553323\n",
      "   0.10005119  0.08687811  0.10379975  0.09537238]\n",
      " [ 0.10653767  0.1064539   0.09832105  0.10080069  0.10896792  0.09577777\n",
      "   0.10025804  0.08820152  0.0963548   0.09832671]\n",
      " [ 0.10124826  0.08925311  0.10929959  0.0997097   0.10184018  0.09494214\n",
      "   0.09832112  0.09001796  0.11289911  0.10246881]\n",
      " [ 0.09826268  0.09224268  0.11032505  0.10204184  0.09957504  0.09542887\n",
      "   0.09821281  0.09957458  0.09877654  0.10555993]\n",
      " [ 0.10352408  0.09307113  0.11798104  0.09764881  0.09126292  0.09196249\n",
      "   0.08585163  0.09450458  0.10454438  0.11964887]\n",
      " [ 0.10235054  0.10468016  0.11012523  0.09955896  0.10239375  0.09398858\n",
      "   0.08733726  0.10503168  0.0971836   0.09735028]\n",
      " [ 0.09847443  0.10631308  0.10381272  0.0920446   0.10609889  0.09488202\n",
      "   0.09681545  0.09880164  0.10250659  0.10025053]\n",
      " [ 0.10947449  0.09491032  0.10460524  0.1000938   0.09442727  0.09935334\n",
      "   0.10661896  0.08302386  0.10120513  0.10628765]\n",
      " [ 0.10435002  0.09522886  0.10529061  0.10258921  0.09973679  0.0908307\n",
      "   0.10935957  0.09325561  0.0975971   0.10176148]\n",
      " [ 0.0884048   0.10480443  0.10674035  0.10298936  0.09290225  0.09274253\n",
      "   0.10945802  0.09396631  0.10478374  0.10320821]\n",
      " [ 0.12894052  0.09022082  0.11151807  0.08758136  0.08894175  0.10683005\n",
      "   0.09652581  0.08709632  0.10058015  0.10176514]\n",
      " [ 0.09408264  0.0965124   0.11761819  0.10200971  0.0997947   0.10193752\n",
      "   0.09169754  0.10485967  0.09607675  0.09541094]\n",
      " [ 0.09768608  0.10618484  0.1060218   0.09772293  0.09535904  0.09740584\n",
      "   0.09852214  0.08737711  0.10934643  0.10437377]\n",
      " [ 0.10796078  0.08826077  0.10752     0.09888072  0.1055245   0.09237619\n",
      "   0.09600511  0.09201582  0.10414876  0.1073074 ]\n",
      " [ 0.1081414   0.09355001  0.11420548  0.10181478  0.09333907  0.08947758\n",
      "   0.09419961  0.09394638  0.10617355  0.10515219]\n",
      " [ 0.11197768  0.10623717  0.11176169  0.09250938  0.09719816  0.09514486\n",
      "   0.09243683  0.09614204  0.09785959  0.0987326 ]\n",
      " [ 0.10477408  0.09006094  0.10074703  0.09423614  0.10211071  0.09421047\n",
      "   0.11257759  0.09014234  0.10164161  0.10949907]\n",
      " [ 0.10858982  0.09780832  0.09994163  0.0998361   0.1082151   0.08879579\n",
      "   0.08835647  0.09468791  0.09570004  0.11806876]\n",
      " [ 0.10080226  0.09787995  0.11568171  0.09828835  0.10074794  0.08437935\n",
      "   0.08990752  0.08843434  0.10882776  0.11505086]\n",
      " [ 0.09310406  0.09949515  0.10675269  0.10397043  0.10534754  0.09612479\n",
      "   0.08575151  0.10002519  0.10651585  0.1029128 ]\n",
      " [ 0.10057034  0.10373331  0.10838668  0.11808034  0.09562247  0.09068244\n",
      "   0.09739862  0.0854212   0.10508626  0.09501832]\n",
      " [ 0.10058726  0.09858482  0.10826933  0.08473162  0.10029028  0.0984925\n",
      "   0.09958566  0.09871012  0.10971752  0.1010309 ]\n",
      " [ 0.11713217  0.09837406  0.10103686  0.09860466  0.08965334  0.1004542\n",
      "   0.09261514  0.10133037  0.1024991   0.09830009]\n",
      " [ 0.0942499   0.10470426  0.09670953  0.09337272  0.10534162  0.10170832\n",
      "   0.10647463  0.09078736  0.10231691  0.10433476]\n",
      " [ 0.11209592  0.09253069  0.10444394  0.09671339  0.11330516  0.08912011\n",
      "   0.0922472   0.0950053   0.09423883  0.11029951]\n",
      " [ 0.12757652  0.10740341  0.10825934  0.08458149  0.08942254  0.10718091\n",
      "   0.0942212   0.09277812  0.09657347  0.09200296]\n",
      " [ 0.10643212  0.09351347  0.12354803  0.09042543  0.09942891  0.08461145\n",
      "   0.10225111  0.09829026  0.09801995  0.10347934]\n",
      " [ 0.10416417  0.09654822  0.09994285  0.10326218  0.1101938   0.08392752\n",
      "   0.10406467  0.09032848  0.10666785  0.10090024]\n",
      " [ 0.09649584  0.10611047  0.10117992  0.10133646  0.10076387  0.09950877\n",
      "   0.10359395  0.0970083   0.09903433  0.09496811]\n",
      " [ 0.11161833  0.09749853  0.11805917  0.10222202  0.08800069  0.09208695\n",
      "   0.08963802  0.09110047  0.11558356  0.09419225]\n",
      " [ 0.09865363  0.09454765  0.09767076  0.10475103  0.10062174  0.08913533\n",
      "   0.09974641  0.09743363  0.10442766  0.11301211]\n",
      " [ 0.10993599  0.09990888  0.09718226  0.11186115  0.09739614  0.08801264\n",
      "   0.0878096   0.08772208  0.10986765  0.11030361]\n",
      " [ 0.10214671  0.10052832  0.1096018   0.09638788  0.10212827  0.09345795\n",
      "   0.09871116  0.10347492  0.09980805  0.09375487]\n",
      " [ 0.11069547  0.10878102  0.11400291  0.08894979  0.09479734  0.08924286\n",
      "   0.09541091  0.09989613  0.09951901  0.09870458]\n",
      " [ 0.09899487  0.09952138  0.09238129  0.10698551  0.10967918  0.11015495\n",
      "   0.09030188  0.09444252  0.10047191  0.09706657]\n",
      " [ 0.09679329  0.09479753  0.11123851  0.09442253  0.0980407   0.09966061\n",
      "   0.09757679  0.10103781  0.10290781  0.10352445]\n",
      " [ 0.10191713  0.0952133   0.10961294  0.09329026  0.10299443  0.0919819\n",
      "   0.10918384  0.09393178  0.10791445  0.09395991]\n",
      " [ 0.0934929   0.10412453  0.10128117  0.10011072  0.10493991  0.09681202\n",
      "   0.1015057   0.09964082  0.10257456  0.09551774]\n",
      " [ 0.0991681   0.09849     0.10488968  0.104953    0.10707675  0.09813379\n",
      "   0.08281685  0.09219278  0.11115495  0.10112414]\n",
      " [ 0.11222356  0.10580447  0.09974988  0.08602966  0.10544471  0.09503206\n",
      "   0.09398408  0.0989494   0.10381699  0.09896518]\n",
      " [ 0.10588729  0.08800517  0.10358081  0.0931529   0.1062286   0.10022874\n",
      "   0.10486889  0.10061617  0.09577236  0.10165899]\n",
      " [ 0.10031884  0.09596143  0.11085892  0.0948185   0.11122515  0.09767383\n",
      "   0.1047065   0.08995363  0.09752583  0.09695733]\n",
      " [ 0.10523143  0.09253405  0.09863788  0.08828068  0.10474375  0.09429707\n",
      "   0.0983699   0.10170566  0.10381714  0.11238245]\n",
      " [ 0.099284    0.07770058  0.11117312  0.10273378  0.10598568  0.0905884\n",
      "   0.10009287  0.09127291  0.09973226  0.12143639]\n",
      " [ 0.11839087  0.09293984  0.10478192  0.09250266  0.09719474  0.10043729\n",
      "   0.08540122  0.0894407   0.11744384  0.1014669 ]\n",
      " [ 0.10164914  0.08749878  0.10654785  0.11041315  0.0947253   0.08560517\n",
      "   0.10161962  0.09180312  0.1087243   0.11141354]\n",
      " [ 0.0933595   0.08490884  0.11757163  0.09263278  0.10189239  0.09351297\n",
      "   0.09583034  0.09759653  0.11755282  0.10514215]\n",
      " [ 0.107958    0.09795295  0.11206371  0.08884557  0.09659532  0.09663394\n",
      "   0.09741911  0.09242562  0.1068854   0.10322041]\n",
      " [ 0.09135228  0.08180579  0.11830045  0.11178082  0.10047202  0.08462033\n",
      "   0.09001765  0.10617411  0.09605407  0.11942242]\n",
      " [ 0.09693719  0.10568287  0.10148481  0.09868019  0.10407868  0.08802135\n",
      "   0.09774605  0.08992764  0.1147531   0.1026881 ]\n",
      " [ 0.09931197  0.09297566  0.11127146  0.09943268  0.1125806   0.0897534\n",
      "   0.09299827  0.08779938  0.10350712  0.11036934]] (8.584 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.27058, step = 301 (17.361 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.1131577   0.09675296  0.09540453  0.09044904  0.09653153  0.08859177\n",
      "   0.10722481  0.08890064  0.10855458  0.11443251]\n",
      " [ 0.10703117  0.0896555   0.12105308  0.09120834  0.09390164  0.10693609\n",
      "   0.10653071  0.09356488  0.10482828  0.08529034]\n",
      " [ 0.109855    0.08190377  0.11431524  0.11165275  0.09616812  0.09607257\n",
      "   0.09449615  0.09419841  0.09997874  0.10135924]\n",
      " [ 0.08876859  0.10421252  0.10209149  0.09480957  0.10325523  0.08431839\n",
      "   0.10166122  0.10375717  0.10507458  0.1120512 ]\n",
      " [ 0.10005927  0.09786503  0.105137    0.10953817  0.09701934  0.09618302\n",
      "   0.09360064  0.09580413  0.09318471  0.11160868]\n",
      " [ 0.1080053   0.09027644  0.11073516  0.10012959  0.09804603  0.09382466\n",
      "   0.10501713  0.08993278  0.11154651  0.09248635]\n",
      " [ 0.09976228  0.11321472  0.10228534  0.09408642  0.1058211   0.09389677\n",
      "   0.09223187  0.09638417  0.101551    0.10076633]\n",
      " [ 0.13531882  0.09472693  0.11214408  0.09955589  0.09512264  0.08662039\n",
      "   0.08848403  0.08671256  0.09955095  0.10176364]\n",
      " [ 0.08722647  0.09672157  0.11513916  0.09899557  0.10629967  0.09420855\n",
      "   0.10104576  0.08632478  0.10556745  0.10847096]\n",
      " [ 0.09837631  0.10308829  0.11253073  0.09740566  0.09929593  0.09151068\n",
      "   0.10427116  0.1002419   0.10369763  0.08958174]\n",
      " [ 0.09148883  0.10023618  0.11448472  0.09840108  0.09845274  0.09997409\n",
      "   0.09990998  0.098527    0.0981449   0.10038047]\n",
      " [ 0.09208391  0.08682752  0.09918278  0.10249589  0.12461013  0.09332472\n",
      "   0.09299663  0.08935165  0.11044212  0.10868474]\n",
      " [ 0.09849977  0.10594525  0.09904949  0.09221257  0.10654548  0.11041763\n",
      "   0.10109351  0.0887318   0.10566361  0.0918409 ]\n",
      " [ 0.1170699   0.10519535  0.10735946  0.08767007  0.09194468  0.09711775\n",
      "   0.08631051  0.09175774  0.1137711   0.10180344]\n",
      " [ 0.09613775  0.07918614  0.11192184  0.10901343  0.11430442  0.08763616\n",
      "   0.09437894  0.09699656  0.10490969  0.10551511]\n",
      " [ 0.09813502  0.09355611  0.12702209  0.1093449   0.09895771  0.0911156\n",
      "   0.10563204  0.07230124  0.10236885  0.10156637]\n",
      " [ 0.12251769  0.09234194  0.10324852  0.10489222  0.10500794  0.07606045\n",
      "   0.09009289  0.09254069  0.10160003  0.1116975 ]\n",
      " [ 0.09893566  0.09176385  0.1009118   0.10134123  0.09573572  0.10086883\n",
      "   0.10308958  0.09366507  0.11297224  0.10071593]\n",
      " [ 0.10126235  0.09981236  0.10755778  0.1142253   0.09266589  0.09215195\n",
      "   0.10029218  0.098811    0.10316499  0.09005621]\n",
      " [ 0.1309185   0.09219915  0.11421161  0.0859835   0.10201667  0.08501127\n",
      "   0.09060404  0.09614542  0.10665508  0.0962547 ]\n",
      " [ 0.11291754  0.09537731  0.11236751  0.10354923  0.09291486  0.09388814\n",
      "   0.09312808  0.08871137  0.1056357   0.10151032]\n",
      " [ 0.14030489  0.09779206  0.10283985  0.0897399   0.09497826  0.09263399\n",
      "   0.10221711  0.08431331  0.09523227  0.09994832]\n",
      " [ 0.09883801  0.10237614  0.11065642  0.09244253  0.09868944  0.09642294\n",
      "   0.09384616  0.10009055  0.1101202   0.09651764]\n",
      " [ 0.09719037  0.10108072  0.10491129  0.09597421  0.09972664  0.10329009\n",
      "   0.09077834  0.10310934  0.10349555  0.10044342]\n",
      " [ 0.08951005  0.08890234  0.10973258  0.10718598  0.09976145  0.09025066\n",
      "   0.09955041  0.09179269  0.1128019   0.11051188]\n",
      " [ 0.09921359  0.08966327  0.11874943  0.09513561  0.09578431  0.09672702\n",
      "   0.09885693  0.09538643  0.09721046  0.11327298]\n",
      " [ 0.0907139   0.09426257  0.10348336  0.12568665  0.10665739  0.09329918\n",
      "   0.08817416  0.09600716  0.0980103   0.10370538]\n",
      " [ 0.10168836  0.08091666  0.12714089  0.10315517  0.0922568   0.1046543\n",
      "   0.09334905  0.08602295  0.11315811  0.0976577 ]\n",
      " [ 0.11250743  0.09044623  0.10317239  0.10553045  0.10178328  0.09660255\n",
      "   0.09116397  0.09458651  0.1028956   0.10131166]\n",
      " [ 0.09656465  0.09391943  0.10063113  0.09334343  0.10929718  0.09382319\n",
      "   0.09143283  0.10122979  0.11507891  0.10467955]\n",
      " [ 0.09278243  0.08471803  0.10955363  0.10121465  0.10252168  0.09412775\n",
      "   0.11326747  0.10174067  0.10199632  0.09807739]\n",
      " [ 0.09737169  0.09119739  0.102069    0.10029787  0.10355674  0.09353006\n",
      "   0.09708682  0.09310454  0.11342359  0.10836226]\n",
      " [ 0.10883316  0.09091574  0.1170516   0.105702    0.09853353  0.08426651\n",
      "   0.08426454  0.09933177  0.10193224  0.10916892]\n",
      " [ 0.09555857  0.10174803  0.10858512  0.09541395  0.10574295  0.08976566\n",
      "   0.10867646  0.09774312  0.10352758  0.09323855]\n",
      " [ 0.09931     0.09794704  0.1120794   0.08944684  0.09336868  0.10065754\n",
      "   0.11599595  0.0842321   0.10901634  0.09794615]\n",
      " [ 0.10397795  0.09634191  0.10820448  0.10335415  0.10313795  0.08659991\n",
      "   0.09697697  0.09736931  0.10055056  0.10348683]\n",
      " [ 0.09998379  0.08625099  0.11342586  0.09833387  0.09474088  0.08896403\n",
      "   0.10031234  0.10078511  0.10343684  0.11376626]\n",
      " [ 0.09487773  0.09366212  0.10632832  0.10434272  0.09473773  0.08508531\n",
      "   0.1065282   0.10120044  0.10191259  0.11132488]\n",
      " [ 0.0983728   0.09470956  0.10363384  0.10483298  0.10638743  0.08980572\n",
      "   0.09223154  0.10210045  0.10309982  0.10482579]\n",
      " [ 0.09707094  0.08262646  0.11064099  0.09808124  0.11248607  0.08760233\n",
      "   0.09453747  0.1009542   0.09853003  0.11747035]\n",
      " [ 0.10204271  0.09876982  0.10344331  0.09887285  0.09345011  0.1036929\n",
      "   0.10009722  0.10398474  0.09596993  0.09967647]\n",
      " [ 0.09755456  0.08583628  0.10765706  0.10977554  0.10268083  0.09050928\n",
      "   0.08897693  0.09836703  0.10220758  0.11643498]\n",
      " [ 0.10119977  0.08453042  0.11817855  0.10809495  0.08696938  0.10208219\n",
      "   0.09802048  0.08480742  0.10551047  0.11060635]\n",
      " [ 0.10019719  0.10135807  0.10996111  0.10480037  0.09658082  0.09892064\n",
      "   0.09343977  0.09676116  0.10217764  0.09580325]\n",
      " [ 0.10755234  0.08502689  0.11087769  0.10346591  0.11491951  0.08889388\n",
      "   0.09470899  0.09187644  0.10566916  0.09700918]\n",
      " [ 0.10417126  0.08404464  0.11808036  0.09675792  0.09556039  0.09296027\n",
      "   0.09156086  0.09131733  0.11610225  0.10944467]\n",
      " [ 0.08933749  0.09764103  0.10227881  0.09171139  0.09742724  0.10876865\n",
      "   0.110189    0.09932274  0.10506801  0.09825569]\n",
      " [ 0.10160816  0.09570065  0.10584003  0.10730539  0.10187844  0.09163111\n",
      "   0.09880158  0.09148292  0.10950982  0.09624181]\n",
      " [ 0.10948966  0.10096579  0.1197357   0.10243151  0.09874772  0.08908749\n",
      "   0.08534846  0.08952141  0.10615988  0.09851243]\n",
      " [ 0.09124812  0.08963726  0.11085921  0.09303792  0.108398    0.09553154\n",
      "   0.07917836  0.10575213  0.10326118  0.12309634]\n",
      " [ 0.1184233   0.07302162  0.10844456  0.09528261  0.10324893  0.09923846\n",
      "   0.09620643  0.08567753  0.11278695  0.10766964]\n",
      " [ 0.10837474  0.09368595  0.10967889  0.100697    0.09147687  0.10564216\n",
      "   0.08604369  0.09935155  0.10663541  0.09841371]\n",
      " [ 0.10977198  0.09916134  0.11267367  0.09013457  0.10003531  0.09511904\n",
      "   0.09526005  0.09639447  0.09913469  0.10231493]\n",
      " [ 0.09295104  0.09656972  0.09650484  0.10292606  0.10588093  0.09297869\n",
      "   0.10532158  0.08984794  0.11146645  0.10555276]\n",
      " [ 0.09606174  0.08740748  0.11329725  0.10947912  0.0945025   0.09375682\n",
      "   0.10603885  0.10084608  0.1049408   0.0936693 ]\n",
      " [ 0.10253063  0.1093801   0.10139507  0.09951541  0.09086493  0.09965691\n",
      "   0.10461454  0.09721936  0.10215838  0.09266474]\n",
      " [ 0.14677122  0.09574451  0.10000101  0.0925153   0.10806802  0.08648165\n",
      "   0.09780199  0.08490787  0.08694518  0.10076323]\n",
      " [ 0.10185923  0.09748211  0.11692457  0.11073063  0.09918544  0.09352857\n",
      "   0.0923351   0.088033    0.10102466  0.09889678]\n",
      " [ 0.09741856  0.09986988  0.11227626  0.09539706  0.09088466  0.09770777\n",
      "   0.09883314  0.10092335  0.10979845  0.09689089]\n",
      " [ 0.09782148  0.08907221  0.12013437  0.09645621  0.09469757  0.08199193\n",
      "   0.10112911  0.10416587  0.10860289  0.10592835]\n",
      " [ 0.10638172  0.08798027  0.11076263  0.11183827  0.09316681  0.08824537\n",
      "   0.09490853  0.09903256  0.10200545  0.10567833]\n",
      " [ 0.09992903  0.09339152  0.09868223  0.11772491  0.09239358  0.10005745\n",
      "   0.09511593  0.09980386  0.09416652  0.10873498]\n",
      " [ 0.10245515  0.0883588   0.09761451  0.11339642  0.10552513  0.08768544\n",
      "   0.09437339  0.09391093  0.10980393  0.10687631]\n",
      " [ 0.10583248  0.09833973  0.10107383  0.08890086  0.09165509  0.10664476\n",
      "   0.10190161  0.10609204  0.10579026  0.09376936]\n",
      " [ 0.10387532  0.0889949   0.1116528   0.10283588  0.09888856  0.09220996\n",
      "   0.08847991  0.09301542  0.10732166  0.11272555]\n",
      " [ 0.09215552  0.10462096  0.09992193  0.09717256  0.10279754  0.09671521\n",
      "   0.09094296  0.10779405  0.10851622  0.09936296]\n",
      " [ 0.08404602  0.09430257  0.08865097  0.09288845  0.11122003  0.10086606\n",
      "   0.10160867  0.10696325  0.1041021   0.11535189]\n",
      " [ 0.09750214  0.10182596  0.1118686   0.09563785  0.10286254  0.09385297\n",
      "   0.09343106  0.10009187  0.10008403  0.10284299]\n",
      " [ 0.0919598   0.09575602  0.12032792  0.10605008  0.09865814  0.09203568\n",
      "   0.09593611  0.08830655  0.11040341  0.10056625]\n",
      " [ 0.08900827  0.11119013  0.10513884  0.09447432  0.10645947  0.09141405\n",
      "   0.10133368  0.09629678  0.09590376  0.10878073]\n",
      " [ 0.09224886  0.09835551  0.10143011  0.09350123  0.09927464  0.08406985\n",
      "   0.10509998  0.10520387  0.10999952  0.11081643]\n",
      " [ 0.10814962  0.09686595  0.10473164  0.10943472  0.0998075   0.08808129\n",
      "   0.09798542  0.08442935  0.09497901  0.11553554]\n",
      " [ 0.11841305  0.08887467  0.11495201  0.09917791  0.09724709  0.08616312\n",
      "   0.08905812  0.09864882  0.10989513  0.09757008]\n",
      " [ 0.10791242  0.10060538  0.11810762  0.09553893  0.09956528  0.08819683\n",
      "   0.09617651  0.0975525   0.10063683  0.09570775]\n",
      " [ 0.08773842  0.09137163  0.10892075  0.10607807  0.10769735  0.0893271\n",
      "   0.0985996   0.1001104   0.10509359  0.10506306]\n",
      " [ 0.09829861  0.09337109  0.11550862  0.10236486  0.09069498  0.0915092\n",
      "   0.09518816  0.08997206  0.10473645  0.11835595]\n",
      " [ 0.09150675  0.10973298  0.10952982  0.10247805  0.09795991  0.09257636\n",
      "   0.09961436  0.09751617  0.10138202  0.09770355]\n",
      " [ 0.10509921  0.1033479   0.11158671  0.09067626  0.09963485  0.09189547\n",
      "   0.09850469  0.09028328  0.1039068   0.10506479]\n",
      " [ 0.08971962  0.08542022  0.1042355   0.11903539  0.09974348  0.08926796\n",
      "   0.09775434  0.09566279  0.10306063  0.11610009]\n",
      " [ 0.10617919  0.11132336  0.10651179  0.0897714   0.09805538  0.09659414\n",
      "   0.1088518   0.0796029   0.10305012  0.10005993]\n",
      " [ 0.0837201   0.09160136  0.12644316  0.10310005  0.09903048  0.08829805\n",
      "   0.09850526  0.086791    0.10121679  0.12129377]\n",
      " [ 0.09707889  0.09331841  0.10667299  0.10840218  0.10296725  0.09054196\n",
      "   0.10218268  0.08734363  0.10333653  0.10815553]\n",
      " [ 0.11174823  0.10579222  0.11562105  0.09871358  0.08743483  0.11227694\n",
      "   0.0835978   0.09210379  0.11003906  0.08267254]\n",
      " [ 0.09940787  0.10352487  0.1001004   0.09544118  0.09775309  0.09474259\n",
      "   0.10098985  0.09424203  0.11012941  0.10366879]\n",
      " [ 0.10996981  0.0910092   0.11616752  0.10692326  0.09099291  0.09564873\n",
      "   0.09782395  0.08746298  0.09547435  0.10852727]\n",
      " [ 0.10505852  0.0946886   0.11586788  0.09998504  0.09611733  0.08352254\n",
      "   0.09826344  0.09401346  0.10239666  0.11008654]\n",
      " [ 0.10490224  0.09567607  0.10597117  0.10202263  0.10529961  0.09032845\n",
      "   0.09362011  0.09571251  0.11048596  0.09598127]\n",
      " [ 0.10694659  0.09429543  0.10724515  0.09750396  0.09850933  0.1046955\n",
      "   0.09967653  0.08883603  0.1000512   0.10224028]\n",
      " [ 0.09485339  0.09143358  0.10555286  0.10226383  0.09876882  0.1038292\n",
      "   0.09601247  0.10585108  0.10330611  0.09812871]\n",
      " [ 0.10239685  0.08756994  0.10784809  0.09838546  0.09995878  0.11136688\n",
      "   0.09822813  0.09385213  0.10634285  0.09405082]\n",
      " [ 0.11553473  0.08196966  0.10214143  0.10287712  0.1004063   0.08084761\n",
      "   0.10290718  0.09245765  0.10610951  0.1147488 ]\n",
      " [ 0.11438517  0.09835573  0.10760324  0.10543834  0.09387043  0.09972937\n",
      "   0.09808156  0.09081813  0.08945414  0.10226389]\n",
      " [ 0.09556891  0.09470206  0.10786276  0.09735481  0.10174054  0.08903797\n",
      "   0.100447    0.09872967  0.10644771  0.10810854]\n",
      " [ 0.09755864  0.08751243  0.11616105  0.09882741  0.11042774  0.0928914\n",
      "   0.10644751  0.08516806  0.10576633  0.09923945]\n",
      " [ 0.1027506   0.09854461  0.11392231  0.09338415  0.09235848  0.09499177\n",
      "   0.10222079  0.09308241  0.10897609  0.0997688 ]\n",
      " [ 0.09262725  0.10165332  0.09708323  0.09940547  0.10166064  0.10837793\n",
      "   0.08732122  0.1026259   0.10648684  0.10275821]\n",
      " [ 0.11244524  0.10103282  0.12414014  0.0884906   0.09555449  0.09538268\n",
      "   0.1063835   0.0944571   0.09068515  0.09142834]\n",
      " [ 0.10176519  0.08818563  0.11655895  0.10965763  0.09981173  0.09105411\n",
      "   0.10092002  0.09082419  0.10726673  0.0939558 ]\n",
      " [ 0.11283021  0.09411412  0.09934302  0.09809048  0.09680781  0.09252609\n",
      "   0.10263238  0.09010698  0.10928508  0.10426388]\n",
      " [ 0.10280874  0.09712071  0.11513763  0.08803212  0.09657554  0.09841121\n",
      "   0.09780172  0.09360271  0.10801164  0.10249795]] (8.584 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.6734\n",
      "INFO:tensorflow:probabilities = [[ 0.09582985  0.08795915  0.09830311  0.10100741  0.10104274  0.10909833\n",
      "   0.09283397  0.10335453  0.10286114  0.10770978]\n",
      " [ 0.10428338  0.09052046  0.09970364  0.08705212  0.11326254  0.08527367\n",
      "   0.10028768  0.08974183  0.1234653   0.1064094 ]\n",
      " [ 0.10631108  0.10567356  0.10846002  0.0961052   0.09681249  0.10084724\n",
      "   0.09788214  0.09416576  0.09848024  0.09526229]\n",
      " [ 0.12020034  0.09277736  0.10224581  0.08999369  0.09744578  0.08570607\n",
      "   0.10094098  0.09673054  0.11917464  0.09478484]\n",
      " [ 0.10416296  0.10010632  0.09955832  0.09962988  0.103236    0.0940593\n",
      "   0.0952606   0.09735925  0.10069466  0.10593271]\n",
      " [ 0.09603655  0.08931705  0.1016034   0.10756029  0.10436949  0.09687504\n",
      "   0.09143835  0.10407441  0.10537295  0.10335245]\n",
      " [ 0.09059211  0.1017735   0.10035861  0.09856886  0.10087072  0.09455733\n",
      "   0.10201832  0.09952543  0.10447831  0.10725679]\n",
      " [ 0.10779995  0.105917    0.10812295  0.09475079  0.08976761  0.0793916\n",
      "   0.11171591  0.08388277  0.1024038   0.11624765]\n",
      " [ 0.10339411  0.09246732  0.11215235  0.10474461  0.1185614   0.09230882\n",
      "   0.09578629  0.0880735   0.09787036  0.09464121]\n",
      " [ 0.11141513  0.10082842  0.10881209  0.10213123  0.10881199  0.10905077\n",
      "   0.07733099  0.09122521  0.09532508  0.09506907]\n",
      " [ 0.10650808  0.09752674  0.10466985  0.09467798  0.09861272  0.09360754\n",
      "   0.09368077  0.08601342  0.10516296  0.11953988]\n",
      " [ 0.10669414  0.09799543  0.10630075  0.09568848  0.08802814  0.08651221\n",
      "   0.10582547  0.0912796   0.10709712  0.11457865]\n",
      " [ 0.09973499  0.09053454  0.10617741  0.10088995  0.10151215  0.09426229\n",
      "   0.10405446  0.09671824  0.09653244  0.10958347]\n",
      " [ 0.10280967  0.08810596  0.10575972  0.0917803   0.09253092  0.0962598\n",
      "   0.10717607  0.09137125  0.11011223  0.114094  ]\n",
      " [ 0.09463221  0.11404507  0.09937082  0.09321468  0.10870136  0.09803186\n",
      "   0.1012046   0.08724302  0.10939265  0.09416374]\n",
      " [ 0.09936591  0.12009647  0.1050561   0.09655637  0.10395933  0.09484518\n",
      "   0.09570137  0.09607216  0.09577534  0.09257174]\n",
      " [ 0.11684874  0.08380844  0.10465991  0.09422538  0.09459693  0.09047247\n",
      "   0.09455045  0.09149352  0.10595853  0.12338569]\n",
      " [ 0.11011065  0.09283024  0.10907125  0.09558289  0.09822477  0.10231361\n",
      "   0.10884728  0.09163879  0.09741401  0.09396654]\n",
      " [ 0.09018798  0.11198     0.1000753   0.09705146  0.1002316   0.09483734\n",
      "   0.09383576  0.10334946  0.11314197  0.09530916]\n",
      " [ 0.11857904  0.08095331  0.12411018  0.09814873  0.10569497  0.08818363\n",
      "   0.098828    0.08498721  0.10157797  0.09893692]\n",
      " [ 0.10188133  0.09656841  0.10717877  0.09777873  0.09239534  0.10519036\n",
      "   0.1094507   0.08583247  0.11070551  0.09301839]\n",
      " [ 0.0958461   0.10138298  0.09916965  0.10132166  0.11094674  0.08318568\n",
      "   0.1003707   0.08606256  0.11770568  0.10400822]\n",
      " [ 0.09668083  0.08917156  0.10561112  0.10891084  0.10523953  0.09650266\n",
      "   0.09406888  0.09414825  0.10839108  0.10127524]\n",
      " [ 0.10662797  0.09360352  0.10768436  0.10639273  0.10754142  0.08322146\n",
      "   0.09713921  0.09329156  0.10966332  0.09483446]\n",
      " [ 0.11289717  0.08969972  0.09544133  0.10598693  0.109449    0.08920232\n",
      "   0.09830265  0.10249447  0.09648515  0.10004129]\n",
      " [ 0.10190018  0.1001765   0.11342578  0.10754147  0.10001892  0.0876237\n",
      "   0.09773371  0.1014797   0.09167381  0.09842622]\n",
      " [ 0.09830139  0.09399018  0.10282188  0.09858745  0.10540656  0.08191154\n",
      "   0.09292787  0.1140031   0.11066179  0.10138814]\n",
      " [ 0.11048257  0.10604879  0.11618935  0.08731987  0.09874637  0.09768286\n",
      "   0.09118678  0.08514964  0.11175148  0.09544228]\n",
      " [ 0.0941399   0.07697477  0.1202027   0.10034214  0.10938058  0.09013817\n",
      "   0.10501883  0.08714884  0.11066148  0.10599255]\n",
      " [ 0.10099401  0.10588     0.11360779  0.1002655   0.09779698  0.0922601\n",
      "   0.10113939  0.08897492  0.10250628  0.09657504]\n",
      " [ 0.08991961  0.08882234  0.10545129  0.10334373  0.10144687  0.10269391\n",
      "   0.10020023  0.09682805  0.10180421  0.10948976]\n",
      " [ 0.12307269  0.09028145  0.10889181  0.09347318  0.08366649  0.09012445\n",
      "   0.10675945  0.09487408  0.09935379  0.1095026 ]\n",
      " [ 0.09267161  0.09514956  0.097441    0.10461853  0.09968235  0.09715191\n",
      "   0.10653374  0.09133826  0.10767851  0.10773449]\n",
      " [ 0.11690509  0.09820595  0.09905443  0.09146395  0.11073255  0.09184017\n",
      "   0.08790094  0.09556476  0.11883195  0.08950026]\n",
      " [ 0.09709912  0.10920071  0.10399824  0.09317493  0.10374756  0.09573173\n",
      "   0.09538823  0.09187186  0.11093753  0.09885012]\n",
      " [ 0.09535192  0.09979459  0.1111993   0.10757955  0.09440803  0.09202956\n",
      "   0.11162246  0.09490464  0.08790556  0.10520445]\n",
      " [ 0.10657782  0.0903889   0.11850318  0.10327853  0.08932879  0.08551767\n",
      "   0.11068332  0.09146736  0.10354033  0.10071409]\n",
      " [ 0.0999855   0.09160478  0.10789274  0.09808857  0.10734033  0.09534078\n",
      "   0.09380298  0.09941841  0.09484895  0.11167699]\n",
      " [ 0.1082975   0.10182525  0.10046262  0.09228244  0.10271227  0.08999724\n",
      "   0.09818738  0.09460672  0.09787466  0.11375394]\n",
      " [ 0.10505788  0.0998541   0.11080971  0.09901263  0.09979977  0.09161175\n",
      "   0.10316018  0.08404553  0.10012874  0.10651975]\n",
      " [ 0.10864372  0.0817383   0.10232042  0.11264353  0.10755959  0.08215944\n",
      "   0.09991888  0.08755176  0.10800229  0.1094621 ]\n",
      " [ 0.10076417  0.09444926  0.1073305   0.11524004  0.10531672  0.09851717\n",
      "   0.09948453  0.08619518  0.09842847  0.09427403]\n",
      " [ 0.09764888  0.10288028  0.103669    0.10102959  0.10111911  0.08951239\n",
      "   0.09848878  0.09994065  0.09993451  0.10577681]\n",
      " [ 0.0885601   0.09511609  0.10044993  0.09533884  0.10779918  0.08888564\n",
      "   0.10644446  0.10161373  0.12050694  0.09528504]\n",
      " [ 0.08648668  0.09726296  0.09354277  0.09399778  0.10156887  0.09705278\n",
      "   0.10168312  0.11784784  0.10783929  0.10271785]\n",
      " [ 0.08742592  0.09724336  0.10784185  0.11256328  0.11655361  0.08944415\n",
      "   0.08936727  0.09235464  0.09798487  0.10922103]\n",
      " [ 0.10811237  0.10204283  0.09133352  0.1021302   0.10209423  0.08432614\n",
      "   0.10146596  0.10573938  0.09960604  0.10314932]\n",
      " [ 0.10939337  0.0952361   0.12366805  0.10189612  0.09440445  0.09651586\n",
      "   0.09361921  0.08939391  0.10075337  0.09511961]\n",
      " [ 0.1022227   0.09229313  0.10312162  0.10228742  0.11122503  0.09040565\n",
      "   0.09100733  0.09524949  0.10301086  0.10917684]\n",
      " [ 0.09400199  0.09334601  0.10777995  0.10176507  0.09907297  0.08549324\n",
      "   0.10463902  0.08874403  0.10925183  0.11590591]\n",
      " [ 0.10572158  0.10629193  0.10800567  0.09411457  0.09274542  0.09418355\n",
      "   0.10455929  0.09842614  0.09120716  0.10474469]\n",
      " [ 0.1024949   0.07431293  0.11513937  0.09945916  0.09969733  0.08631093\n",
      "   0.10556851  0.09485012  0.10535727  0.11680952]\n",
      " [ 0.1028849   0.09511984  0.10814661  0.10882386  0.10064026  0.08148539\n",
      "   0.10154321  0.10381025  0.10640219  0.09114346]\n",
      " [ 0.10519826  0.0973958   0.11005908  0.08475461  0.0998949   0.09498997\n",
      "   0.0994202   0.09859096  0.11028014  0.09941607]\n",
      " [ 0.09054638  0.11327157  0.10071674  0.10228318  0.10561505  0.09390061\n",
      "   0.08794845  0.10037762  0.10236964  0.10297073]\n",
      " [ 0.10721408  0.07776199  0.10562876  0.10085573  0.1039757   0.10044236\n",
      "   0.09988551  0.09789374  0.10240361  0.10393856]\n",
      " [ 0.12718832  0.0965777   0.10306005  0.10857522  0.10575746  0.08368168\n",
      "   0.10582338  0.08974014  0.09976035  0.07983573]\n",
      " [ 0.09705012  0.08522368  0.10429432  0.10004294  0.10148851  0.10044587\n",
      "   0.11273882  0.09542557  0.09930304  0.10398711]\n",
      " [ 0.11072221  0.09117472  0.10712417  0.10010277  0.11630456  0.08219267\n",
      "   0.09932904  0.0891058   0.11530803  0.08863601]\n",
      " [ 0.08774338  0.0905659   0.11051363  0.10438044  0.11425909  0.09480134\n",
      "   0.09965971  0.09507313  0.10305262  0.09995077]\n",
      " [ 0.10749882  0.08463844  0.12268522  0.10743311  0.09528238  0.09418339\n",
      "   0.08638784  0.09541532  0.11070582  0.09576964]\n",
      " [ 0.08737434  0.10523488  0.09918673  0.09508401  0.10581777  0.09837744\n",
      "   0.10642662  0.09749161  0.10098824  0.10401836]\n",
      " [ 0.08824839  0.08747025  0.09849683  0.10628485  0.11075385  0.09732274\n",
      "   0.09715588  0.09940775  0.09956672  0.11529276]\n",
      " [ 0.10175281  0.08227621  0.12126846  0.09688636  0.10121489  0.0860359\n",
      "   0.09944662  0.0903558   0.10441302  0.11634992]\n",
      " [ 0.09695335  0.09319478  0.11382636  0.09851537  0.10563986  0.08808238\n",
      "   0.09367188  0.0996951   0.11020172  0.1002192 ]\n",
      " [ 0.10155997  0.09174126  0.11841464  0.10459716  0.09028208  0.0956004\n",
      "   0.09891041  0.08847874  0.10117843  0.10923689]\n",
      " [ 0.116123    0.09819998  0.12784971  0.09331018  0.08948619  0.07752272\n",
      "   0.08441953  0.10393342  0.1121828   0.09697251]\n",
      " [ 0.11941974  0.08234628  0.11023121  0.0912462   0.09222179  0.08857282\n",
      "   0.10625053  0.09450455  0.1137156   0.10149132]\n",
      " [ 0.10500313  0.08172908  0.10640422  0.09410995  0.1079635   0.08685726\n",
      "   0.10980639  0.10275676  0.11063544  0.09473418]\n",
      " [ 0.08816222  0.09041072  0.10740293  0.101584    0.09730288  0.10660676\n",
      "   0.09373935  0.09327731  0.11399776  0.10751601]\n",
      " [ 0.09509839  0.09182633  0.0988514   0.10563223  0.09336209  0.09606688\n",
      "   0.10122766  0.10237657  0.11480961  0.1007489 ]\n",
      " [ 0.0903198   0.09470619  0.10698811  0.09601805  0.10105687  0.10514148\n",
      "   0.10354896  0.09813873  0.11107606  0.09300573]\n",
      " [ 0.09453471  0.10223996  0.10834858  0.0962164   0.10346299  0.09225561\n",
      "   0.10189243  0.10123137  0.10199327  0.09782464]\n",
      " [ 0.09738919  0.10791182  0.10590906  0.10238818  0.09795659  0.09433493\n",
      "   0.09737245  0.09787434  0.10380123  0.0950622 ]\n",
      " [ 0.11111464  0.09472623  0.10281419  0.11199381  0.0976929   0.08960962\n",
      "   0.10163415  0.07937833  0.1034866   0.10754948]\n",
      " [ 0.09718116  0.08664178  0.10956625  0.09993017  0.1193864   0.0983666\n",
      "   0.09548157  0.10203078  0.0928212   0.09859403]\n",
      " [ 0.10293592  0.08482915  0.12471677  0.11577028  0.0970153   0.09304415\n",
      "   0.09142664  0.09755734  0.09162731  0.10107716]\n",
      " [ 0.13688301  0.0947379   0.11937987  0.10326238  0.09749781  0.08203936\n",
      "   0.09190918  0.08568082  0.09901507  0.08959462]\n",
      " [ 0.1131115   0.09319202  0.11128361  0.09725201  0.09372058  0.08463256\n",
      "   0.10314503  0.09580617  0.09909984  0.10875673]\n",
      " [ 0.10177343  0.09962309  0.11153971  0.10214472  0.10065942  0.09048633\n",
      "   0.09393554  0.08984567  0.11135907  0.09863302]\n",
      " [ 0.09446544  0.1129159   0.10085926  0.09660931  0.09944132  0.10726834\n",
      "   0.09454405  0.09054977  0.11219969  0.09114699]\n",
      " [ 0.09150761  0.10511342  0.09956077  0.10777682  0.1052002   0.08866455\n",
      "   0.08975799  0.10332526  0.10386173  0.10523165]\n",
      " [ 0.12859696  0.0896649   0.10633021  0.10190354  0.09939178  0.09936781\n",
      "   0.09721074  0.08612579  0.0997318   0.09167647]\n",
      " [ 0.10477535  0.09279327  0.10094951  0.10107663  0.11629108  0.08539088\n",
      "   0.09816344  0.09279247  0.10225102  0.10551632]\n",
      " [ 0.09449234  0.08438176  0.10504405  0.09864481  0.11664829  0.08383324\n",
      "   0.10045558  0.09006549  0.10633074  0.12010369]\n",
      " [ 0.10446875  0.10026447  0.10563714  0.10865086  0.10097113  0.08798444\n",
      "   0.10827478  0.09357883  0.09200305  0.09816653]\n",
      " [ 0.10501011  0.08419094  0.09444853  0.11270645  0.10253762  0.09339199\n",
      "   0.09056204  0.09321398  0.12008055  0.10385768]\n",
      " [ 0.09249114  0.08263042  0.11356229  0.11234901  0.10029233  0.08740284\n",
      "   0.08335289  0.09792168  0.11233622  0.11766116]\n",
      " [ 0.09234934  0.11300724  0.11022871  0.09126277  0.09977438  0.09976377\n",
      "   0.09739279  0.08944766  0.1121977   0.09457565]\n",
      " [ 0.09049776  0.10021389  0.11879487  0.09870487  0.10963333  0.09451748\n",
      "   0.09290803  0.09549727  0.10521194  0.09402047]\n",
      " [ 0.10172915  0.091166    0.11319335  0.10601564  0.10537926  0.09588656\n",
      "   0.08696735  0.09622115  0.09731368  0.10612782]\n",
      " [ 0.10789319  0.09339633  0.11219477  0.1051388   0.09038075  0.09567859\n",
      "   0.09503865  0.09677897  0.09679344  0.10670657]\n",
      " [ 0.12167447  0.09655162  0.09986872  0.08895007  0.08723412  0.10515623\n",
      "   0.10203477  0.09546955  0.10258859  0.10047188]\n",
      " [ 0.1044261   0.09403187  0.10811526  0.10639603  0.09185556  0.09987292\n",
      "   0.08554438  0.10694871  0.10445108  0.09835812]\n",
      " [ 0.10723583  0.08696923  0.11571825  0.11254779  0.10313021  0.0850634\n",
      "   0.09267262  0.09207609  0.10349097  0.10109569]\n",
      " [ 0.10662633  0.08649255  0.11993684  0.10675292  0.1021863   0.09500401\n",
      "   0.08395031  0.09589582  0.10142136  0.10173358]\n",
      " [ 0.09416248  0.09148955  0.10174419  0.09902498  0.10032126  0.09215268\n",
      "   0.11351795  0.10217854  0.10210111  0.1033073 ]\n",
      " [ 0.0978253   0.08117496  0.09892067  0.1001483   0.10739926  0.09312274\n",
      "   0.09814735  0.10064637  0.1196992   0.10291589]\n",
      " [ 0.09486528  0.09174253  0.11730164  0.09849181  0.10203335  0.090809\n",
      "   0.09892564  0.10270561  0.09348094  0.10964417]\n",
      " [ 0.09222434  0.08312577  0.10649855  0.11291011  0.1093245   0.07910267\n",
      "   0.1036604   0.08810024  0.12260517  0.10244813]] (9.043 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.26059, step = 401 (17.627 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10940592  0.09193227  0.1049511   0.10281099  0.11415455  0.07907294\n",
      "   0.08523299  0.08989301  0.11568087  0.10686531]\n",
      " [ 0.10311554  0.09985098  0.09875515  0.10354508  0.10684851  0.08510327\n",
      "   0.10349617  0.09693368  0.09786624  0.10448536]\n",
      " [ 0.10169364  0.0990688   0.1069536   0.10290079  0.09931566  0.0899144\n",
      "   0.10721134  0.0809075   0.09923963  0.11279467]\n",
      " [ 0.1042388   0.08020748  0.14707215  0.10117883  0.09729939  0.08536743\n",
      "   0.08822282  0.09021088  0.111969    0.09423324]\n",
      " [ 0.10800438  0.09346939  0.11477197  0.08900634  0.09040853  0.09361637\n",
      "   0.09504143  0.10307249  0.11248701  0.10012201]\n",
      " [ 0.11826206  0.08931812  0.10072858  0.10811847  0.09120985  0.09538344\n",
      "   0.08267272  0.08684359  0.10604144  0.12142168]\n",
      " [ 0.09234492  0.09417005  0.11376958  0.11294535  0.09407111  0.08341525\n",
      "   0.11439654  0.09392656  0.0983449   0.1026157 ]\n",
      " [ 0.08448651  0.09128818  0.10776328  0.1063048   0.10688031  0.08506601\n",
      "   0.10046489  0.09485818  0.12555861  0.09732925]\n",
      " [ 0.11189603  0.09553457  0.11285074  0.09647366  0.09466267  0.09904514\n",
      "   0.10532844  0.10225201  0.09712005  0.08483665]\n",
      " [ 0.09982785  0.09760638  0.09657148  0.10605053  0.11005235  0.08772694\n",
      "   0.09938801  0.09769776  0.10116596  0.10391277]\n",
      " [ 0.10326692  0.10204675  0.09934676  0.09943237  0.10946684  0.09585194\n",
      "   0.09326764  0.09708505  0.10744852  0.0927873 ]\n",
      " [ 0.10290411  0.09746572  0.10527064  0.10053466  0.10537015  0.0942695\n",
      "   0.1033074   0.0956425   0.09794352  0.09729173]\n",
      " [ 0.11105797  0.10250527  0.10675689  0.10478219  0.09212074  0.09294499\n",
      "   0.09289286  0.09469873  0.10331865  0.09892166]\n",
      " [ 0.10112469  0.09737592  0.11255429  0.10419293  0.09301388  0.10110368\n",
      "   0.0895915   0.10035995  0.11337442  0.08730868]\n",
      " [ 0.11209475  0.09254137  0.11530787  0.10304276  0.10050985  0.10193221\n",
      "   0.09123257  0.08023646  0.10030652  0.10279563]\n",
      " [ 0.10098018  0.08320976  0.10795699  0.11199225  0.10050737  0.08234293\n",
      "   0.091614    0.10470987  0.10975304  0.10693367]\n",
      " [ 0.09297955  0.10229422  0.10167681  0.10481004  0.10300839  0.09729283\n",
      "   0.10219914  0.09316781  0.1034655   0.09910566]\n",
      " [ 0.10812704  0.09028149  0.11023244  0.104479    0.10773625  0.08961172\n",
      "   0.10767496  0.09403078  0.09489076  0.09293552]\n",
      " [ 0.09348798  0.09502539  0.14311627  0.09568397  0.09358924  0.08973755\n",
      "   0.10608979  0.07493275  0.10893694  0.09940009]\n",
      " [ 0.08295815  0.08736341  0.10016676  0.11619958  0.10439503  0.09263095\n",
      "   0.10595539  0.09318378  0.11169034  0.1054566 ]\n",
      " [ 0.10877339  0.07965089  0.09913776  0.11993742  0.11339229  0.06775282\n",
      "   0.09311254  0.09545746  0.11998703  0.10279839]\n",
      " [ 0.09739733  0.09325279  0.10906842  0.09904926  0.09410969  0.09520499\n",
      "   0.11086005  0.0992551   0.10187853  0.09992385]\n",
      " [ 0.10302774  0.09581525  0.11434112  0.10538007  0.10547637  0.0964224\n",
      "   0.09140638  0.09346599  0.10640767  0.08825703]\n",
      " [ 0.11987787  0.08841198  0.10932047  0.09603575  0.10045764  0.08881126\n",
      "   0.09572525  0.09482588  0.1038081   0.10272589]\n",
      " [ 0.09972329  0.10971829  0.09680853  0.09475274  0.11765505  0.0883681\n",
      "   0.09584492  0.0865802   0.10499705  0.10555183]\n",
      " [ 0.1003184   0.09791679  0.13189657  0.09232705  0.09652398  0.08987067\n",
      "   0.11172574  0.08871796  0.10292306  0.08777978]\n",
      " [ 0.10111868  0.1026407   0.1005246   0.0873061   0.10628444  0.08898206\n",
      "   0.10758858  0.09362159  0.10421018  0.10772302]\n",
      " [ 0.1147837   0.09799748  0.09819634  0.0877275   0.10231659  0.10530394\n",
      "   0.10279452  0.10494621  0.09415592  0.09177779]\n",
      " [ 0.0979588   0.09845243  0.10363719  0.10101341  0.09763353  0.09289813\n",
      "   0.09907292  0.09833088  0.10418821  0.10681456]\n",
      " [ 0.08493734  0.11528939  0.11041309  0.09807748  0.10690413  0.09420849\n",
      "   0.10019438  0.09665503  0.09993494  0.09338576]\n",
      " [ 0.09265436  0.09309123  0.10281472  0.10367654  0.09413292  0.09474928\n",
      "   0.10392591  0.09188858  0.11690073  0.10616577]\n",
      " [ 0.12754364  0.07603473  0.09293424  0.10968352  0.11403813  0.0818347\n",
      "   0.09967756  0.09854606  0.089217    0.11049037]\n",
      " [ 0.10399638  0.06723783  0.09408367  0.11551608  0.12142284  0.09646259\n",
      "   0.09295889  0.09039912  0.10605825  0.11186431]\n",
      " [ 0.10314716  0.08751458  0.11438944  0.0887702   0.09575082  0.09940968\n",
      "   0.11947467  0.0849653   0.10493205  0.10164612]\n",
      " [ 0.10286493  0.09390599  0.10523468  0.0952718   0.11012518  0.09305341\n",
      "   0.10880647  0.0840876   0.10064435  0.10600569]\n",
      " [ 0.12209714  0.08597235  0.10937808  0.10017478  0.10021733  0.08510034\n",
      "   0.10706753  0.08874485  0.09708833  0.10415933]\n",
      " [ 0.11096781  0.08585401  0.10116397  0.10914589  0.10087106  0.08583615\n",
      "   0.10137232  0.0873288   0.11326786  0.10419215]\n",
      " [ 0.10602513  0.10836363  0.10926501  0.09862895  0.08764383  0.09643387\n",
      "   0.09478847  0.09205832  0.10151065  0.10528215]\n",
      " [ 0.09550891  0.09474523  0.11058123  0.09016563  0.10627951  0.0899212\n",
      "   0.11616376  0.09451357  0.10339099  0.09873003]\n",
      " [ 0.0987343   0.07613679  0.09525764  0.11033913  0.10610718  0.09376003\n",
      "   0.10319222  0.10454787  0.10216121  0.10976371]\n",
      " [ 0.1147394   0.09151407  0.10928468  0.1008663   0.09606285  0.07969733\n",
      "   0.10147815  0.09038784  0.10963981  0.10632956]\n",
      " [ 0.09724697  0.08517992  0.10724738  0.09086138  0.11099946  0.09543631\n",
      "   0.0973037   0.10058402  0.10140564  0.11373523]\n",
      " [ 0.1069273   0.08386889  0.10918288  0.09387688  0.10000291  0.09155867\n",
      "   0.10145605  0.0974801   0.10767342  0.10797287]\n",
      " [ 0.11399281  0.09751397  0.1056513   0.08806252  0.09491007  0.1018476\n",
      "   0.09973011  0.10586376  0.10520083  0.087227  ]\n",
      " [ 0.13506173  0.09773767  0.09971457  0.10000277  0.09210095  0.09517648\n",
      "   0.09658133  0.08210081  0.10643915  0.09508453]\n",
      " [ 0.104272    0.09177504  0.09905665  0.10579758  0.10385789  0.08485637\n",
      "   0.0901695   0.10560439  0.11257578  0.10203477]\n",
      " [ 0.15604691  0.07437629  0.11052504  0.10380431  0.10028887  0.08680441\n",
      "   0.09955268  0.0831219   0.0822545   0.10322507]\n",
      " [ 0.1008581   0.09178652  0.10898264  0.09294227  0.09536865  0.10845879\n",
      "   0.09265502  0.10306646  0.10630826  0.09957332]\n",
      " [ 0.0953375   0.0827276   0.10732611  0.0995404   0.09958366  0.09059472\n",
      "   0.09179141  0.09796337  0.1213579   0.11377735]\n",
      " [ 0.11793616  0.10055034  0.09798837  0.09645578  0.11038996  0.08110318\n",
      "   0.10066111  0.10113347  0.09294102  0.10084066]\n",
      " [ 0.09207033  0.09446333  0.10210333  0.10894055  0.11256978  0.08370772\n",
      "   0.09838234  0.09455061  0.10100211  0.11220988]\n",
      " [ 0.09706666  0.11331151  0.10653733  0.10387073  0.0973508   0.0965375\n",
      "   0.09848966  0.08991328  0.10467217  0.09225038]\n",
      " [ 0.10042361  0.09233313  0.10661528  0.10421257  0.09944991  0.08827486\n",
      "   0.08230339  0.10693444  0.10634346  0.11310934]\n",
      " [ 0.10501358  0.0964668   0.10114767  0.1108014   0.11147486  0.08915894\n",
      "   0.09553706  0.0904199   0.10112412  0.09885567]\n",
      " [ 0.10892352  0.09158535  0.08715837  0.10806321  0.09819739  0.10357204\n",
      "   0.09660063  0.1023082   0.10569677  0.09789453]\n",
      " [ 0.11350999  0.09538288  0.10949173  0.10194716  0.09687544  0.09552669\n",
      "   0.09063754  0.09481061  0.10292099  0.09889705]\n",
      " [ 0.09301423  0.09619619  0.10586874  0.10715014  0.104201    0.08359698\n",
      "   0.09594645  0.09051673  0.11258454  0.11092503]\n",
      " [ 0.09089305  0.08676243  0.11237541  0.0939163   0.10856417  0.08031277\n",
      "   0.12794149  0.09168778  0.09760477  0.10994185]\n",
      " [ 0.09417563  0.09588618  0.09206212  0.10399094  0.10602156  0.10107641\n",
      "   0.09277134  0.09022363  0.10275025  0.12104195]\n",
      " [ 0.10454629  0.09467787  0.10341585  0.08904562  0.0991386   0.09284351\n",
      "   0.11290484  0.09492429  0.10623568  0.1022675 ]\n",
      " [ 0.13486622  0.08678916  0.1059074   0.10054693  0.11009196  0.0904533\n",
      "   0.10190897  0.08646864  0.10222707  0.0807403 ]\n",
      " [ 0.09919301  0.11244231  0.09552945  0.0953677   0.09811826  0.08510149\n",
      "   0.0924012   0.10417363  0.10719346  0.1104795 ]\n",
      " [ 0.10018782  0.10248762  0.10601512  0.10374523  0.10451479  0.08904774\n",
      "   0.09851091  0.09446798  0.10304331  0.09797952]\n",
      " [ 0.1029314   0.09420812  0.1027182   0.1079414   0.10311606  0.08568998\n",
      "   0.09805523  0.09444668  0.10625194  0.10464098]\n",
      " [ 0.10798321  0.08679007  0.11498527  0.09633317  0.10268045  0.0919848\n",
      "   0.10841574  0.08649643  0.0928678   0.11146302]\n",
      " [ 0.11121573  0.08909785  0.10795081  0.09443837  0.10729937  0.07934403\n",
      "   0.09008024  0.09274957  0.10080374  0.12702034]\n",
      " [ 0.09547744  0.10095262  0.1051011   0.0933579   0.09977703  0.09333273\n",
      "   0.09545761  0.10488331  0.10578649  0.1058738 ]\n",
      " [ 0.10215106  0.0945795   0.10380001  0.11019464  0.10131615  0.08806112\n",
      "   0.09904255  0.09043408  0.10114244  0.10927849]\n",
      " [ 0.1095843   0.09962842  0.10776143  0.11022111  0.1007063   0.09800752\n",
      "   0.08753019  0.09637679  0.09407026  0.09611369]\n",
      " [ 0.09441666  0.09976492  0.09854073  0.10205607  0.10687671  0.08408003\n",
      "   0.10656478  0.10800538  0.0956918   0.10400297]\n",
      " [ 0.09880869  0.10076804  0.1019107   0.10031321  0.10756216  0.09591134\n",
      "   0.10142117  0.0967863   0.10151528  0.09500309]\n",
      " [ 0.10189801  0.11340246  0.10968514  0.10106038  0.0960152   0.09553865\n",
      "   0.08449914  0.09551012  0.10625596  0.09613491]\n",
      " [ 0.11608578  0.09236466  0.09777966  0.09999549  0.09476356  0.07972059\n",
      "   0.10089611  0.1048496   0.107472    0.10607262]\n",
      " [ 0.09743014  0.08764834  0.11478779  0.10671108  0.10991722  0.08701358\n",
      "   0.0947354   0.09718569  0.09935097  0.1052198 ]\n",
      " [ 0.09246449  0.08860872  0.10355932  0.10507036  0.11066188  0.08908366\n",
      "   0.10529705  0.1038556   0.09320099  0.10819788]\n",
      " [ 0.10797008  0.09226461  0.1027588   0.10688113  0.10023721  0.09748783\n",
      "   0.09370693  0.10856413  0.09288513  0.09724416]\n",
      " [ 0.11373202  0.08578776  0.11086859  0.09850329  0.09987079  0.10129668\n",
      "   0.09358874  0.09494635  0.10022631  0.1011795 ]\n",
      " [ 0.12061814  0.07648848  0.10135158  0.09844775  0.1010191   0.10799268\n",
      "   0.10988366  0.09482177  0.08968621  0.09969053]\n",
      " [ 0.0993974   0.07317209  0.10625335  0.10217399  0.097858    0.08981955\n",
      "   0.09931793  0.09497896  0.12439141  0.11263724]\n",
      " [ 0.09957471  0.09859042  0.11649559  0.09559093  0.09923629  0.08972647\n",
      "   0.09492594  0.10214897  0.10158368  0.102127  ]\n",
      " [ 0.11390077  0.08516363  0.1104862   0.10672632  0.09122634  0.0939625\n",
      "   0.08632497  0.09147844  0.10866079  0.11207008]\n",
      " [ 0.09598435  0.10043393  0.11054575  0.09143788  0.100171    0.09351529\n",
      "   0.10027165  0.10536069  0.10114965  0.10112983]\n",
      " [ 0.08564103  0.08646182  0.11721905  0.11817295  0.11199646  0.08620975\n",
      "   0.09346768  0.10430181  0.10040029  0.09612912]\n",
      " [ 0.11361466  0.09936231  0.1133202   0.10421003  0.09637564  0.08486921\n",
      "   0.09707922  0.09593277  0.09289521  0.10234074]\n",
      " [ 0.12666659  0.09430651  0.10609451  0.09552925  0.08786532  0.10186431\n",
      "   0.10098841  0.09798272  0.09332011  0.09538223]\n",
      " [ 0.10625846  0.09187712  0.10137381  0.09083612  0.11899776  0.0974144\n",
      "   0.10062514  0.09916099  0.09789117  0.09556511]\n",
      " [ 0.10633916  0.09737679  0.12023043  0.08654176  0.09766413  0.09868716\n",
      "   0.09472954  0.098442    0.09909188  0.10089705]\n",
      " [ 0.10438335  0.09978119  0.12053125  0.10996354  0.08738118  0.08778144\n",
      "   0.10909582  0.08823485  0.10049347  0.09235398]\n",
      " [ 0.10614344  0.11653828  0.09784532  0.09261157  0.0932329   0.09479555\n",
      "   0.10550334  0.09630495  0.10813901  0.08888565]\n",
      " [ 0.10547338  0.09571578  0.10430489  0.10195915  0.09778322  0.09065877\n",
      "   0.08925458  0.1165951   0.09790291  0.10035226]\n",
      " [ 0.10314418  0.09578927  0.10638933  0.09966002  0.09330327  0.10073047\n",
      "   0.10393602  0.0986325   0.09694014  0.10147484]\n",
      " [ 0.1103734   0.10279921  0.11225522  0.09004773  0.09092838  0.08514505\n",
      "   0.0966462   0.08748444  0.11395483  0.11036545]\n",
      " [ 0.09744173  0.0794758   0.0974545   0.11047217  0.12025495  0.07568371\n",
      "   0.10136423  0.09497707  0.11145282  0.11142305]\n",
      " [ 0.08882557  0.08967113  0.10116543  0.09860338  0.11013348  0.08663242\n",
      "   0.10577229  0.09785128  0.10603394  0.11531108]\n",
      " [ 0.11058334  0.09792457  0.11350853  0.08439754  0.1057359   0.07776322\n",
      "   0.09715775  0.09066008  0.11002352  0.1122456 ]\n",
      " [ 0.11062963  0.09278176  0.1044846   0.10373162  0.10294676  0.09516618\n",
      "   0.1021858   0.10247748  0.09940767  0.0861885 ]\n",
      " [ 0.10592253  0.08866734  0.09676637  0.11466662  0.09311293  0.08804997\n",
      "   0.09654907  0.11215413  0.10079361  0.10331746]\n",
      " [ 0.10264768  0.10152691  0.09989078  0.09972697  0.10005786  0.08639713\n",
      "   0.10364253  0.09541383  0.10417413  0.10652227]\n",
      " [ 0.0983194   0.08335557  0.11581492  0.10768463  0.09365536  0.07744434\n",
      "   0.09832838  0.10657064  0.09903362  0.11979312]\n",
      " [ 0.11543638  0.09606492  0.09437125  0.09728688  0.08181383  0.08910296\n",
      "   0.11105716  0.09802212  0.09888095  0.11796359]] (9.946 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 5.42112\n",
      "INFO:tensorflow:probabilities = [[ 0.08981386  0.08738995  0.09394916  0.11301885  0.10630744  0.08910614\n",
      "   0.10809409  0.10665477  0.10360356  0.10206211]\n",
      " [ 0.1015413   0.09714746  0.11046288  0.11053274  0.09276791  0.08939563\n",
      "   0.08613151  0.10999762  0.1038971   0.09812587]\n",
      " [ 0.09460279  0.09870596  0.10881232  0.10985542  0.10269371  0.09544756\n",
      "   0.10133152  0.09935673  0.10046914  0.08872489]\n",
      " [ 0.09174289  0.10241986  0.11305233  0.10169758  0.10208864  0.09334816\n",
      "   0.09290493  0.09301712  0.10473032  0.10499802]\n",
      " [ 0.0982032   0.10660134  0.11110257  0.10325376  0.09839263  0.08795477\n",
      "   0.09861344  0.09488598  0.09149483  0.10949748]\n",
      " [ 0.10747917  0.09730601  0.10463203  0.09506118  0.09772133  0.08342811\n",
      "   0.09989933  0.10471979  0.10824817  0.10150488]\n",
      " [ 0.1162504   0.09404715  0.11612194  0.10507382  0.08519047  0.09860472\n",
      "   0.0905885   0.09127557  0.1076365   0.09521089]\n",
      " [ 0.11249939  0.08885524  0.10590702  0.09107929  0.09546991  0.09130406\n",
      "   0.10468565  0.10160825  0.10920855  0.09938257]\n",
      " [ 0.08475167  0.10202724  0.10919483  0.10600765  0.10378863  0.09361736\n",
      "   0.10479041  0.09031851  0.09939219  0.10611153]\n",
      " [ 0.11113498  0.08258211  0.11372067  0.08651534  0.10032728  0.08943899\n",
      "   0.10943153  0.09023102  0.1047765   0.11184154]\n",
      " [ 0.11168791  0.07972359  0.11664014  0.12489282  0.09286977  0.10928879\n",
      "   0.08231715  0.08887278  0.10087205  0.092835  ]\n",
      " [ 0.10281163  0.08401783  0.09937298  0.11080711  0.10639431  0.08842751\n",
      "   0.09329043  0.10171048  0.09290889  0.12025889]\n",
      " [ 0.09679986  0.0721426   0.13318747  0.10449089  0.09650815  0.09580611\n",
      "   0.10113565  0.08326679  0.10694519  0.10971735]\n",
      " [ 0.09859979  0.10303635  0.09427111  0.10836362  0.09956008  0.0948636\n",
      "   0.09939002  0.10055991  0.1012416   0.10011392]\n",
      " [ 0.11781496  0.08033083  0.09619256  0.10782561  0.10355642  0.08622393\n",
      "   0.1129977   0.09724227  0.08880944  0.10900623]\n",
      " [ 0.10945296  0.08769396  0.11769301  0.12248103  0.09947962  0.08052282\n",
      "   0.09059854  0.09385113  0.09230778  0.10591915]\n",
      " [ 0.10505359  0.07880572  0.11564887  0.10814584  0.10706101  0.08545659\n",
      "   0.09204444  0.08419999  0.1081643   0.11541962]\n",
      " [ 0.10924993  0.11355589  0.10851971  0.09393208  0.09140839  0.0914037\n",
      "   0.09911885  0.10178326  0.09425018  0.09677802]\n",
      " [ 0.10678358  0.08373117  0.11486497  0.11011555  0.09994267  0.09375704\n",
      "   0.09810805  0.09622929  0.10065788  0.09580981]\n",
      " [ 0.10159676  0.09048508  0.11574668  0.10249875  0.10914129  0.09236263\n",
      "   0.10501201  0.08199649  0.10529827  0.09586208]\n",
      " [ 0.10249248  0.08922223  0.11123294  0.11342959  0.08610856  0.08275545\n",
      "   0.09199763  0.10136516  0.10935538  0.1120406 ]\n",
      " [ 0.08592608  0.08424714  0.10396401  0.11629077  0.10449286  0.07792632\n",
      "   0.09921291  0.11095271  0.10355876  0.1134284 ]\n",
      " [ 0.10175964  0.09875863  0.09631132  0.11292383  0.10058623  0.08250286\n",
      "   0.08729422  0.10223778  0.10735052  0.11027506]\n",
      " [ 0.10126028  0.09781547  0.12763473  0.10487721  0.09465549  0.08462146\n",
      "   0.09420808  0.09067787  0.11466662  0.08958276]\n",
      " [ 0.11564713  0.09538499  0.10239325  0.09973271  0.09411705  0.10502902\n",
      "   0.09343737  0.08683447  0.10817714  0.09924686]\n",
      " [ 0.09747394  0.10417651  0.10256395  0.09678594  0.10483129  0.09754509\n",
      "   0.09534223  0.1010735   0.0953825   0.10482498]\n",
      " [ 0.09973556  0.08982454  0.10148562  0.10985542  0.10382211  0.08232186\n",
      "   0.09019589  0.10149916  0.10427526  0.11698462]\n",
      " [ 0.11832906  0.0736331   0.12093327  0.10982593  0.1098596   0.08586635\n",
      "   0.08551949  0.10147297  0.09948106  0.09507914]\n",
      " [ 0.09895582  0.08277024  0.1003103   0.097372    0.09226396  0.08818982\n",
      "   0.10215504  0.09160956  0.11796411  0.12840915]\n",
      " [ 0.09975268  0.10081507  0.1120258   0.0995767   0.09489235  0.0911407\n",
      "   0.09976643  0.10783785  0.09407511  0.1001173 ]\n",
      " [ 0.09983277  0.10276519  0.10294846  0.09638716  0.08644104  0.11398935\n",
      "   0.09827071  0.09412102  0.10949484  0.09574945]\n",
      " [ 0.09035671  0.09626139  0.09881996  0.10817475  0.12289213  0.08445718\n",
      "   0.11149306  0.08375434  0.09987523  0.10391532]\n",
      " [ 0.09515364  0.08818972  0.12017307  0.11465426  0.10911507  0.09682744\n",
      "   0.09554975  0.0921772   0.09513322  0.09302661]\n",
      " [ 0.11914152  0.09980228  0.11931092  0.09237939  0.10084263  0.09276036\n",
      "   0.10262804  0.08630498  0.0976869   0.08914299]\n",
      " [ 0.09977341  0.09620392  0.1196658   0.09909316  0.10289662  0.08920553\n",
      "   0.09278068  0.09662167  0.10724794  0.09651128]\n",
      " [ 0.09131416  0.11265718  0.10561124  0.09965558  0.09565087  0.08914189\n",
      "   0.09726765  0.10240691  0.10422114  0.10207339]\n",
      " [ 0.09643634  0.09478351  0.10714416  0.10498372  0.09885448  0.09965227\n",
      "   0.08877767  0.10509172  0.0980778   0.10619833]\n",
      " [ 0.11139193  0.09563237  0.11508783  0.09894659  0.09634151  0.09024442\n",
      "   0.09927069  0.09684677  0.09439966  0.1018383 ]\n",
      " [ 0.13038969  0.09099866  0.1142979   0.09323623  0.08869434  0.10731534\n",
      "   0.10112678  0.09837517  0.08718383  0.08838212]\n",
      " [ 0.09990465  0.08571185  0.11408686  0.10364919  0.10390217  0.1018355\n",
      "   0.09702571  0.09722912  0.10682842  0.08982647]\n",
      " [ 0.09039669  0.09590274  0.1227765   0.10716082  0.10414876  0.09116855\n",
      "   0.09345648  0.09258144  0.1005059   0.10190211]\n",
      " [ 0.09810594  0.09623324  0.10072044  0.11037905  0.1123428   0.0841212\n",
      "   0.09513531  0.10087302  0.10018362  0.10190538]\n",
      " [ 0.0989285   0.08405985  0.08799866  0.10044454  0.10335004  0.10063799\n",
      "   0.09921783  0.09488568  0.11668356  0.11379334]\n",
      " [ 0.09459329  0.10703491  0.10552438  0.10235142  0.09138362  0.09328146\n",
      "   0.09453157  0.10067606  0.09881805  0.11180519]\n",
      " [ 0.1000937   0.09262346  0.09573332  0.10155962  0.10375595  0.09045329\n",
      "   0.09448694  0.10345151  0.11795086  0.09989134]\n",
      " [ 0.10319255  0.09634948  0.10493082  0.10005704  0.09699893  0.08494725\n",
      "   0.09808758  0.10334893  0.10435741  0.10772997]\n",
      " [ 0.10573854  0.08575431  0.11325362  0.09585828  0.09467395  0.09755853\n",
      "   0.09667976  0.10441157  0.09126344  0.11480799]\n",
      " [ 0.09547792  0.09405667  0.10270201  0.07938095  0.10044602  0.08846979\n",
      "   0.11470819  0.0918407   0.11980519  0.11311255]\n",
      " [ 0.1141388   0.07517003  0.11275379  0.11444282  0.11292848  0.09358228\n",
      "   0.08898693  0.08019315  0.11546635  0.09233739]\n",
      " [ 0.11023978  0.10055523  0.12294452  0.10597456  0.08856083  0.09060847\n",
      "   0.10434119  0.09351628  0.0985506   0.08470847]\n",
      " [ 0.10009283  0.09832039  0.11373025  0.10483698  0.09409577  0.0973611\n",
      "   0.10195729  0.09838997  0.09782803  0.09338734]\n",
      " [ 0.10259035  0.11425624  0.09942511  0.08664523  0.10711287  0.09079792\n",
      "   0.0942312   0.09701448  0.10797027  0.09995633]\n",
      " [ 0.09318228  0.09883655  0.10199594  0.12251808  0.11116964  0.09361929\n",
      "   0.08750158  0.09472191  0.09728077  0.09917394]\n",
      " [ 0.09620646  0.09768265  0.10952696  0.09496474  0.11253136  0.0925115\n",
      "   0.08221135  0.09289213  0.11762843  0.10384443]\n",
      " [ 0.11097821  0.08601164  0.10620761  0.09980272  0.11393587  0.07528362\n",
      "   0.09228241  0.09717403  0.0953062   0.12301765]\n",
      " [ 0.09869572  0.10226321  0.10375181  0.09763647  0.10165945  0.10204316\n",
      "   0.09305285  0.09756343  0.10828998  0.09504397]\n",
      " [ 0.0965274   0.08024292  0.10897041  0.09578443  0.11034077  0.10314123\n",
      "   0.10108622  0.09566377  0.0945677   0.11367513]\n",
      " [ 0.11115665  0.122375    0.10149515  0.09990412  0.08411518  0.09516723\n",
      "   0.10008345  0.09364625  0.10363606  0.08842106]\n",
      " [ 0.09588815  0.09345308  0.10996197  0.09978084  0.10479838  0.09344409\n",
      "   0.09385335  0.09421962  0.1089084   0.10569217]\n",
      " [ 0.10630015  0.10408844  0.10764612  0.09437676  0.0917882   0.08111183\n",
      "   0.09611443  0.10555595  0.10443693  0.10858123]\n",
      " [ 0.11496969  0.09950627  0.11495087  0.10147962  0.09395636  0.09205557\n",
      "   0.09554323  0.08754259  0.10678427  0.09321152]\n",
      " [ 0.09719855  0.09244384  0.11162271  0.11227653  0.09045532  0.09895833\n",
      "   0.08623776  0.10105211  0.10909203  0.10066284]\n",
      " [ 0.09907652  0.08406878  0.10006311  0.11007776  0.10744764  0.08658477\n",
      "   0.10327491  0.096924    0.09879901  0.11368347]\n",
      " [ 0.10209751  0.11930294  0.11395871  0.09834881  0.09418595  0.09700951\n",
      "   0.0931175   0.09565569  0.09899141  0.08733191]\n",
      " [ 0.09661268  0.08712857  0.09851719  0.1124249   0.096692    0.10042769\n",
      "   0.0920423   0.09073372  0.11988547  0.10553543]\n",
      " [ 0.12214319  0.07204739  0.11663321  0.09778351  0.1015839   0.08834662\n",
      "   0.09820221  0.07744107  0.12207414  0.1037447 ]\n",
      " [ 0.09934495  0.09817228  0.10130724  0.10783592  0.09135944  0.09145077\n",
      "   0.10146761  0.09645831  0.10561179  0.10699172]\n",
      " [ 0.13023984  0.07588285  0.11933535  0.09773485  0.1026869   0.08593244\n",
      "   0.10465853  0.0757456   0.09883688  0.10894676]\n",
      " [ 0.10327756  0.08531499  0.10892326  0.10061089  0.11707836  0.106506\n",
      "   0.09169708  0.09222701  0.11094553  0.0834193 ]\n",
      " [ 0.13193996  0.1022374   0.09558225  0.08556246  0.09049525  0.10196985\n",
      "   0.09670851  0.09552218  0.10225934  0.09772274]\n",
      " [ 0.10401017  0.09889971  0.10872035  0.09476535  0.09355803  0.10452773\n",
      "   0.09026046  0.10152029  0.10423999  0.09949785]\n",
      " [ 0.09453721  0.07954638  0.11028314  0.10757479  0.09387015  0.09764063\n",
      "   0.11077432  0.09889965  0.09007275  0.11680105]\n",
      " [ 0.10778661  0.08191519  0.09170089  0.08880273  0.11085593  0.09506694\n",
      "   0.10595554  0.0922894   0.11458506  0.11104169]\n",
      " [ 0.12454938  0.09836718  0.11910157  0.10047729  0.08726902  0.09612737\n",
      "   0.09475049  0.09094443  0.1012967   0.08711652]\n",
      " [ 0.10412422  0.10061888  0.11618274  0.09077089  0.09729452  0.09139228\n",
      "   0.10403488  0.0975338   0.09913576  0.0989121 ]\n",
      " [ 0.10950284  0.08954208  0.11477803  0.11971179  0.09699517  0.08876804\n",
      "   0.09104523  0.08664924  0.10992226  0.09308532]\n",
      " [ 0.10037566  0.09050956  0.10251619  0.09863592  0.09990357  0.09809326\n",
      "   0.09979311  0.10160752  0.1107695   0.09779576]\n",
      " [ 0.09052063  0.10142846  0.11701211  0.09915392  0.10767907  0.09574632\n",
      "   0.08584712  0.10600153  0.1058777   0.09073318]\n",
      " [ 0.11331764  0.09421987  0.11404923  0.08969601  0.10521549  0.08539448\n",
      "   0.09375316  0.09093788  0.10190174  0.11151448]\n",
      " [ 0.10255978  0.08957347  0.11440517  0.09693138  0.10892863  0.08797106\n",
      "   0.09951398  0.09662043  0.09540933  0.10808679]\n",
      " [ 0.09244515  0.10088281  0.11250132  0.10417712  0.10157999  0.08795595\n",
      "   0.10201584  0.09009552  0.10911675  0.09922955]\n",
      " [ 0.10284109  0.08706788  0.11047101  0.094097    0.09739718  0.09425202\n",
      "   0.09609693  0.09672139  0.11098283  0.1100726 ]\n",
      " [ 0.09698559  0.09352714  0.09946351  0.09700119  0.10897268  0.09579317\n",
      "   0.08886733  0.10456164  0.10921434  0.10561343]\n",
      " [ 0.1158087   0.08645219  0.11375634  0.10766236  0.0994454   0.10424438\n",
      "   0.10526846  0.09178892  0.09471643  0.0808568 ]\n",
      " [ 0.11722579  0.09780369  0.11060169  0.08856039  0.09876376  0.09008904\n",
      "   0.0981619   0.08842129  0.10406426  0.10630819]\n",
      " [ 0.09311285  0.09299558  0.09967226  0.10905066  0.10671115  0.09107209\n",
      "   0.10261478  0.09858004  0.09906822  0.10712233]\n",
      " [ 0.09704097  0.08622606  0.10857466  0.09147888  0.1032501   0.08883071\n",
      "   0.13023263  0.09954535  0.0939118   0.10090884]\n",
      " [ 0.11356783  0.12228705  0.10346027  0.08871139  0.09840128  0.09684949\n",
      "   0.09692198  0.09221137  0.09669586  0.09089349]\n",
      " [ 0.09677222  0.10337865  0.10501418  0.10494091  0.09589743  0.10674305\n",
      "   0.10949404  0.08648369  0.10693374  0.08434205]\n",
      " [ 0.11633904  0.10456305  0.10411913  0.10784211  0.09616614  0.09896928\n",
      "   0.09059251  0.08729386  0.09388218  0.10023276]\n",
      " [ 0.10359438  0.09723183  0.12797098  0.08830226  0.08662865  0.08306603\n",
      "   0.09727593  0.09754882  0.11867616  0.09970497]\n",
      " [ 0.09512058  0.09723561  0.09287246  0.10238055  0.10456134  0.09402227\n",
      "   0.10163327  0.09376013  0.1090894   0.10932433]\n",
      " [ 0.09079532  0.08423445  0.09554832  0.09061521  0.10691407  0.08733494\n",
      "   0.10676521  0.09070575  0.13547151  0.11161528]\n",
      " [ 0.11342054  0.09683244  0.10691126  0.08670213  0.09402421  0.10507604\n",
      "   0.07936364  0.09556686  0.11693925  0.10516363]\n",
      " [ 0.10477128  0.08685691  0.09800278  0.12536961  0.09681067  0.08700643\n",
      "   0.09653138  0.08712719  0.11909028  0.09843349]\n",
      " [ 0.11528176  0.08467292  0.10263593  0.09587815  0.1140542   0.08320376\n",
      "   0.09309138  0.09947766  0.09506936  0.11663491]\n",
      " [ 0.10002644  0.10090742  0.105567    0.09742173  0.09852194  0.08889131\n",
      "   0.09046855  0.10294911  0.11242515  0.10282127]\n",
      " [ 0.10006988  0.08265585  0.10300619  0.09047376  0.10475426  0.08997318\n",
      "   0.09769718  0.09948954  0.10312875  0.12875137]\n",
      " [ 0.1032992   0.11392346  0.1048159   0.09818545  0.10277864  0.09073587\n",
      "   0.09188946  0.09889612  0.10050159  0.09497427]\n",
      " [ 0.10580437  0.10427635  0.10798008  0.09250104  0.092895    0.09311862\n",
      "   0.1013909   0.10263592  0.1034751   0.0959226 ]] (8.501 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.24367, step = 501 (18.447 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa083ac3af30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa083ac3af30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       hooks=[logging_hook])\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;31m# Evaluate the model and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=20000,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_6:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "weights=tf.Variable(tf.random_normal([2,3],stddev=2))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros_3:0' shape=(2, 3) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biases=tf=tf.Variable(tf.zeros([3]))\n",
    "w2=tf.Variable(weights.initialized_value())\n",
    "w3=tf.Variable(weights.initialized_value()*2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.95757794]]\n"
     ]
    }
   ],
   "source": [
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "x=tf.constant([[0.7,0.9]])\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "sess=tf.Session()\n",
    "sess.run(w1.initializer)\n",
    "sess.run(w2.initializer)\n",
    "print(sess.run(y))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-eedad6d94d13>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-eedad6d94d13>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    w1=tf.Variable(tf.random_normal(([2,3],stddev=1,seed=1))\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "#定义训练数据batch 的大小\n",
    "batch_size=8\n",
    "\n",
    "# 定义神经网络的参数\n",
    "w1=tf.Variable(tf.random_normal(([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "               \n",
    "x=tf.placeholder(tf.float32,shape=(None,2),name='x-input')      \n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name='y-input')\n",
    "\n",
    "# define 神经网络前向传播的过程\n",
    "a=tf.matnul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "               \n",
    "#定义损失函数的反向传播过程和损失函数\n",
    "cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,le-10,1.0)))\n",
    "train_step=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdm=RandomState(1)\n",
    "# dateaset_size=128\n",
    "# X=rdm.rand(dataset_size,2)\n",
    "# Y=[[int(x1+x2<1) for (x1,x2) in X]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_excution()\n",
    "print(tf.add(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_1:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add([1,2],[3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Square:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.square(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sum:0\", shape=(), dtype=int32)\n",
      "Tensor(\"EncodeBase64:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_sum([1,2,3]))\n",
    "print(tf.encode_base64(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.square(2)+tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
